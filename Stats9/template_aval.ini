
---
title: ""
---
## Calculating p~value~ for multiple comparisons in one-way ANOVA

<div dir = "rtl", style = "color: black; font-size: 18px; font-family: B Nazanin;">
<h4 style = "color: blue;">
محاسبه <bdi>p<sub>value</sub></bdi>&nbsp; برای مقایسه‌های چند گانه در آنالیز واریانس یک‌طرفه
</h4>
<br><br> 
داده‌های موجود و البته مخصوصا داده‌های زیستی امروزه در مقیاس وسیعی تولید می شود. این امر جدا از آن‌که منجر به ذخیره انبوهی از داده‌های خام شده هست، بلکه باعث شکل‌گیری آزمون‌های فرض مختلفی نیز بوده هست. برای آزمایش این فرضیه‌ها، روش‌هایی از آمار استنباطی بر‌روی مجموعه‌ داده‌ها اِعمال می‌شود که منجر به بینش‌های زیستی بیشتر(برای داده‌های زیستی) و اصولا بینش عمیق‌تر در مورد داده‌ها می‌شود. اساسا، آزمون فرضیه یک روش آماری هست که احتمال موافق بودن داده‌ها را که بر‌اساس یک نمونه‌گیری تصادفی جمع‌آوری شده‌اند، با فرض صفر (یا مخالف فرض صفر) محاسبه می‌کند و نتایج این محاسبات در یک عدد خاص با نماد <bdi>p<sub>value</sub></bdi>&nbsp; خلاصه می‌شود. من پیرو قولی که در زمان ضبط ویدئوهای مربوط به <bdi>BlueSky</bdi>&nbsp; داده‌ام می‌خواهیم درباره‌ تصحیح مقادیر <bdi>p<sub>value</sub></bdi>&nbsp; یک گزارش نسبتا مفصل ارائه بدم، ولی قبل از آن‌که در مورد تصحیح <bdi>p<sub>value</sub></bdi>&nbsp;  برای مقایسه‌های چند‌گانه صحبت کنم، در مورد خود آن توضیح کوتاهی ارائه دهم. 
<br>
</div>
## What is p~value~
<div dir = "rtl", style = "color: black; font-size: 18px; font-family: B Nazanin;">
<h4 style = "color:blue;"> 
<bdi> p<sub>value</sub></bdi>&nbsp;  چیست؟
</h4>
هنگامی که می‌خواهید به صورت آماری استنباط کنید که آیا نتیجه آزمون آماری قابل توجه (معنادار) هست یا خیر، با توجه به فرض صفر <bdi>(H<sub>0</sub>)</bdi>&nbdp;، احتمال شکل‌گیری نتیجه مشاهده شده را با وضعیتی که در آن همه چیز کاملا تصادفی باشد البته با فرض درستی فرض صفر، مقایسه کنیم. یک مقدار یا برشی که به عنوان مرز تصمیم گیری که البته هم بر‌اساس روابط تکنیکی ریاضی و هم تاریخی بر‌روی آن تا حدود یک اجماع وجود دارد (البته با توجه به زمینه تحقیق) مقدار خطای نوع اول یا <bdi>&alpha;</bdi>&nbsp; ;که معمولا برابر با <bdi>0.05</bdi>&nbsp;  در نظر گرفته می‌شود. بر این اساس، (با فرض آزمون مقایسه میانگین چند گروه (سطح) هست) اگر احتمال فرضیه صفر برابری میانگین سطوح باشد یعنی <bdi> &mu;<sub>1</sub> == &mu;<sub>2</sub> == … &mu;<sub>k</sub></bdi>&nbsp;   اگر مقدار <bdi>p<sub>value</sub></bdi>&nbsp; به‌دست آمده کمتر از نقطه برش انتخاب شده یا همان <bdi>&alpha;</bdi>&nbsp; باشد فرض صفر رد می‌شود و در غیر این صورت فرض صفر تأیید می‌شود. البته باید اضافه شود که در آزمون‌های آماری صرف بیان کردن مقدار <bdi>p<sub>value</sub></bdi>&nbsp; کفایت نمی‌کند. و باید علاوه بر این مقدار کمیت‌هایی مانند فواصل اطمینان، توان آزمون و یا اندازه اثر نیز گزارش شود. 
<br>
</div>

## p~value~ Problems
<div dir = "rtl", style = "color: black; font-size: 18px; font-family: B Nazanin;">
<h4 style = "color: blue;">
مشکلات <bdi>p<sub>value</sub></bdi>&nbsp; 
</h4>
حقیقت این هست که بحث جدل زیادی پیرامون موقعیت و اهمیت <bdi>p<sub>value</sub></bdi>&nbsp; در محافل علمی وجود دارد. و این موضوع با ظهور کلان‌داده‌ها که عمدتا حول سوء تفاهم و همچنین استفاده نادرست از <bdi>p<sub>value</sub></bdi>&nbsp; می‌شود افزونی یافته هست. اولین ایرادی که وارد می‌کنند این هست که نقاط برش انتخاب شده یعنی <bdi> &alpha; = 0.1, 0.05, 0.001, ...</bdi>&nbsp; کاملا دلخواه هستند و صرفا بر‌اساس یک قرار‌داد شکل گرفته‌اند. و این واقعیت مولد آن هست که این مقدار لزوما برای هر زمینه‌ مطالعاتی مناسب نیست و به عنوان مثال برای بعضی از کارآزمایی‌های بالینی حتی مقدار <bdi>&alpha; = 0.001</bdi>&nbsp; پیشنهاد می‌شود. علاوه بر‌این، دو تَوَرّش (سوگیری) رایج که به یک‌پارچگی یافته‌های تحقیق اثر می‌گذارد، یکی گزارش‌های انتخابی یا با عنوان انگلیسی <bdi>Selective Reporting</bdi>&nbsp; و دیگری با اصطلاح <bdi>P-Hacking</bdi>&nbsp; شناخته می‌شود، می‌باشد. به‌طور خلاصه گزارش‌ دهی انتخابی به گرایش به سمت گزارش کردن صرفا مقادیر معنادار یعنی زمانی که <bdi>p<sub>value</sub></bdi>&nbsp; از مقدار نقطه برش کمتر هست توجه دارد، که در یک بررسی مشخص شد این اریبی به سمت نتایج معنادار گزارش شده می‌باشد. که در متا‌آنالیز با عنوان اریبی انتشار از آن یاد می‌شود. در مقابل، اصطلاح <bdi>P-Hacking</bdi>&nbsp;  اشاره به نمونه‌‌گیری‌های غیر تصادفی و یا دستکاری عمدی داده‌ها دارد. 
<br>
</div>

## The problem of multiple comparisons
<div dir = "rtl", style = font-size: 18px; font-family: B Nazanin;">
<h4 style = "color:blue;">
مسئله مقایسه‌های چند‌گانه
</h4>
با فرض این‌که تمام ایرادات مطرح شده برطرف شده یا نادیده گرفته شوند، آخرین و اما مهم‌ترین مسئله‌ای که در کمی سازی مقدار <bdi>p<sub>value</sub></bdi>&nbsp; باقی می‌ماند، زمانی هست که یک آزمون چند‌گانه روی می‌دهد، اما آزمون چند‌گانه چه مفهومی می‌تواند داشته باشد؟ وضعیتی را تصور کنید که می‌خواهیم تأثیر چند نوع کود را بر‌روی میزان محصولات برداشت با هم مقایسه کنیم، که البته تعداد انواع کود بیشتر از ۲ هست و همچنین با فرض یکسان بودن سایر شرایط، مانند نوع خاک، وسعت زمین، نوع آبیاری و …<br>
و بخواهیم این مقایسه‌ها را به صورت دو‌به‌دو انجام دهیم، یعنی ابتدا کود نوع ۱ را با نوع ۲ و سپس با نوع ۳والی آخر  یعنی به شکل زیر:‌
</div>
$$
\begin{aligned}
& \text{Test}_1: ~ \begin{cases}H_0: & \mu_A = \mu_B\\ H_1: & \mu_A\ne \mu_B \end{cases}\\
& \text{Test}_2: ~ \begin{cases}H_0: & \mu_A = \mu_C\\ H_1: & \mu_A\ne \mu_B \end{cases}\\
& \text{Test}_3: ~ \begin{cases}H_0: & \mu_A = \mu_D\\ H_1: & \mu_A\ne \mu_B \end{cases}\\
& \text{Test}_4: ~ \begin{cases}H_0: & \mu_B = \mu_C\\ H_1: & \mu_A\ne \mu_B \end{cases}\\
& \text{Test}_5: ~ \begin{cases}H_0: & \mu_B = \mu_D\\ H_1: & \mu_A\ne \mu_B \end{cases}\\
& \text{Test}_6: ~ \begin{cases}H_0: & \mu_C = \mu_D\\ H_1: & \mu_A\ne \mu_B \end{cases}\\
\end{aligned}
$$
<br>
<div dir = "rtl", style = "color: black; font-size: 18px; font-family: B Nazanin;">
واضح هست که حروف <bdi>A, B, C, D</bdi>&nbsp; اشاره به نوع کودها دارد، همان‌طور که می بینیم وقتی انواع کود دارای ۴ سطح هست، ما ۶ مقایسه دو به دو خواهیم داشت که ترکیب ۲ از ۴ هست که جواب همان ۶ هست. <br>
حالا اگر خطای نوع اول یا همان <bdi> &alpha; = 0.05</bdi>&nbsp; در نظر بگیریم و برای هر ۶ مقایسه همزمان خطای نوع اول را پنج صدم در نظر بگیریم با وضعیت زیر مواجه خواهیم شد: 
</div>
<br>
```{r}
#| warning: false
#| message: false
#| echo: false
a_single <- 0.05
n <- 6
p_single <- 1 - a_single
p_m = p_single ** n
a_m <- 1 - p_m 
p_m2 <- (1 - a_single)**50
a_s <- 1 - (1 - 0.05)^(1/20)
```

$$
\alpha_{Test_1} = \alpha_{Test_2} = \cdots = \alpha_{Test_6} = 0.05\implies
$$

<div dir = "rtl", style = "color: black; font-size: 18px; font-family: B Nazanin;">
خطای نوع اول یعنی امکان مشاهده وضعیتی که فرض <bdi>H<sub>0</sub></bdi>&nbsp; را رد کنیم در صورتی که این فرض درست باشد،‌ پس احتمال این‌که فرض <bdi>H<sub>0</sub></bdi>&nbsp; را رد نکنیم در صورتی که این فرض درست باشد می‌شود <bdi> 1 - &alpha; </bdi>&nbsp; ولی این مقادیر برای یک آزمون صدق می‌کند، ولی اگه بخواهیم احتمال این‌ را بسنجیم در صورتی برابری تمام میانگین سطوح‌ها ما فرض <bdi>H<sub>0</sub></bdi>&nbsp; را برای هیچ‌کدام از آزمون‌ها  رد نکنیم باید به این شکل آن را محاسبه کنیم
</div>
$$
\begin{aligned}
& \alpha_{Single} = 0.05 \implies P_{single} = 1 - \alpha_{single} = 1 - 0.05 = 0.95\\
& \implies P_{multiple} = P_{single} ^ 6 = `r p_m` \implies \\
& \alpha_{multiple} = 1 - P_{multiple} = `r (1-p_m)`
\end{aligned}
$$
<div dir = "rtl", style = "color: black; font-size: 18px; font-family: B Nazanin;">
همان‌طور که مشاهده می‌کنیم، خطا نوع اول برای مقایسه‌های همزمان به شدت تورم پیدا کرده هست و اگر تعداد مقایسه‌ها افزایش پیدا کند یعنی اگر ما فرضا ۵۰ تا مقایسه همزمان داشته باشیم و خطای نوع اول را را برای همه ۵۰ تا مقایسه پنج‌صدم در نظر بگیریم، آن‌گاه خطای نوع اول آزمون‌های چند‌گانه با توجه به روابطی که بالا آوردیم می‌شود:‌
</div>
$$
\alpha_{multiple} = 1 - P_{multiple} = 1 - (1 - 0.05)^{50} =  `r (1 - p_m2)`
$$
<div dir = "rtl", style = "color: black; font-size: 18px; font-family: B Nazanin;">
واضح هست که در صورت افزایش مقایسه‌های چند‌گانه خطای نوع اول چند‌گانه به یک هم خواهد رسید. <br>
سؤالی که این‌جا شکل می‌گیرد این هست که چگونه باید جلوی رشد نرخ خطای نوع اول برای مقایسه‌های چند‌گانه گرفته شود؟
<br> 
اولین جوابی که به این سؤال میشه داد، کاهش خطای نوع اول هست. یا در واقع کاهش <bdi>Threshold</bdi>&nbsp; یا آن آستانه‌ای که در صورتی که <bdi>p<sub>value</sub></bdi>&nbsp; از آن کمتر شود فرض اولیه رد می‌شود. یکی از روش‌هایی که برای پاسخ به این پرسش مد نظر قرار می‌گیرد، روش بونفرونی هست که در ادامه روش‌ها گوناگون تصحیح خطای نوع اول و یا مقدار <bdi>p<sub>value</sub></bdi>&nbsp; بیان خواهد شد. 
<br>

قبل از آن‌که من ادامه این مبحث را بدهم، باید اشاره کنم؛ من در این بخش قصد دارم، چند روش معروف از روش‌های اصلاح <bdi>p<sub>value</sub></bdi> را بیان کنم. از جمله روش‌های که می‌خواهم به آن‌ها بپردازم از این قرار هست. 
<ul>
<li> <bdi> Bonferroni</bdi></li>
<li><bdi>Holm</bdi></li>
<li><bdi>Hochberg</bdi></li>
<li><bdi>Hommel</bdi></li>
<li><bdi>Benjumaini and Hochberg (BH)</bdi></li>
<li><bdi>Benjumaini and Yekutieli (BY)</bdi></li>
<li><bdi>False discovery rate (fdr)</bdi></li>
</ul>
<br>
</div>

## Bonferroni's method for correcting type 1 error in multiple tests
<div dir = "rtl", style = "color: black; font-size: 18px; font-family: B Nazanin;">
<h4 style = "color: blue;">
روش بونفرونی برای تصحیح خطای  نوع اول در آزمون‌های چند‌گانه
</h4>
ما برای توضیح این ۸ نوع روش تصحیح <bdi>p<sub>value</sub></bdi>&nbsp; یا خطای نوع اول، یک بردار از مقادیر <bdi>p<sub>value</sub></bdi>&nbsp; محاسبه شده به روش‌های معمولی را مد نظر قرار می‌دهیم، یعنی فرض می‌کنیم که یک  آزمون چند‌گانه را پیاده‌سازی کرده‌ایم و مقادیر محاسبه شده برای <bdi>p<sub>value</sub></bdi>&nbsp; از قرار زیر بوده هست
</div>
<br>
```{python}
#| warning: false
#| message: false
#| echo: false

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import statsmodels.stats.multitest as stest 
pVal = [0.0001, 0.001, .01, 0.1, 0.08, 0.09, 0.15, 0.21, 0.35, 0.55, 0.3, 
0.64, 0.77, 0.9, 0.03, 0.02, 0.09, 0.19, 0.21, 0.41]
# len(pVal)
print(*pVal)
# res = stest.multipletests(pVal, alpha = 0.05, method = "bonferroni")
# res
```

<div dir = "rtl", style = "color: black; font-size: 18px; font-family: B Nazanin;">
روش بونفرونی رویکرد خیلی ساده‌ای دارد، این روش به ما می گوید که اگر فرضا تعداد مقایسه‌ها (آزمون‌ها) فرضا <bdi>m</bdi>تا آزمون هست، آن‌گاه بر‌اساس خطای نوع اولیه که در شروع تعیین می‌کنید، برای مقایسه‌های چند‌گانه این خطا را بر تعداد آزمون‌ها که در این‌جا فرض کردیم <bdi>m</bdi>تا می‌باشد تقسیم کنید و مقادیر <bdi>p<sub>value</sub></bdi>&nbsp;محاسبه شده را با این خطا مقایسه کنید و آن‌گاه اگر مقدار <bdi>p<sub>value</sub></bdi>&nbsp; کمتر از مقدار خطا نوع اول برآورد شده کمتر بود فرض <bdi>H<sub<0</sub></bdi>&nbsp; را رد کنید. یعنی؛
</div>

$$
\begin{aligned}
& \text{Initial} ~\alpha = \alpha_0\implies \\
& \text{if number of test}~ = m \implies \text{final}~ \alpha = \alpha_{multiple} = \frac{\alpha_0}{m}
\end{aligned}
$$

<div dir = "rtl", style = "color: black; font-size: 18px; font-family: B Nazanin;">
حالا اگر بخواهیم برای مثالی که در بالا مقادیر <bdi>p<sub>value</sub></bdi>&nbsp; آن را آورده‌ایم، این روش را پیاده‌سازی کنیم، به جواب زیر خواهیم رسید. 
<br>
البته قبل از آن‌که جواب را ببینیم، ذکر یک نکته در این‌جا می تواند اهمیت داشته باشد، و آن این هست که، در <bdi>R</bdi> و در بسته <bdi>stats</bdi>&nbsp; که همراه <bdi>R</bdi> 
بر‌روی سیستم نصب می‌شود، یعنی جز بسته‌های پیش‌فرض هست، تابع <bdi><b><span style = "font-family: courier new;"> p.adjust </span></bdi></b>&nbsp; روش‌های گفته شده در بالا را پشتیبانی می‌کند و ما می‌توانیم با دادن بردار مقادیر <bdi>p<sub>value</sub></bdi>&nbsp; به این تابع و تعیین نوع تصحیح خروجی که مقادیر اصلاح شده <bdi>p<sub>value</sub></bdi>&nbsp; می‌باشد را داشته باشیم. ولی از نظر من در کتابخانه <bdi><b><span style = "font-family: courier new;"> statsmodels </span></bdi></b>&nbsp; در پایتون متد‌هایی هست که خروجی بهتری و همچنین روش‌های به نسبت بیشتری را برای تصحیح خطای نوع اول و یا <bdi>p<sub>value</sub></bdi>&nbsp; پشتیبانی می‌کنند. من خروجی در هر دو نرم‌افزار برای شما در پایین می‌آورم تا بهتر متوجه این مسئله بشوید. 
<br><br>
مثال:
</div>

```{python}
#| warning: false
#| message: false
#| echo: true
import statsmodels.stats.multitest as stest 
pVal = [0.0001, 0.001, .01, 0.1, 0.08, 0.09, 0.15, 0.21, 0.35, 0.55, 0.3, 
0.64, 0.77, 0.9, 0.03, 0.02, 0.09, 0.19, 0.21, 0.41]
res = stest.multipletests(pVal, alpha = 0.05, method = "bonferroni")
# python Result
print(res)
```
<hr/>
```{r}
#| echo: true
#| warning: false
#| message: false
# R Result
p.adjust(c(0.0001, 0.001, .01, 0.1, 0.08, 0.09, 0.15, 0.21, 0.35, 0.55, 0.3, 
0.64, 0.77, 0.9, 0.03, 0.02, 0.09, 0.19, 0.21, 0.41), method = "bonferroni")
```
<div dir = "rtl", style = "color: black; font-size: 18px; font-family: B Nazanin;">
همان‌طور که مشاهده می‌کنیم خروجی پایتون دارای جزئیات بیشتری هست، خروجی این‌نرم‌افزار علاوه بر مقادیر اصلاح شده <bdi>p<sub>value</sub></bdi>&nbsp; که اگر بخواهیم به شکل مشخص‌تری نشان دهیم؛‌
<br>
</div>
<div style = "color: black; font-size: 16px; font-family: courier new;">
<b>
<span style = "color: red;"> 
(array([ True,  True, False, False, False, False, False, False, False,
False, False, False, False, False, False, False, False, False,
False, False])</span>, <span style = "color: green;">array([0.002, 0.02 , 0.2  , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,
1.   , 1.   , 1.   , 1.   , 1.   , 0.6  , 0.4  , 1.   , 1.   ,
1.   , 1.   ])</span>, <span style = "color: darkblue;">0.0025613787765302876, 0.0025) </span>

</b>
</div>

<div dir = "rtl", style = "color: black; font-size: 18px; font-family: B Nazanin;">
خروجی پایتون یک <a href = "https://www.geeksforgeeks.org/python-tuples/">تاپل</a> می ‌باشد که شامل ۴ عضو هست، عضو اول و دوم <bdi>array</bdi>&nbsp; می‌باشند و عضو‌های سوم و چهارم مقادیر عددی، آرایه اول در حقیقت نتایج آزمون‌ها را نشان می‌دهد که مقدار <bdi>True</bdi>&nbsp; به معنای رد فرض اولیه هست و مقدار <bdi>False</bdi>&nbsp; به معنای فرض اولیه. که در این‌جا این آرایه با رنگ قرمز مشخص شده هست. آرایه دوم که با رنگ سبز مشخص شده هست اشاره دارد به مقادیر <bdi>p<sub>value</sub></bdi>&nbsp;اصلاح شده توسط روش به‌کار برده شده که در این‌جا بونفرونی می‌باشد. و مقادیر عددی که عضو‌های سوم و چهارم این تاپل می‌باشند و با رنگ آبی پر‌رنگ مشخص شده‌اند، عضو سوم اشاره خطای نوع اول اصلاح شده با روش <bdi>Sidak</bdi>&nbsp; دارد. که برای این‌که بدانیم خطای نوع اول اصلاح شده <bdi>Sidak</bdi>&nbsp; چگونه محاسبه می‌شود، با توجه به مثال آورده شده در بالا، به معادله زیر توجه کنید: 

</div>


$$
\begin{aligned}
& \alpha_{Sidak} = 1 - (1 - \alpha_{Intiial})^{\frac{1}{\text{\# number of Tests}}} \implies \\
& \text{In This Example:}\quad  \alpha_{Sidak} = 1 - (1 - 0.05)^{\frac{1}{20}} = `r a_s`
\end{aligned}
$$

<br>
<div dir = "rtl", style = "color: black; font-size: 18px; font-family: B Nazanin;">
که البته در این‌جا کمی این مقدار گرد شده هست. و همچنین 
عضو چهارم همان خطای نوع اول اصلاح شده به روش بونفرونی می‌باشد. 
ولی در خروجی <bdi>R</bdi> همان‌طور که ملاحظه می‌کنیم فقط مقادیر اصلاح شده <bdi>p<sub>value</sub></bdi>&nbsp; را ما در خروجی می‌بینیم. باز هم ذکر یک نکته حائز اهمیت هست، چرا وقتی ما در روش بونفرونی حرف از اصلاح خطای نوع اول زده‌ایم در این دو تابع مقادیر اصلاح شده برای <bdi>p<sub>value</sub></bdi>&nbsp; برای ما در خروجی ظاهر شده هست. دلیل این امر این هست که هر دو این توابع  یا متدها، به جای آن‌که در حقیقت مقایسه <bdi>p<sub>value</sub></bdi>&nbsp; را با مقدار تقسیم خطای نوع اول بر تعداد آزمون‌ها مقایسه کنند، به جای آن تعداد آزمون‌ها را در مقدار <bdi>p<sub>value</sub></bdi>&nbsp; ضرب می‌کنند و آن گاه مقدار <bdi>p<sub>value</sub></bdi>&nbsp; به‌دست آمده را با همان خطای نوع اول آغازین آزمون مقایسه می‌کنند. ولی در خروجی نهایی پایتون ما خطای نوع اول اصلاح شده نهایی هم در انتها می‌بینیم ولی در خروجی <bdi>R</bdi> این چنین نیست. البته باز هم شاید این ابهام شکل بگیرد که ضرب تعداد آزمون‌ها در بعضی از مقادیر <bdi>p<sub>value</sub></bdi>&nbsp; مقادیر گزارش شده در خروجی‌های بالا نیست، برای این مورد باید ذکر شود که مقدار <bdi>p<sub>value</sub></bdi>&nbsp; یک مقدار احتمال هست پس نمی‌تواند بزرگتر از ۱ گزارش شود و برای وقتی که ضرب تعداد آزمون‌ها در <bdi>p<sub>value</sub></bdi>&nbsp; برآورد شده اولیه بزرگتر از ۱ باشد، آن مقدار همان ۱ گزارش می‌شود. 
</div>
## Holm's method for correcting type 1 error in multiple tests
<div dir = "rtl", style = "color: black; font-size: 18px; font-family: B Nazanin;">
<h4 style = "color: blue;">
روش هولم برای تصحیح خطای  نوع اول در آزمون‌های چند‌گانه
</h4>
این روش در حقیقت یک اصلاح هست بر‌روی روش بونفرونی که از مراحل زیر تشکیل شده هست. 
</div>
<br>
<div dir = "rtl", style = "font-size: 18px; font-family: B Nazanin;">
<ul>
<li>فرض کنید که <bdi>m</bdi> آزمون همزمان دارید و مقادیر برآورد شده برای <bdi>p<sub>value</sub></bdi>&nbsp; این آزمون‌ها را از کوچک به بزرگ به شکل زیر مرتب کرده‌اید: <bdi>P<sub>1</sub>, &nbsp; P<sub>2</sub>, &nbsp;, ..., &nbsp; P<sub>m</sub></bdi>&nbsp; و این مقادیر متناظر با فرض‌های اولیه <bdi>H<sub>1</sub>, &nbsp; H<sub>2</sub>, &nbsp;, ..., &nbsp; H<sub>m</sub></bdi>&nbsp;می‌باشد برای به دست آوردن نتیجه هر آزمون البته با تصحیح خطای  نوع اول به شکل زیر عمل می‌کنیم</li>
<li>اگر <bdi>P<sub>1</sub> &lt; <sup>&alpha;</sup>&frasl;<sub>m</sub></bdi> آن‌گاه فرض اولیه <bdi>H<sub>1</sub></bdi>&nbsp; را رد کن و برو گام بعدی، در غیر این صورت  فرض اولیه  <bdi>H<sub>1</sub></bdi>&nbsp; را قبول کن و از ادامه مراحل صرف‌نظر کن</li>
<li>اگر <bdi>P<sub>2</sub> &lt; <sup>&alpha;</sup>&frasl;<sub>(m-1)</sub></bdi> آن‌گاه فرض اولیه <bdi>H<sub>2</sub></bdi>&nbsp; را رد کنید و بروید گام بعدی، در غیر این صورت  فرض اولیه  <bdi>H<sub>2</sub></bdi>&nbsp; را قبول کنید و از ادامه مراحل صرف‌نظر کنید</li>
<li>
این روند ادامه پیدا‌ می‌کند به این‌ شکل که برای هر مقدار <bdi>P<sub>k</sub>, k = 1, 2, ..., m</bdi>&nbsp; اگر <bdi>P<sub>k</sub> &lt; <sup>&alpha;</sup>&frasl;<sub>(m - k + 1)</sub></bdi>&nbsp; آن‌گاه فرض اولیه <bdi>H<sub>k</sub></bdi>&nbsp; را رد کنید و بروید مرحله بعد در غیر این صورت از ادامه مراحل صرف‌نظر کنید. 
</li>
</ul>
این روش اطمینان حاصل می‌کند که مقدار خطای نوع اول چند‌گانه یا در اصطلاح بهتر آن <bdi>FWER (family-wise error rate)</bdi>&nbsp; در سطح خطای نوع اول آزمون باقی بماند. 
<br><br>
مثال:
</div>

```{python}
#| warning: false
#| message: false
#| echo: true
import statsmodels.stats.multitest as stest 
pVal = [0.0001, 0.001, .01, 0.1, 0.08, 0.09, 0.15, 0.21, 0.35, 0.55, 0.3, 
0.64, 0.77, 0.9, 0.03, 0.02, 0.09, 0.19, 0.21, 0.41]
res = stest.multipletests(pVal, alpha = 0.05, method = "holm")
# python Result
print(res)
```
<hr/>


```{r}
#| echo: true
#| warning: false
#| message: false
# R Result
p.adjust(c(0.0001, 0.001, .01, 0.1, 0.08, 0.09, 0.15, 0.21, 0.35, 0.55, 0.3, 
0.64, 0.77, 0.9, 0.03, 0.02, 0.09, 0.19, 0.21, 0.41), method = "holm")
```
<br><br>
## Hochberg's method for correcting type 1 error in multiple tests
<div dir = "rtl", style = "color: black; font-size: 18px; font-family: B Nazanin;">
<h4 style = "color: blue;">
روش هاچبرگ برای تصحیح خطای  نوع اول در آزمون‌های چند‌گانه
</h4>
روش هاچبرگ دقیقا مانند روش هولم هست، با این تفاوت که مقایسه‌ها از  بزرگترین مقدار <bdi>p<sub>value</sub></bdi>&nbsp; برآورد شده شروع می‌شود و تا کوچکترین مقدار امتداد پیدا می کند یا به عبارتی دیگر عکس مسیری که روش هولم در پیش می‌گرفت، روش هولم مقایسه‌ها را از کوچکترین مقدار <bdi>p<sub>value</sub></bdi>&nbsp; برآورد شده شروع می‌کرد ولی در روش هاچبرگ از بزرگترین مقدار شروع می‌شود و با اولین معناداری مقابسه ادامه الگوریتم متوقف می‌شود و تمام مقایسه‌های باقی‌مانده، معنادار گزارش می‌شود. 
<br>
البته یک تفاوت دیگر هم بین این روش و روش هولم وجود دارد و آن تعیین مقدار <bdi>p<sub>value</sub></bdi>&nbsp; در هر مرحله هست، روش‌های ذکر شده همگی تصحیح‌ را را بر روی مقادیر خطای نوع اول انجام می‌دهند ولی همان‌طور که ذکر شده به جا مقایسه <bdi>p<sub>value</sub></bdi>&nbsp; هر مرحله با خطای نوع اول آن مرحله ضریب اِممال شده در خطای نوع اول هر مرحله را معکوس کرده و در مقدار <bdi>p<sub>value</sub></bdi>&nbsp; همان مرحله ضرب می‌کنند و اسم این مقدار <bdi>p<sub>value</sub></bdi>&nbsp; را مقدار اصلاح شده <bdi>p<sub>value</sub></bdi>&nbsp; می‌نامند ولی همان‌طور که ذکر شده <bdi>p<sub>value</sub></bdi>&nbsp; یک مقدار احتمال هست و نمی‌تواند بزرگتر از ۱ باشد لذا مقداری که انتخاب می‌‌شود مقدار کمینه بین ۱ و مقدار حاصل شده هست. 
تفاوت روش هاچبرگ با روش هولم در این‌جاست که روش‌های بونفرونی و هولم مقدار <bdi>p<sub>value</sub></bdi>&nbsp; حاصل شده را با یک مقایسه کرده و مقدار کمینه را در خروجی می‌آورند ولی روش هاچبرگ مقدار حاصل‌شده را با بیشینه مقدار <bdi>p<sub>value</sub></bdi>&nbsp; محاسبه شده با مقادیر <bdi>p<sub>value</sub></bdi>&nbsp; محاسبه شده در همه مقایسه‌های شکل گرفته مقابسه کرده و مقدار مینیم را انتخاب کرده و در خروجی می‌آورد. یعنی در مثال ما چون مقدار بیشینه <bdi>0.9</bdi>&nbsp; می‌باشد لذا آن‌جا که <bdi>p<sub>value</sub></bdi>&nbsp;حاصل شده بیش‌تر از این مقدار باشد، همین مقدار <bdi>0.9</bdi>&nbsp; به عنوان مقدار نهایی برای <bdi>p<sub>value</sub></bdi>&nbsp; آن مرحله در خروجی خواهد آمد. 
<br><br>
مثال: 
</div>
```{python}
#| warning: false
#| message: false
#| echo: true
import statsmodels.stats.multitest as stest 
pVal = [0.0001, 0.001, .01, 0.1, 0.08, 0.09, 0.15, 0.21, 0.35, 0.55, 0.3, 
0.64, 0.77, 0.9, 0.03, 0.02, 0.09, 0.19, 0.21, 0.41]
res = stest.multipletests(pVal, alpha = 0.05, method = "simes-hochberg")
# python Result
print(res)
```
<hr/>


```{r}
#| echo: true
#| warning: false
#| message: false
# R Result
p.adjust(c(0.0001, 0.001, .01, 0.1, 0.08, 0.09, 0.15, 0.21, 0.35, 0.55, 0.3, 
0.64, 0.77, 0.9, 0.03, 0.02, 0.09, 0.19, 0.21, 0.41), method = "hochberg")
```
<br><br>

## Hommel's method for correcting type 1 error in multiple tests
<div dir = "rtl", style = "color: black; font-size: 18px; font-family: B Nazanin;">
<h4 style = "color: blue;">
روش هومِل برای تصحیح خطای  نوع اول در آزمون‌های چند‌گانه
</h4>
این روش، نسبتا روش پیچیده‌ای هست البته در مقایسه با روش‌های قبلی. <br>
فرض کنیم؛ 
</div>
$$
\text{H} = \left\{H_{(1)}, H_{(2)}, ..., H_{(m)}\right\}, 
$$
<div dir = "rtl", style = "color: black; font-size: 18px; font-family: B Nazanin;">
فرض‌های صفر متناظر با آزمون‌های چند‌گانه با مقادیر <bdi>p<sub>value</sub></bdi>&nbsp; برآورد شده به شرح زیر باشد؛ 
<br>
<p style = "color: red">
<b>
مقادیر مرتب شده هست.
</b>
</p>
</div>

$$
p_{(1)}, p_{(2)}, ..., p_{(m)}
$$

<div dir = "rtl", style = "color: black; font-size: 18px; font-family: B Nazanin;">
که در این‌جا <bdi>m</bdi> تعداد مقایسه‌های چند‌گانه هست. آن‌گاه برای بررسی معناداری آزمون <bdi>H<sub>i</sub></bdi>&nbsp; به روش زیر عمل می‌کنیم. 
<br>
ابتدا مقدار <bdi>j</bdi> که به فرم زیر هست را محاسبه می‌کنیم
</div>
$$
j = \max\left\{i \in \left\{1, ..., m\right\}:\quad p_{(m -i+k)} > \frac{k\alpha}{i},\quad\text{for}~~k = 1, ..., i\right\}
$$




<div dir = "rtl", style = "color: black; font-size: 18px; font-family: B Nazanin;">
واضح هست که اگر به ازای یک مقدار دلخواه <bdi>i</bdi> هیچ مقداری برای <bdi>j</bdi> حاصل نشود آن‌گاه تمام فرض صفر که در بالا آورده شد رد می‌شود. حالا فرض کنیم که ما برای یک مقدار <bdi>i</bdi> یک مقدار <bdi>j</bdi> به‌دست آورده‌ایم آن‌گاه برای این‌که معناداری <bdi>H<sub>i</sub></bdi>&nbsp; را بررسی کنیم باید این مقایسه را شکل دهیم؛ 
</div>

$$
p_i \geq \frac{\alpha}{j}
$$

<div dir = "rtl", style = "color: black; font-size: 18px; font-family: B Nazanin;">
اگر گزاره شرطی بالا برقرار باشد، آن‌گاه فرض صفر <bdi>H<sub>i</sub></bdi>&nbsp; را رد می‌کنیم. 
<br><br>
مثال:
</div>


```{python}
#| warning: false
#| message: false
#| echo: true
import statsmodels.stats.multitest as stest 
pVal = [0.0001, 0.001, .01, 0.1, 0.08, 0.09, 0.15, 0.21, 0.35, 0.55, 0.3, 
0.64, 0.77, 0.9, 0.03, 0.02, 0.09, 0.19, 0.21, 0.41]
res = stest.multipletests(pVal, alpha = 0.05, method = "hommel")
# python Result
print(res)
```
<hr/>


```{r}
#| echo: true
#| warning: false
#| message: false
# R Result
p.adjust(c(0.0001, 0.001, .01, 0.1, 0.08, 0.09, 0.15, 0.21, 0.35, 0.55, 0.3, 
0.64, 0.77, 0.9, 0.03, 0.02, 0.09, 0.19, 0.21, 0.41), method = "hommel")
```

<br><br>

## Benjamini-Hochberg Method (BH) for correcting type 1 error in multiple tests
<div dir = "rtl", style = "color: black; font-size: 18px; font-family: B Nazanin;">
<h4 style = "color: blue;">
روش بنجامینی-هاچبرگ برای تصحیح خطای  نوع اول در آزمون‌های چند‌گانه
</h4>
این روش به نسبت روش قبل ساده‌‌تر هست، ولی تفاوتی که این روش و روش‌هایی که در ادامه می‌آید با روش‌هایی که ذکر شد در این هست که، روش‌های ذکر شده در جهت کنترل خطای نوع اول کل مقایسه یا همان <bdi>(FWER)</bdi>&nbsp; کارکرد خودشان را پیاده‌سازی می‌کردند. ولی این روش و روش‌هایی که در ادامه می‌آید، فارغ از این‌که خطای نوع اول در ابتدا چه مقداری هست در جهت کنترل رد به اشتباه فرض صفر عمل می‌کنند. یا به عبارتی کنترل <bdi>FDR (False Discovery Rate)</bdi>&nbsp;  که نسبت <bdi>FDR</bdi>&nbsp; اشاره دارد به تعداد فرض‌های صفر به اشتباه رد شده بر کل فرض‌های صفر رد شده. 
از این بستر اولین روشی که معرفی می‌شود روش بنجامینی-هاچبرگ هست که مقدار <bdi>p<sub>value</sub></bdi>&nbsp; تصحیح شده با استفاده از این شیوه از طریق زیر حاصل می‌شود.
<br>
در ابتدا مقادیر <bdi>p<sub>value</sub></bdi>&nbsp; برآورد شده را از کوچک به بزرگ مرتب می‌کنیم و در مجموعه زیر قرار می‌دهیم
</div>

$$
\left\{p_{(1)}, p_{(2)}, ..., p_{(m)}\right\}
$$


<div dir = "rtl", style = "color: black; font-size: 18px; font-family: B Nazanin;">
که مقدار <bdi>m</bdi> اشاره به تعداد کل آزمون‌های چند‌گانه دارد. آن‌گاه مقدار <bdi>p<sub>value</sub></bdi>&nbsp; حاصل شده برای عضو <bdi>i<sup>th</sup></bdi>&nbsp; این مجموعه با معادله زیر به دست می‌آید
</div>


$$
p_{(i)}^{(BH)} = \min\left\{\underset{j \geq i}{\min}\left\{\frac{m \times p_{(j)}}{j}\right\}, ~1\right\}
$$




<div dir = "rtl", style = "color: black; font-size: 18px; font-family: B Nazanin;">
<br><br>
مثال:
</div>



```{python}
#| warning: false
#| message: false
#| echo: true
import statsmodels.stats.multitest as stest 
pVal = [0.0001, 0.001, .01, 0.1, 0.08, 0.09, 0.15, 0.21, 0.35, 0.55, 0.3, 
0.64, 0.77, 0.9, 0.03, 0.02, 0.09, 0.19, 0.21, 0.41]
res = stest.multipletests(pVal, alpha = 0.05, method = "fdr_bh")
# python Result
print(res)
```
<hr/>


```{r}
#| echo: true
#| warning: false
#| message: false
# R Result
p.adjust(c(0.0001, 0.001, .01, 0.1, 0.08, 0.09, 0.15, 0.21, 0.35, 0.55, 0.3, 
0.64, 0.77, 0.9, 0.03, 0.02, 0.09, 0.19, 0.21, 0.41), method = "BH")
```


<br><br>

## Benjumaini and Yekutieli Method (BY) for correcting type 1 error in multiple tests
<div dir = "rtl", style = "color: black; font-size: 18px; font-family: B Nazanin;">
<h4 style = "color: blue;">
روش بنجامینی-یِکوتیلی برای تصحیح خطای  نوع اول در آزمون‌های چند‌گانه
</h4>
این روش در سال ۲۰۰۱ معرفی شد، مانند روش قبل ولی محافظه‌کارانه‌تر. همچنین به مانند روش قبل در جهت کنترل <bdi>FDR</bdi>&nbsp; می‌باشد. روش محاسبه‌ی <bdi>p<sub>value</sub></bdi>&nbsp; اصلاح شده با این شیوه به فرم زیر هست، در ابتدا اگر فرض کنیم؛
</div>


$$
\text{H} = \left\{H_{(1)}, H_{(2)}, ..., H_{(m)}\right\}, 
$$
<div dir = "rtl", style = "color: black; font-size: 18px; font-family: B Nazanin;">
فرض‌های صفر متناظر با آزمون‌های چند‌گانه با مقادیر <bdi>p<sub>value</sub></bdi>&nbsp; برآورد شده به شرح زیر باشد؛
<br>
<p style = "color: red">
<b>
مقادیر مرتب شده هست.
</b>
</p>
</div>

$$
p_{(1)}, p_{(2)}, ..., p_{(m)}
$$


<div dir = "rtl", style = "color: black; font-size: 18px; font-family: B Nazanin;">
آن‌گاه
</div>




$$
k = \max\left\{i:\quad p_{(i)} \leq \frac{i}{m}\tilde{\alpha}\right\}, \quad \tilde{\alpha} = \frac{\alpha_{(Initial)}}{\sum_{i = 1}^m \frac{1}{i}}
$$



<div dir = "rtl", style = "color: black; font-size: 18px; font-family: B Nazanin;">
 منظور از <bdi>&alpha;<sub>Initial</sub></bdi>&nbsp; همان خطای نوع اولی هست که در ابتدا آزمون به آن اشاره می‌شود. و در معادله بالا اگر مقداری برای <bdi>k</bdi> به دست نیاید تمام فرض‌های اولیه پذیرفته می‌شوند. و اگر مقدار برای </bdi>k</bdi> به دست بیاید، فرض های 
</div>

$$
\left\{H_1, \dots, H_k\right\}
$$

<div dir = "rtl", style = "color: black; font-size: 18px; font-family: B Nazanin;">
 رد می شود، همان‌طور که مشاهده می کنیم این روش به نسبت دارای محاسبات کمتری و همچنین محافظه‌کارانه‌تر از روش قبلی می‌باشد. 
</div>

```{python}
#| warning: false
#| message: false
#| echo: true
import statsmodels.stats.multitest as stest 
pVal = [0.0001, 0.001, .01, 0.1, 0.08, 0.09, 0.15, 0.21, 0.35, 0.55, 0.3, 
0.64, 0.77, 0.9, 0.03, 0.02, 0.09, 0.19, 0.21, 0.41]
res = stest.multipletests(pVal, alpha = 0.05, method = "fdr_by")
# python Result
print(res)
```
<hr/>


```{r}
#| echo: true
#| warning: false
#| message: false
# R Result
p.adjust(c(0.0001, 0.001, .01, 0.1, 0.08, 0.09, 0.15, 0.21, 0.35, 0.55, 0.3, 
0.64, 0.77, 0.9, 0.03, 0.02, 0.09, 0.19, 0.21, 0.41), method = "BY")
```



<br><br>

## False Discovery Rate (FDR) Method for correcting type 1 error in multiple tests
<div dir = "rtl", style = "color: black; font-size: 18px; font-family: B Nazanin;">
<h4 style = "color: blue;">
روش <bdi>FDR</bdi>&nbsp; برای تصحیح خطای  نوع اول در آزمون‌های چند‌گانه
</h4>
این روش در حقیقت ساده‌تر از دو روش قبلی هست، دراین‌جا هم ما مقادیر <bdi>p<sub>value</sub></bdi>&nbsp; را از کوچک به بزرگ مرتب می‌کنیم
</div>

$$
q_{(1)}, \dots, q_{(m)}
$$
<bdi><b><span style = "font-family: courier new;"> p.adjust </span></bdi></b>&nbsp;
اگر مانند قبل فرض‌‌های صفر متناظر با مقادیر <bdi>p<sub>value</sub></bdi>&nbsp; ذکر شده در بالا، عبارت باشد از
</div>


$$
\text{H} = \left\{H_{(1)}, H_{(2)}, ..., H_{(m)}\right\}, 
$$

<div dir = "rtl", style = "color: black; font-size: 18px; font-family: B Nazanin;">
برای برآورد <bdi>p<sub>value</sub></bdi>&nbsp; اصلاح شده به شکل زیر عمل می‌کنیم؛
</div>

$$
p_{(i)}^{(FDR)} = \frac{m}{i} \times p_{(i)} \implies \text{if}~~~ p_{(i)}^{(FDR)} \leq \alpha_{Initial} ~~ \text{Reject}~H_i
$$

<div dir = "rtl", style = "color: black; font-size: 18px; font-family: B Nazanin;">
که در این‌جا مقدار <bdi>m</bdi> اشاره به تعداد مقایسه‌های چند‌گانه‌ای هست که می‌خواهیم انجام دهیم. 
<br><br>
مثال: 
</div>
```{python}
#| warning: false
#| message: false
#| echo: true
import statsmodels.stats.multitest as stest 
pVal = [0.0001, 0.001, .01, 0.1, 0.08, 0.09, 0.15, 0.21, 0.35, 0.55, 0.3, 
0.64, 0.77, 0.9, 0.03, 0.02, 0.09, 0.19, 0.21, 0.41]
res = stest.fdrcorrection(pVal, alpha = 0.05, method = "indep")
# python Result
print(res)
```
<hr/>


```{r}
#| echo: true
#| warning: false
#| message: false
# R Result
p.adjust(c(0.0001, 0.001, .01, 0.1, 0.08, 0.09, 0.15, 0.21, 0.35, 0.55, 0.3, 
0.64, 0.77, 0.9, 0.03, 0.02, 0.09, 0.19, 0.21, 0.41), method = "fdr")
```
<br>
<div dir = "rtl", style = "color: black; font-size: 18px; font-family: B Nazanin;">
تابع <bdi><b><span style = "font-family: courier new;">statsmodels.stats.multitest.fdrcorrection</span></b></bdi>&nbsp;  در حقیقت یک ابزار دیگر پایتون برای پیاده‌سازی همان  دو روش قبلی <bdi>(BH, BY)</bdi>&nbsp; هست؛ این تابع 
برای آرگومان <bdi>method</bdi> پنج‌تا مقدار می تواند بگیرد که هر کدام اشاره یا به روش <bdi>BH</bdi>&nbsp; دارد یا روش <bdi>BY</bdi>&nbsp; و همان‌طور که می‌بینیم خروجی روش <bdi>fdr</bdi>&nbsp; در <bdi>R</bdi>  نتیجه پیاده‌سازی روش <bdi>BH</bdi>&nbsp; را دارد، در حقیقت وجود <bdi>fdr</bdi>&nbsp; به عنوان یک آرگومان ضرورتی ندارد. البته برای روش‌های مستقر شده بر‌روی مفهوم <bdi>FDR</bdi>&nbsp; تیب‌شیرانی نیز روش‌هایی مبتنی بر <bdi>BH, BY</bdi>&nbsp; ارائه داده هست که از طریق بسته <bdi>statsmodels</bdi>&nbsp; قابل دسترس هستند. برای جزئیات آرگومان‌های تابع ذکر شده در <bdi>statsmodels</bdi>&nbsp; می‌توانید به این <a href = "https://www.statsmodels.org/dev/generated/statsmodels.stats.multitest.multipletests.html">لینک</a> مراجعه کنید. 
</div>
<br><br>

## PostHoc Tests With Adjusted P~value~
<div dir = "rtl", style = "color: black; font-size: 18px; font-family: B Nazanin;">
<h4 style = "color: blue;">
پیاده‌سازی آزمون‌های تعقیبی با مقادیر اصلاح شده <bdi>p<sub>value</sub></bdi>&nbsp;
</h4>
در این‌جا با استفاده از یک مجموعه داده ساده یعنی همان داده‌های <bdi>Iris</bdi>&nbsp; پیاده‌سازی متدهای ذکر شده نشان خواهیم داد 
</div>


```{r}
#| fig-width: 7
#| fig-height: 7
#| echo: true
#| warning: false
#| message: false
## for use iris data in python 
library(reticulate)
pathh <- Sys.which("python") |>
            gsub("\\", "//", x = _,  fixed = TRUE)
use_python(pathh)
```
<hr/>
```{python}
## use python 
import statsmodels.formula.api as sfa
import scikit_posthocs as sp
dat = r.iris.copy()
dat.columns = dat.columns.str.replace(".", "")
print(dat.head(10))
```

```{python}
## pairwise comparison use ttest 
sp.posthoc_ttest(dat, val_col = 'SepalWidth', group_col = 'Species', 
p_adjust = "bonferroni").round(4)
"""p_adjust: 
    bonferroni : one-step correction
    sidak : one-step correction
    holm-sidak : step down method using Sidak adjustments
    holm : step-down method using Bonferroni adjustments
    simes-hochberg : step-up method (independent)
    hommel : closed method based on Simes tests (non-negative)
    fdr_bh : Benjamini/Hochberg (non-negative)
    fdr_by : Benjamini/Yekutieli (negative)
    fdr_tsbh : two stage fdr correction (non-negative)
    fdr_tsbky : two stage fdr correction (non-negative)
"""
## NonParametric pairwise test----
sp.posthoc_mannwhitney(a = dat, val_col = 'SepalWidth', group_col = "Species", 
p_adjust = "fdr_by").round(4)
```
<hr/>
```{r}
## R: pairwise Ttest
pairwise.t.test(x = iris$Sepal.Width, g = iris$Species, 
p.adjust.method = "bonferroni", pool.sd = F) |> 
_$p.value |> 
round(4)

## R: pairwise wilcoxon test
pairwise.wilcox.test(x = iris$Sepal.Width, g = iris$Species, 
p.adjust.method = "BY") |>
_$p.value |>
round(4)
```
<div dir = "rtl", style = "color: black; font-size: 18px; font-family: B Nazanin;">
واضح هست که نتایج گزارش شده برای هر دو زبان یکسان هست. 
</div>
<hr/><hr/>
<br><br>

## References
<div dir = "rtl", style = "color: black; font-size: 18px; font-family: B Nazanin;">
<h4 style = "color: blue;">
منابع
</div>
1. Hsu JC. Multiple comparisons: theory and methods. London: Chapman & Hall: CRC Press, 1996. [[Google Scholar](https://scholar.google.com/scholar_lookup?journal=Stat+Methods+Med+Res&title=A+review+of+modern+multiple+hypothesis+testing,+with+particular+attention+to+the+false+discovery+proportion.&author=A.+Farcomeni&volume=17&publication_year=2008&pages=347-88&pmid=17698936&doi=10.1177/0962280206079046&)]
2. Bender R, Lange S. Adjusting for multiple testing—when and how? J Clin Epidemiol 2001;54:343-9. 10.1016/S0895-4356(00)00314-0 [[Google Scholar](https://scholar.google.com/scholar_lookup?journal=J+Clin+Epidemiol&title=Adjusting+for+multiple+testing%E2%80%94when+and+how?&author=R+Bender&author=S+Lange&volume=54&publication_year=2001&pages=343-9&pmid=11297884&doi=10.1016/S0895-4356(00)00314-0&)]
3. Thiese MS, Ronna B, Ott U. P value interpretations and considerations. J Thorac Dis 2016;8:E928-E931. 10.21037/jtd.2016.08.16 [[Google Scholar](https://scholar.google.com/scholar_lookup?journal=J+Thorac+Dis&title=P+value+interpretations+and+considerations.&author=MS+Thiese&author=B+Ronna&author=U+Ott&volume=8&publication_year=2016&pages=E928-E931&pmid=27747028&doi=10.21037/jtd.2016.08.16&)]
4. Farcomeni A. A review of modern multiple hypothesis testing, with particular attention to the false discovery proportion. Stat Methods Med Res 2008;17:347-88. 10.1177/0962280206079046 [[Google Scholar](https://scholar.google.com/scholar_lookup?journal=Stat+Methods+Med+Res&title=A+review+of+modern+multiple+hypothesis+testing,+with+particular+attention+to+the+false+discovery+proportion.&author=A.+Farcomeni&volume=17&publication_year=2008&pages=347-88&pmid=17698936&doi=10.1177/0962280206079046&)]
5. Bland JM, Altman DG. Multiple significance tests: the Bonferroni method. BMJ 1995;310:170. 10.1136/bmj.310.6973.170 [[Google Scholar](https://scholar.google.com/scholar_lookup?journal=BMJ&title=Multiple+significance+tests:+the+Bonferroni+method.&author=JM+Bland&author=DG+Altman&volume=310&publication_year=1995&pages=170&pmid=7833759&doi=10.1136/bmj.310.6973.170&)]
6. Holm M. A simple sequentially rejective multiple test procedure. Scand J Statist 1979;6:65-70. [[Google Scholar](https://scholar.google.com/scholar_lookup?journal=Scand+J+Statist&title=A+simple+sequentially+rejective+multiple+test+procedure.&author=M.+Holm&volume=6&publication_year=1979&pages=65-70&)]
7. Hochberg Y. A sharper Bonferroni procedure for multiple tests of significance. Biometrika 1988;75:800-2. 10.1093/biomet/75.4.800 [[Google Scholar](https://scholar.google.com/scholar_lookup?journal=Biometrika&title=A+sharper+Bonferroni+procedure+for+multiple+tests+of+significance.&author=Y.+Hochberg&volume=75&publication_year=1988&pages=800-2&doi=10.1093/biomet/75.4.800&)]
8. Simes RJ. An improved Bonferroni procedure for multiple tests of significance. Biometrika 1986;73:751-4. 10.1093/biomet/73.3.751 [[Google Scholar](https://scholar.google.com/scholar_lookup?journal=Biometrika&title=An+improved+Bonferroni+procedure+for+multiple+tests+of+significance.&author=RJ+Simes&volume=73&publication_year=1986&pages=751-4&doi=10.1093/biomet/73.3.751&)]
9. Hommel G. A stagewise rejective multiple test procedure based on a modified Bonferroni test. Biometrika 1988;75:383-6. 10.1093/biomet/75.2.383 [[Google Scholar](https://scholar.google.com/scholar_lookup?journal=Biometrika&title=A+stagewise+rejective+multiple+test+procedure+based+on+a+modified+Bonferroni+test.&author=G.+Hommel&volume=75&publication_year=1988&pages=383-6&doi=10.1093/biomet/75.2.383&)]
10. Benjamini Y, Hochberg Y. Controlling the false discovery rate: a practical and powerful approach to multiple testing. J R Stat Soc Series B Stat Methodol 1995;57:289-300. [[Google Scholar](https://scholar.google.com/scholar_lookup?journal=J+R+Stat+Soc+Series+B+Stat+Methodol&title=Controlling+the+false+discovery+rate:+a+practical+and+powerful+approach+to+multiple+testing.&author=Y+Benjamini&author=Y+Hochberg&volume=57&publication_year=1995&pages=289-300&)]
11. Benjamini Y, Yekutieli D. The control of the false discovery rate in multiple testing under dependency. Ann Stat 2001;29:1165-88. [[Google Scholar](https://scholar.google.com/scholar_lookup?journal=Ann+Stat&title=The+control+of+the+false+discovery+rate+in+multiple+testing+under+dependency.&author=Y+Benjamini&author=D+Yekutieli&volume=29&publication_year=2001&pages=1165-88&)]
