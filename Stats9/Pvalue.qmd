---
title: ""
---

## Calculating p~value~ for multiple comparisons in one-way ANOVA


<div dir = "rtl", style = "color: black; font-size: 25px; font-family: B Nazanin;">

<h1>
محاسبه <bdi>p<sub>value</sub></bdi>&nbsp; برای مقایسه‌های چند گانه در آنالیز واریانس یک‌طرفه
</h1>
<br><br> 

داده‌های موجود و البته مخصوصا داده‌های زیستی امروزه در مقیاس وسیعی تولید می شود. این امر جدا از آن‌که منجر به ذخیره انبوهی از داده‌های خام شده هست، بلکه باعث شکل‌گیری آزمون‌های فرضیه مختلفی نیز بوده هست. برای آزمایش این فرضیه‌ها، روش‌هایی از آمار استنباطی بر‌روی مجموعه‌ داده‌ها اِعمال می‌شود که منجر به بینش‌های زیستی بیشتر (برای داده‌های زیستی) و اصولا بینش عمیق‌تر در مورد داده‌ها می‌شود. اساسا، آزمون فرضیه یک روش آماری هست که احتمال موافق بودن داده‌ها را که بر‌اساس یک نمونه‌گیری تصادفی جمع‌آوری شده‌اند را با فرضیه صفر (یا مخالف فرضیه صفر) محاسبه می‌کند و نتایج این محاسبات در یک عدد خاص با نماد <bdi>p<sub>value</sub></bdi>&nbsp; خلاصه می‌شود. من در این بخش دوست دارم قبل از آن‌که در مورد تصحیح <bdi>p<sub>value</sub></bdi>&nbsp;  برای مقایسه‌های چند‌گانه صحبت کنم، در مورد خود آن صحبت کنم. 
<br>
<h2> 
<bdi> p<sub>value</sub></bdi>&nbsp;  چیست؟
</h2>

هنگامی که می‌خواهید به صورت آماری استنباط کنید که آیا نتیجه آزمون آماری قابل توجه هست یا خیر، با توجه به فرضیه صفر، احتمال شکل‌گیری نتیجه را با وضعیتی که در آن همه چیز کاملا تصادفی باشد البته با فرض درستی فرض صفر، مقایسه می‌کنید. یک مقدار یا برشی که به عنوان مرز تصمیم گیری که البته هم بر‌اساس روابط تکنیکی ریاضی و هم تاریخی بر‌روی آن اتفاق نظر وجود دارد (البته با توجه زمینه تحقیق) مقدار خطای نوع یا <bdi>&alpha;</bdi>&nbsp; که برابر با <bdi>0.5</bdi>&nbsp;  در نظر گرفته می‌شود. بر این اساس، (با فرض آزمون مقایسه میانگین چند گروه (سطح) هست) اگر احتمال فرضیه صفر برابری میانگین سطوح باشد یعنی <bdi> &mu;<sub>1</sub> == &mu;<sub>2</sub> == … &mu;<sub>k</sub></bdi>&nbsp;   اگر مقدار <bdi>p<sub>value</sub></bdi>&nbsp; به‌دست آمده کمتر از نقطه برش انتخاب شده یا همان <bdi>&alpha;</bdi>&nbsp; باشد فرض صفر رد می‌شود و در غیر این صورت فرض صفر تأیید می‌شود. البته باید اضافه شود که در آزمون‌های آماری صرف بیان کردن مقدار <bdi>p<sub>value</sub></bdi>&nbsp; کفایت نمی‌کند. و باید علاوه بر این مقدار کمیت‌هایی مانند فواصل اطمینان، توان آزمون و یا اندازه اثر نیز گزارش شود. 
<br>
<h2>
مشکلات <bdi>p<sub>value</sub></bdi>&nbsp; 
</h2>

حقیقت این هست که بحث جدل زیادی پیرامون موقعیت و اهمیت <bdi>p<sub>value</sub></bdi>&nbsp; در محافل علمی وجود دارد. و این موضوع با ظهور کلان‌داده‌ها که عمدتا حول سوء تفاهم و همچنین استفاده نادرست از <bdi>p<sub>value</sub></bdi>&nbsp; می‌شود افزونی یافته هست. اولین ایرادی که وارد می‌کنند این هست که نقاط برش انتخاب شده یعنی <bdi> &alpha; = 0.1, 0.05, 0.001, ...</bdi>&nbsp; کاملا دلخواه هستند و صرفا بر‌اساس یک قرار‌داد شکل گرفته‌اند. و این واقعیت مولد آن هست که این مقدار لزوما برای هر زمینه‌ مطالعاتی مناسب نیست و به عنوان مثال برای بعضی از کارآزمایی‌های بالینی حتی مقدار <bdi>&alpha; = 0.001</bdi>&nbsp; پیشنهاد می‌شود. علاوه بر‌این، دو تَوَرّش (سوگیری) رایج که به یک‌پارچگی یافته‌های تحقیق اثر می‌گذارد، یکی گزارش‌های انتخابی یا با عنوان انگلیسی <bdi>Selective Reporting</bdi>&nbsp; و دیگری با اصطلاح <bdi>P-Hacking</bdi>&nbsp; شناخته می‌شود، می‌باشد. به‌طور خلاصه گزارش‌ دهی انتخابی به گرایش به سمت گزارش کردن صرفا مقادیر معنادار یعنی زمانی که <bdi>p<sub>value</sub></bdi>&nbsp; از مقدار نقطه برش کمتر هست توجه دارد، که در یک بررسی مشخص شد این اریبی به سمت نتایج معنادار گزارش شده می‌باشد. که در متا‌آنالیز با عنوان اریبی انتشار از آن یاد می‌شود. در مقابل، اصطلاح <bdi>P-Hacking</bdi>&nbsp;  اشاره به نمونه‌‌گیری‌های غیر تصادفی و یا دستکاری عمدی داده‌ها دارد. 
<br>
<h2>
مسئله مقایسه‌های چند‌گانه
</h2>

با فرض این‌که تمام ایرادات مطرح شده برطرف شده یا نادیده گرفته شوند، آخرین و اما مهم‌ترین مسئله‌ای که در کمی سازی مقدار <bdi>p<sub>value</sub></bdi>&nbsp; باقی می‌ماند، زمانی هست که یک آزمون چند‌گانه روی می‌دهد، اما آزمون چند‌گانه چه مفهومی می‌تواند داشته باشد؟ وضعیتی را تصور کنید که می‌خواهیم تأثیر چند نوع کود را بر‌روی میزان محصولات برداشت با هم مقایسه کنیم، که البته تعداد انواع کود بیشتر از ۲ هست و همچنین با فرض یکسان بودن سایر شرایط، مانند نوع خاک، وسعت زمین، نوع آبیاری و …<br>
و بخواهیم این مقایسه‌ها را به صورت دو‌به‌دو انجام دهیم، یعنی ابتدا کود نوع ۱ را با نوع ۲ و سپس با نوع ۳والی آخر  یعنی به شکل زیر:‌
</div>

$$
\begin{aligned}
& \text{Test}_1: ~ \begin{cases}H_0: & \mu_A = \mu_B\\ H_1: & \mu_A\ne \mu_B \end{cases}\\
& \text{Test}_2: ~ \begin{cases}H_0: & \mu_A = \mu_C\\ H_1: & \mu_A\ne \mu_B \end{cases}\\
& \text{Test}_3: ~ \begin{cases}H_0: & \mu_A = \mu_D\\ H_1: & \mu_A\ne \mu_B \end{cases}\\
& \text{Test}_4: ~ \begin{cases}H_0: & \mu_B = \mu_C\\ H_1: & \mu_A\ne \mu_B \end{cases}\\
& \text{Test}_5: ~ \begin{cases}H_0: & \mu_B = \mu_D\\ H_1: & \mu_A\ne \mu_B \end{cases}\\
& \text{Test}_6: ~ \begin{cases}H_0: & \mu_C = \mu_D\\ H_1: & \mu_A\ne \mu_B \end{cases}\\
\end{aligned}
$$
<br>

<div dir = "rtl", style = "color: black; font-size: 25px; font-family: B Nazanin;">
واضح هست که حروف <bdi>A, B, C, D</bdi>&nbsp; اشاره به نوع کودها دارد، همان‌طور که می بینیم وقتی انواع کود دارای ۴ سطح هست، ما ۶ مقایسه دو به دو خواهیم داشت که ترکیب ۲ از ۴ هست که جواب همان ۶ هست. <br>
حالا اگر خطای نوع اول یا همان <bdi> &alpha; = 0.05</bdi>&nbsp; در نظر بگیریم و برای هر ۶ مقایسه همزمان خطای نوع اول را پنج صدم در نظر بگیریم با وضعیت زیر مواجه خواهیم شد: 
</div>

<br>

```{r}
#| warning: false
#| message: false
#| echo: false

a_single <- 0.05
n <- 6
p_single <- 1 - a_single
p_m = p_single ** n
a_m <- 1 - p_m 
p_m2 <- (1 - a_single)**50
```


$$
\alpha_{Test_1} = \alpha_{Test_2} = \cdots = \alpha_{Test_6} = 0.05\implies
$$


<div dir = "rtl", style = "color: black; font-size: 25px; font-family: B Nazanin;">

خطای نوع اول یعنی امکان مشاهده وضعیتی که فرض <bdi>H<sub>0</sub></bdi>&nbsp; را رد کنیم در صورتی که این فرض درست باشد،‌ پس احتمال این‌که فرض <bdi>H<sub>0</sub></bdi>&nbsp; را رد نکنیم در صورتی که این فرض درست باشد می‌شود <bdi> 1 - &alpha; </bdi>&nbsp; ولی این مقادیر برای یک آزمون صدق می‌کند، ولی اگه بخواهیم احتمال این‌ را بسنجیم در صورتی برابری تمام میانگین سطوح‌ها ما فرض <bdi>H<sub>0</sub></bdi>&nbsp; را برای هیچ‌کدام از آزمون‌ها  رد نکنیم باید به این شکل آن را محاسبه کنیم

</div>

$$
\begin{aligned}
& \alpha_{Single} = 0.05 \implies P_{single} = 1 - \alpha_{single} = 1 - 0.05 = 0.95\\
& \implies P_{multiple} = P_{single} ^ 6 = `r p_m` \implies \\
& \alpha_{multiple} = 1 - P_{multiple} = `r (1-p_m)`
\end{aligned}
$$

<div dir = "rtl", style = "color: black; font-size: 25px; font-family: B Nazanin;">

همان‌طور که مشاهده می‌کنیم، خطا نوع اول برای مقایسه‌های همزمان به شدت تورم پیدا کرده هست و اگر تعداد مقایسه‌ها افزایش پیدا کند یعنی اگر ما فرضا ۵۰ تا مقایسه همزمان داشته باشیم و خطای نوع اول را را برای همه ۵۰ تا مقایسه پنج‌صدم در نظر بگیریم، آن‌گاه خطای نوع اول آزمون‌های چند‌گانه با توجه به روابطی که بالا آوردیم می‌شود:‌

</div>

$$
\alpha_{multiple} = 1 - P_{multiple} = 1 - (1 - 0.05)^{50} =  `r (1 - p_m2)`
$$

<div dir = "rtl", style = "color: black; font-size: 25px; font-family: B Nazanin;">
واضح هست که در صورت افزایش مقایسه‌های چند‌گانه خطای نوع اول چند‌گانه به یک هم خواهد رسید. <br>
سؤالی که این‌جا شکل می‌گیرد این هست که چگونه باید جلوی رشد نرخ خطای نوع اول برای مقایسه‌های چند‌گانه گرفته شود؟
<br> 
اولین جوابی که به این سؤال میشه داد، کاهش خطای نوع اول هست. یا در واقع کاهش <bdi>Threshold</bdi>&nbsp; یا آن آستانه‌ای که در صورتی که <bdi>p<sub>value</sub></bdi>&nbsp; از آن کمتر شود فرض اولیه رد می‌شود. این رویکرد باعث جوابی می شود که بونفرونی به این مسئله داد. در ادامه روش‌ها گوناگون تصحیح خطای نوع اول و یا مقدار <bdi>p<sub>value</sub></bdi>&nbsp; بیان خواهد شد. 
<br>

<h2>
روش بونفرونی برای تصحیح خطای  نوع اول در آزمون‌های چند‌گانه
</h2>


</div>