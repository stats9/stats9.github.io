[
  {
    "objectID": "Pvalue.html",
    "href": "Pvalue.html",
    "title": "",
    "section": "",
    "text": "داده‌های موجود و البته مخصوصا داده‌های زیستی امروزه در مقیاس وسیعی تولید می شود. این امر جدا از آن‌که منجر به ذخیره انبوهی از داده‌های خام شده هست، بلکه باعث شکل‌گیری آزمون‌های فرضیه مختلفی نیز بوده هست. برای آزمایش این فرضیه‌ها، روش‌هایی از آمار استنباطی بر‌روی مجموعه‌ داده‌ها اِعمال می‌شود که منجر به بینش‌های زیستی بیشتر (برای داده‌های زیستی) و اصولا بینش عمیق‌تر در مورد داده‌ها می‌شود. اساسا، آزمون فرضیه یک روش آماری هست که احتمال موافق بودن داده‌ها را که بر‌اساس یک نمونه‌گیری تصادفی جمع‌آوری شده‌اند را با فرضیه صفر (یا مخالف فرضیه صفر) محاسبه می‌کند و نتایج این محاسبات در یک عدد خاص با نماد pvalue  خلاصه می‌شود. من در این بخش دوست دارم قبل از آن‌که در مورد تصحیح pvalue   برای مقایسه‌های چند‌گانه صحبت کنم، در مورد خود آن صحبت کنم. \n\n \n pvalue   چیست؟\n\n\nهنگامی که می‌خواهید به صورت آماری استنباط کنید که آیا نتیجه آزمون آماری قابل توجه هست یا خیر، با توجه به فرضیه صفر، احتمال شکل‌گیری نتیجه را با وضعیتی که در آن همه چیز کاملا تصادفی باشد البته با فرض درستی فرض صفر، مقایسه می‌کنید. یک مقدار یا برشی که به عنوان مرز تصمیم گیری که البته هم بر‌اساس روابط تکنیکی ریاضی و هم تاریخی بر‌روی آن اتفاق نظر وجود دارد (البته با توجه زمینه تحقیق) مقدار خطای نوع یا α  که برابر با 0.5   در نظر گرفته می‌شود. بر این اساس، (با فرض آزمون مقایسه میانگین چند گروه (سطح) هست) اگر احتمال فرضیه صفر برابری میانگین سطوح باشد یعنی  μ1 == μ2 == … μk    اگر مقدار pvalue  به‌دست آمده کمتر از نقطه برش انتخاب شده یا همان α  باشد فرض صفر رد می‌شود و در غیر این صورت فرض صفر تأیید می‌شود. البته باید اضافه شود که در آزمون‌های آماری صرف بیان کردن مقدار pvalue  کفایت نمی‌کند. و باید علاوه بر این مقدار کمیت‌هایی مانند فواصل اطمینان، توان آزمون و یا اندازه اثر نیز گزارش شود. \n\n\nمشکلات pvalue  \n\n\nحقیقت این هست که بحث جدل زیادی پیرامون موقعیت و اهمیت pvalue  در محافل علمی وجود دارد. و این موضوع با ظهور کلان‌داده‌ها که عمدتا حول سوء تفاهم و همچنین استفاده نادرست از pvalue  می‌شود افزونی یافته هست. اولین ایرادی که وارد می‌کنند این هست که نقاط برش انتخاب شده یعنی  α = 0.1, 0.05, 0.001, ...  کاملا دلخواه هستند و صرفا بر‌اساس یک قرار‌داد شکل گرفته‌اند. و این واقعیت مولد آن هست که این مقدار لزوما برای هر زمینه‌ مطالعاتی مناسب نیست و به عنوان مثال برای بعضی از کارآزمایی‌های بالینی حتی مقدار α = 0.001  پیشنهاد می‌شود. علاوه بر‌این، دو تَوَرّش (سوگیری) رایج که به یک‌پارچگی یافته‌های تحقیق اثر می‌گذارد، یکی گزارش‌های انتخابی یا با عنوان انگلیسی Selective Reporting  و دیگری با اصطلاح P-Hacking  شناخته می‌شود، می‌باشد. به‌طور خلاصه گزارش‌ دهی انتخابی به گرایش به سمت گزارش کردن صرفا مقادیر معنادار یعنی زمانی که pvalue  از مقدار نقطه برش کمتر هست توجه دارد، که در یک بررسی مشخص شد این اریبی به سمت نتایج معنادار گزارش شده می‌باشد. که در متا‌آنالیز با عنوان اریبی انتشار از آن یاد می‌شود. در مقابل، اصطلاح P-Hacking   اشاره به نمونه‌‌گیری‌های غیر تصادفی و یا دستکاری عمدی داده‌ها دارد. \n\n\nمسئله مقایسه‌های چند‌گانه\n\n\nبا فرض این‌که تمام ایرادات مطرح شده برطرف شده یا نادیده گرفته شوند، آخرین و اما مهم‌ترین مسئله‌ای که در کمی سازی مقدار pvalue  باقی می‌ماند، زمانی هست که یک آزمون چند‌گانه روی می‌دهد، اما آزمون چند‌گانه چه مفهومی می‌تواند داشته باشد؟ وضعیتی را تصور کنید که می‌خواهیم تأثیر چند نوع کود را بر‌روی میزان محصولات برداشت با هم مقایسه کنیم، که البته تعداد انواع کود بیشتر از ۲ هست و همچنین با فرض یکسان بودن سایر شرایط، مانند نوع خاک، وسعت زمین، نوع آبیاری و …\nو بخواهیم این مقایسه‌ها را به صورت دو‌به‌دو انجام دهیم، یعنی ابتدا کود نوع ۱ را با نوع ۲ و سپس با نوع ۳والی آخر  یعنی به شکل زیر:‌\n\n\\[\n\\begin{aligned}\n& \\text{Test}_1: ~ \\begin{cases}H_0: & \\mu_A = \\mu_B\\\\ H_1: & \\mu_A\\ne \\mu_B \\end{cases}\\\\\n& \\text{Test}_2: ~ \\begin{cases}H_0: & \\mu_A = \\mu_C\\\\ H_1: & \\mu_A\\ne \\mu_B \\end{cases}\\\\\n& \\text{Test}_3: ~ \\begin{cases}H_0: & \\mu_A = \\mu_D\\\\ H_1: & \\mu_A\\ne \\mu_B \\end{cases}\\\\\n& \\text{Test}_4: ~ \\begin{cases}H_0: & \\mu_B = \\mu_C\\\\ H_1: & \\mu_A\\ne \\mu_B \\end{cases}\\\\\n& \\text{Test}_5: ~ \\begin{cases}H_0: & \\mu_B = \\mu_D\\\\ H_1: & \\mu_A\\ne \\mu_B \\end{cases}\\\\\n& \\text{Test}_6: ~ \\begin{cases}H_0: & \\mu_C = \\mu_D\\\\ H_1: & \\mu_A\\ne \\mu_B \\end{cases}\\\\\n\\end{aligned}\n\\] \n\nواضح هست که حروف A, B, C, D  اشاره به نوع کودها دارد، همان‌طور که می بینیم وقتی انواع کود دارای ۴ سطح هست، ما ۶ مقایسه دو به دو خواهیم داشت که ترکیب ۲ از ۴ هست که جواب همان ۶ هست. \nحالا اگر خطای نوع اول یا همان  α = 0.05  در نظر بگیریم و برای هر ۶ مقایسه همزمان خطای نوع اول را پنج صدم در نظر بگیریم با وضعیت زیر مواجه خواهیم شد: \n\n\n\\[\n\\alpha_{Test_1} = \\alpha_{Test_2} = \\cdots = \\alpha_{Test_6} = 0.05\\implies\n\\]\n\n\nخطای نوع اول یعنی امکان مشاهده وضعیتی که فرض H0  را رد کنیم در صورتی که این فرض درست باشد،‌ پس احتمال این‌که فرض H0  را رد نکنیم در صورتی که این فرض درست باشد می‌شود  1 - α   ولی این مقادیر برای یک آزمون صدق می‌کند، ولی اگه بخواهیم احتمال این‌ را بسنجیم در صورتی برابری تمام میانگین سطوح‌ها ما فرض H0  را برای هیچ‌کدام از آزمون‌ها  رد نکنیم باید به این شکل آن را محاسبه کنیم\n\n\n\\[\n\\begin{aligned}\n& \\alpha_{Single} = 0.05 \\implies P_{single} = 1 - \\alpha_{single} = 1 - 0.05 = 0.95\\\\\n& \\implies P_{multiple} = P_{single} ^ 6 = 0.7350919 \\implies \\\\\n& \\alpha_{multiple} = 1 - P_{multiple} = 0.2649081\n\\end{aligned}\n\\]\n\n\nهمان‌طور که مشاهده می‌کنیم، خطا نوع اول برای مقایسه‌های همزمان به شدت تورم پیدا کرده هست و اگر تعداد مقایسه‌ها افزایش پیدا کند یعنی اگر ما فرضا ۵۰ تا مقایسه همزمان داشته باشیم و خطای نوع اول را را برای همه ۵۰ تا مقایسه پنج‌صدم در نظر بگیریم، آن‌گاه خطای نوع اول آزمون‌های چند‌گانه با توجه به روابطی که بالا آوردیم می‌شود:‌\n\n\n\\[\n\\alpha_{multiple} = 1 - P_{multiple} = 1 - (1 - 0.05)^{50} =  0.923055\n\\]\n\nواضح هست که در صورت افزایش مقایسه‌های چند‌گانه خطای نوع اول چند‌گانه به یک هم خواهد رسید. \nسؤالی که این‌جا شکل می‌گیرد این هست که چگونه باید جلوی رشد نرخ خطای نوع اول برای مقایسه‌های چند‌گانه گرفته شود؟\n \nاولین جوابی که به این سؤال میشه داد، کاهش خطای نوع اول هست. یا در واقع کاهش Threshold  یا آن آستانه‌ای که در صورتی که pvalue  از آن کمتر شود فرض اولیه رد می‌شود. این رویکرد باعث جوابی می شود که بونفرونی به این مسئله داد. در ادامه روش‌ها گوناگون تصحیح خطای نوع اول و یا مقدار pvalue  بیان خواهد شد. \n\n\n\nروش بونفرونی برای تصحیح خطای  نوع اول در آزمون‌های چند‌گانه\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "BlueSky.html",
    "href": "BlueSky.html",
    "title": "\nیک پروژه برای گسترش جامعه کاربری R\n",
    "section": "",
    "text": "یک پروژه برای گسترش جامعه کاربری R\n\n\n\nمن در این پروژه‌ قصد دارم  به صورت ارائه چند فایل ویدئویی، نرم‌افزار BlueSky را به تمام دوستانی که قصد استفاده از یک نرم‌افزار ساده و منویی جهت انجام تحلیل‌های آماری هستند، آموزش دهم. دلیل اصلی این موضوع بر‌میگردد به این‌که اصولا این نرم‌افزار بر‌روی بستر زبان‌برنامه نویسی R پیاده‌سازی شده هست و همچنین رایگان می‌باشد. پس می‌توانیم به واسطه این نرم‌افزار از قدرت R در تحلیل داده‌ها و البته به شکل خیلی راحت‌تری استفاده کنیم. با توجه به این‌که اکثر جامعه‌ی علمی کشور در تحلیل داده‌ها به سوی SPSS گرایش دارند، که ذکر دلایل آن خارج از این نوشتار هست، باید توجه داشت که نرم‌افزار SPSS یک نرم‌افزار رایگان نیست، و آخرین ورژن قفل شکسته آن که به راحتی قابل نصب باشد ورژن ۲۶ می‌باشد. در حال حاضر ورژن ۲۹ این نرم‌افزار منتشر شده هست. با توجه به‌اینکه ویژگی‌های خیلی زیادی به ورژن‌های جدید نرم‌افزار SPSS افزوده شده هست که متأسفانه در دسترس ما نیست. چرا که نصب ورژن‌های اورجینال این نرم‌افزار مبالغ زیادی را می‌طلبد. \n\nنرم‌افزار BlueSky یک  جایگزین شایسته برای   SPSSمی باشد، با این‌نرم‌افزار می‌توان هم از قدرت برنامه‌نویسی R استفاده کرد و هم به شکل بسیار چشم نوازی منوی‌های توانای نرم‌افزار ما را تا حد خیلی زیادی از کد نویسی به دور نگه خواهد داشت و همچنین با آپدیت‌های به موقع از آخرین روش‌های نرم‌افزاری در تحلیل داده بهره‌مند خواهیم بود. \n\nمن جلسات مربوط به آموزش را در قالب ۳۲ جلسه تهیه کرده‌ام. متأسفانه فایل‌ها به صورت حرفه‌ای ضبط نشده هست ولی تلاش شده هست که اطلاعات نسبتا جامعی درباره این نرم‌افزار در اختیار شما عزیزان قرار گیرد. قطعا بعضی ویدئو‌ها نسبتا که نه، اکثر ویدئو‌ها حجم زمانی بالایی دارند که برای ویدئوهای آموزشی، این یک ویژگی منفی هست. با همه این اوصاف باید اضافه کنم که تهیه این ۳۲ ویدئو یک فرآیند آسان برای من نبوده هست.  البته علاوه بر‌ ویدئو‌ها به دلایلی که در ویدئو‌ها هم ذکر کرده‌ام، دو مبحث دیگر مربوط به برآورد pvalue برای آزمون‌ها چند‌گانه و همچنین شیوه محاسبه SS‌ها در تحلیل آنالیز واریانس نیز اضافه کرده‌ام، چون احساس کردم این مباحث می‌تواند مفید باشد و جای این مباحث در منابع فارسی را خالی دیدم. \n\n\n\n\n\n\nلینک‌های ویدئو‌ها\n\n\n\n\n\n\n\n\n لینک اول: نحوه نصب نرم‌افزار \n لینک دوم: یک مقدمه بر نرم‌افزار \nلینک سوم: نحوه ورود داده‌ها به نرم‌افزار. \nلینک چهارم: ترسیم نمودار StripPlot با نرم‌افزار. \nلینک پنجم: نمودار میله‌ای\n لینک ششم: نمودار جعبه‌ای \n لینک هفتم: نمودار کانتور پلات \n لینک هشتم: نمودار‌های بررسی توزیع (منحنی چگالی، نمودار چندک‌چندک و نمودار احتمال‌احتمال).\n لینک نهم:‌ نمودار HeatMap \nلینک دهم: نمودار LineChart\n لینک یازدهم: ترسیم Map و PieChart \nلینک دوازدهم: نمودار ScatterPlot و ViolinPlot\nلینک سیزدهم:‌ یک مقایسه با SPSS\n لینک چهاردهم: تولید داده تصادفی در نرم‌افزار BlueSky به‌همراه بررسی خوبی و برازندگی داده‌ها با یک توزیع خاص و آزمون نرمالیتی به همراه مقایسه با نرم‌افزار SPSS \nلینک پانزدهم: آزمون Ttest در BlueSky و SPSS به همراه Reshape کردن داده‌ها\nلینک شانزدهم: آنالیز واریانس، قسمت اول\nلینک هفدهم: آنالیز واریانس، قسمت دوم؛ به همراه مقایسه با نرم‌افزار SPSS\nلینک هجدهم: آنالیز کواریانس؛ به همراه مقایسه با نرم‌افزار SPSS\n لینک نوزدهم: آنالیز واریانس چند متغیره به همراه مقایسه با نرم‌افزار SPSS یا همان (MANOVA)\n لینک بیستم: تحلیل داده‌های با اندازه‌گیری مکرر (Repeated Measure Anova) به همراه مقایسه با نرم‌افزار SPSS قسمت اول\nلینک بیست و یکم: تحلیل داده‌‌های اندازه‌گیری مکرر (Repeated Measure Anova) و همچنین تغییر شکل داده‌ها از حالت Long به Wide  و برعکس به همراه مقایسه با نرم‌افزار SPSS، قسمت دوم\n لینک بیست و دوم: آزمون کای دو برای جداول توافقی و آزمون مک‌نمار قسمت اول \n لینک بیست و سوم: آزمون کای دو، مقایسه با نرم‌افزار SPSS  قسمت دوم\n لینک بیست و چهارم: آزمون کرسکال‌والیس و آزمون فریدمن به همراه مقایسه با نرم‌افزار SPSS\nلینک بیست و پنجم: آزمون ویلکاکسون به همراه مقایسه با نرم‌افزار SPSS\n لینک بیست و ششم: Compute Variables\n لینک بیست و هفتم: رگرسیون خطی با نرم‌‌افزار BlueSky Statistics\nلینک بیست و هشتم: رگرسیون لوجستیک و ترسیم نمودار ROC   برای رگرسیون لوجستیک به همراه  پیاده‌سازی آزمون Hosmer LemeShow و ماتریس آشتفتگی (Confusion Matrix) مدل\nلینک بیست و نهم: مقایسه مدل‌ها، پیاده‌سازی مدل های طبقه‌بندی و همچنین استفاده از شبکه‌های عصبی به همراه به دست آوردن مقادیر احتمال برآورد شده مدل‌ها و مقایسه نمودارهای ROC برای وقتی که متغیر پاسخ باینری هست. \n\nلینک سی‌ام: ماتریس همبستگی و آزمون همبستگی در BlueSky Statistics \nلینک سی‌ و یکم: فیلتر کردن داده‌ها در BlueSky Statistics \n\nلینک سی و دوم: تحلیل بقا در BlueSky Statistics، منحنی کاپلان-میر و رگرسیون کاکس \n\n\n\n\n\n\n\n\nمحاسبه pvalue  برای مقایسه‌های چند گانه در آنالیز واریانس یک‌طرفه\n\n \n\nداده‌های موجود و البته مخصوصا داده‌های زیستی امروزه در مقیاس وسیعی مورد استفاده قرار میگیرد. این امر جدا از آن‌که منجر به انبوهی از داده‌های خام شده هست، بلکه باعث شکل‌گیری آزمون‌های فرضیه مختلفی نیز شده هست. برای آزمایش این فرضیه‌ها، روش‌هایی از آمار استنباطی بر‌روی مجموعه‌ داده‌ها اِعمال می‌شود که منجر به بینش‌های زیستی بیشتر (برای داده‌های زیستی) و اصولا بینش عمیق‌تر در مورد داده‌ها می‌شود. اساسا، آزمون فرضیه یک روش آماری هست که احتمال موافق بودن داده‌ها را که بر‌اساس یک نمونه‌گیری تصادفی جمع‌آوری شده‌اند را با فرضیه صفر (یا مخالف فرضیه صفر) محاسبه می‌کنند و که نتایج این محاسبات در یک عدد خاص به نمام pvalue  خلاصه می‌شود. من در قسمت دوست دارم قبل از آن‌که در مورد تصحیح pvalue   برای مقایسه‌های چند‌گانه صحبت کنم، در مورد خود آن صحبت کنم. \n\n \n pvalue   چیست؟\n\n\nهنگامی که می‌خواهید به صورت آماری استنباط کنید که آیا نتیجه آزمون آماری قابل توجه هست یا خیر، با توجه به فرضیه صفر، احتمال شکل‌گیری نتیجه را با وضعیتی که در آن همه چیز کاملا تصادفی باشد البته با فرض درستی فرض صفر، مقایسه می‌کنید. یک مقدار یا برشی که به عنوان مرز تصمیم گیری که البته هم بر‌اساس روابط تکنیکی ریاضی و هم تاریخی بر‌روی آن اتفاق نظر وجود دارد (البته با توجه زمینه تحقیق) مقدار خطای نوع یا α  که برابر با 0.5   در نظر گرفته می‌شود. بر این اساس، (با فرض آزمون مقایسه میانگین چند گروه (سطح) هست) اگر احتمال فرضیه صفر برابری میانگین سطوح باشد یعنی  μ1 == μ2 == … μk    اگر مقدار pvalue  به‌دست آمده کمتر از نقطه برش انتخاب شده یا همان α  باشد فرض صفر رد می‌شود و در غیر این صورت فرض صفر تأیید می‌شود. البته باید اضافه شود که در آزمون‌های آماری صرف بیان کردن مقدار pvalue  کفایت نمی‌کند. و باید علاوه بر این مقدار کمیت‌هایی مانند فواصل اطمینان، توان آزمون و یا اندازه اثر نیز گزارش شود. \n\n\nمشکلات pvalue  \n\n\nحقیقت این هست که بحث جدل زیادی پیرامون موقعیت و اهمیت pvalue  در محافل علمی وجود دارد. و این موضوع با ظهور کلان‌داده‌ها که عمدتا حول سوء تفاهم و همچنین استفاده نادرست از pvalue  می‌شود افزونی یافته هست. اولین ایرادی که وارد می‌کنند این هست که نقاط برش انتخاب شده یعنی  α = 0.1, 0.05, 0.001, ...  کاملا دلخواه هستند و صرفا بر‌اساس یک قرار‌داد شکل گرفته‌اند. و این واقعیت مولد آن هست که این مقدار لزوما برای هر زمینه‌ مطالعاتی مناسب نیست و به عنوان مثال برای بعضی از کارآزمایی‌های بالینی حتی مقدار α = 0.001  پیشنهاد می‌شود. علاوه بر‌این، دو تَوَرّش (سوگیری) رایج که به یک‌پارچگی یافته‌های تحقیق اثر می‌گذارد، یکی گزارش‌های انتخابی یا با عنوان انگلیسی Selective Reporting  و دیگری با اصطلاح P-Hacking  شناخته می‌شود، می‌باشد. به‌طور خلاصه گزارش‌ دهی انتخابی به گرایش به سمت گزارش کردن صرفا مقادیر معنادار یعنی زمانی که pvalue  از مقدار نقطه برش کمتر هست توجه دارد، که در یک بررسی مشخص شد این اریبی به سمت نتایج معنادار گزارش شده می‌باشد. که در متا‌آنالیز با عنوان اریبی انتشار از آن یاد می‌شود. در مقابل، اصطلاح P-Hacking   اشاره به نمونه‌‌گیری‌های غیر تصادفی و یا دستکاری عمدی داده‌ها دارد. \n\n\nمسئله مقایسه‌های چند‌گانه\n\n\nبا فرض این‌که تمام ایرادات مطرح شده برطرف شده یا نادیده گرفته شوند، آخرین و اما مهم‌ترین مسئله‌ای که در کمی سازی مقدار pvalue  باقی می‌ماند، زمانی هست که یک آزمون چند‌گانه روی می‌دهد، اما آزمون چند‌گانه چه مفهومی می‌تواند داشته باشد؟ وضعیتی را تصور کنید که می‌خواهیم تأثیر چند نوع کود را بر‌روی میزان محصولات برداشت با هم مقایسه کنیم، که البته تعداد انواع کود بیشتر از ۲ هست و همچنین با فرض یکسان بودن سایر شرایط، مانند نوع خاک، وسعت زمین، نوع آبیاری و …\nو بخواهیم این مقایسه‌ها را به صورت دو‌به‌دو انجام دهیم، یعنی ابتدا کود نوع ۱ را با نوع ۲ و سپس با نوع ۳والی آخر  یعنی به شکل زیر:‌\n\n\\[\n\\begin{aligned}\n& \\text{Test}_1: ~ \\begin{cases}H_0: & \\mu_A = \\mu_B\\\\ H_1: & \\mu_A\\ne \\mu_B \\end{cases}\\\\\n& \\text{Test}_2: ~ \\begin{cases}H_0: & \\mu_A = \\mu_C\\\\ H_1: & \\mu_A\\ne \\mu_B \\end{cases}\\\\\n& \\text{Test}_3: ~ \\begin{cases}H_0: & \\mu_A = \\mu_D\\\\ H_1: & \\mu_A\\ne \\mu_B \\end{cases}\\\\\n& \\text{Test}_4: ~ \\begin{cases}H_0: & \\mu_B = \\mu_C\\\\ H_1: & \\mu_A\\ne \\mu_B \\end{cases}\\\\\n& \\text{Test}_5: ~ \\begin{cases}H_0: & \\mu_B = \\mu_D\\\\ H_1: & \\mu_A\\ne \\mu_B \\end{cases}\\\\\n& \\text{Test}_6: ~ \\begin{cases}H_0: & \\mu_C = \\mu_D\\\\ H_1: & \\mu_A\\ne \\mu_B \\end{cases}\\\\\n\\end{aligned}\n\\] \n\nواضح هست که حروف A, B, C, D  اشاره به نوع کودها دارد، همان‌طور که می بینیم وقتی انواع کود دارای ۴ سطح هست، ما ۶ مقایسه دو به دو خواهیم داشت که ترکیب ۲ از ۴ هست که جواب همان ۶ هست. \nحالا اگر خطای نوع اول یا همان  α = 0.05  در نظر بگیریم و برای هر ۶ مقایسه همزمان خطای نوع اول را پنج صدم در نظر بگیریم با وضعیت زیر مواجه خواهیم شد: \n\n\n\\[\n\\alpha_{Test_1} = \\alpha_{Test_2} = \\cdots = \\alpha_{Test_6} = 0.05\\implies\n\\]\n\n\nخطای نوع اول یعنی امکان مشاهده وضعیتی که فرض H0  را رد کنیم در صورتی که این فرض درست باشد،‌ پس احتمال این‌که فرض H0  را رد نکنیم در صورتی که این فرض درست باشد می‌شود  1 - α   ولی این مقادیر برای یک آزمون صدق می‌کند، ولی اگه بخواهیم احتمال این‌ را بسنجیم در صورتی برابری تمام میانگین سطوح‌ها ما فرض H0  را برای هیچ‌کدام از آزمون‌ها  رد نکنیم باید به این شکل آن را محاسبه کنیم\n\n\n\\[\n\\begin{aligned}\n& \\alpha_{Single} = 0.05 \\implies P_{single} = 1 - \\alpha_{single} = 1 - 0.05 = 0.95\\\\\n& \\implies P_{multiple} = P_{single} ^ 6 = 0.7350919 \\implies \\\\\n& \\alpha_{multiple} = 1 - P_{multiple} = 0.2649081\n\\end{aligned}\n\\]\n\n\nهمان‌طور که مشاهده می‌کنیم، خطا نوع اول برای مقایسه‌های همزمان به شدت تورم پیدا کرده هست و اگر تعداد مقایسه‌ها افزایش پیدا کند یعنی اگر ما فرضا ۵۰ تا مقایسه همزمان داشته باشیم و خطای نوع اول را را برای همه ۵۰ تا مقایسه پنج‌صدم در نظر بگیریم، آن‌گاه خطای نوع اول آزمون‌های چند‌گانه با توجه به روابطی که بالا آوردیم می‌شود:‌\n\n\n\\[\n\\alpha_{multiple} = 1 - P_{multiple} = 1 - (1 - 0.05)^{50} =  0.923055\n\\]\n\nواضح هست که در صورت افزایش مقایسه‌های چند‌گانه خطای نوع اول چند‌گانه به یک هم خواهد رسید. \n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "\nدرباره من\n",
    "section": "",
    "text": "درباره من\n\n\n\n\nسلام. من حبیب عزت‌آبادی هستم، دانشجوی کارشناسی ارشد دانشگاه علوم پزشکی شیراز. \nاین صفحه به منظور معرفی فعالیت‌های من درون گیت‌هاب طراحی شده هست. \n\nاین وبسایت با استفاده از  Quarto   کمی  CSS    و   HTML     و البته سخاوت گیت‌هاب برای ایجاد امکاناتی جهت ایجاد یک وبسایت شخصی بر‌روی این پلتفرم شکل گرفته هست. \n\n  \n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "",
    "section": "",
    "text": "تلاش من در این‌جا صرفا برای معرفی کارهایی هست که درون  مخازن گیت‌هابم انجام می‌دهم، و همچنین ارائه آموزش‌هایی که شاید برای دیگران هم جالب باشد. ولی اصلی‌ترین چیزی که باعث شکل‌گیری انگیزه درونی جهت ایجاد این صفحه شد. معرفی یک ابزار مبتنی بر‌ برنامه نویسی R بود به نام BlueSky که در این  صفحه  به آن خواهیم پرداخت. با توجه به زمان محدودی که در اختیار دارم، تکمیل این صفحات زمان خواهد برد. ولی قسمت مربوط به  BlueSky را می‌توانید به صورت کامل مشاهده کنید. \n\n\n\n\n\n\n Back to top"
  }
]