[
  {
    "objectID": "Pvalue.html#calculating-pvalue-for-multiple-comparisons-in-one-way-anova",
    "href": "Pvalue.html#calculating-pvalue-for-multiple-comparisons-in-one-way-anova",
    "title": "",
    "section": "Calculating pvalue for multiple comparisons in one-way ANOVA",
    "text": "Calculating pvalue for multiple comparisons in one-way ANOVA\n\n\n\nمحاسبه pvalue  برای مقایسه‌های چند گانه در آنالیز واریانس یک‌طرفه\n\n \n\nداده‌های موجود و البته مخصوصا داده‌های زیستی امروزه در مقیاس وسیعی تولید می شود. این امر جدا از آن‌که منجر به ذخیره انبوهی از داده‌های خام شده هست، بلکه باعث شکل‌گیری آزمون‌های فرض مختلفی نیز بوده هست. برای آزمایش این فرضیه‌ها، روش‌هایی از آمار استنباطی بر‌روی مجموعه‌ داده‌ها اِعمال می‌شود که منجر به بینش‌های زیستی بیشتر(برای داده‌های زیستی) و اصولا بینش عمیق‌تر در مورد داده‌ها می‌شود. اساسا، آزمون فرض یک روش آماری هست که احتمال موافق بودن داده‌ها را که بر‌اساس یک نمونه‌گیری تصادفی جمع‌آوری شده‌اند، با فرض صفر (یا مخالف فرض صفر) محاسبه می‌کند و نتایج این محاسبات در یک عدد خاص با نماد pvalue  خلاصه می‌شود. من پیرو قولی که در زمان ضبط ویدئوهای مربوط به BlueSky  داده‌ام می‌خواهم درباره‌ تصحیح مقادیر pvalue  یک گزارش نسبتا مفصل ارائه بدم، ولی قبل از آن‌که در مورد تصحیح pvalue   برای مقایسه‌های چند‌گانه صحبت کنم، در مورد خود آن توضیح کوتاهی ارائه خواهم داد."
  },
  {
    "objectID": "Pvalue.html#what-is-pvalue",
    "href": "Pvalue.html#what-is-pvalue",
    "title": "",
    "section": "What is pvalue",
    "text": "What is pvalue\n\n\n \n pvalue   چیست؟\n\n\nهنگامی که می‌خواهید به صورت آماری استنباط کنید که آیا نتیجه آزمون آماری قابل‌توجه (معنادار) هست یا خیر، با توجه به فرض صفر (H0) ، احتمال شکل‌گیری نتیجه مشاهده شده را با وضعیتی که در آن همه چیز کاملا تصادفی باشد البته با پذیرش درستی فرض صفر، مقایسه می‌کنیم. یک مقدار یا برشی که به عنوان مرز تصمیم گیری که البته هم بر‌اساس روابط تکنیکی ریاضی و هم تاریخی بر‌روی آن یک اجماع نسبی وجود دارد (البته با توجه به زمینه و بستر مطالعه) که با عنوان خطای نوع اول یا α  که معمولا  برابر با مقادیر0.1, 0.05, 0.01, 0.001   می‌باشد، در نظر گرفته می‌شود. با توجه به نقطه برش یا خط مرزی درنظر گرفته شده، برای مثال اگر فرض صفر برابری میانگین‌های چند‌ گروه باشید، یعنی؛\n\n\\[\n\\begin{cases}H_0:& \\mu_1 = \\mu_2 = \\cdots = \\mu_k\\\\\nH_1: & \\exists ~~ i, j ~~s.t~~ \\mu_i \\ne \\mu_j, ~~ i, j = 1, 2, ..., k, \\quad i \\ne j\\end{cases}\n\\]\n\nاگر مقدار pvalue  به‌دست آمده کمتر از نقطه برش انتخاب شده یا همان α  باشد فرض صفر رد می‌شود و در غیر این صورت فرض صفر تأیید می‌شود. البته باید ذکر شود که در آزمون‌های آماری صرف بیان کردن مقدار pvalue  کفایت نمی‌کند. و باید علاوه بر این مقدار کمیت‌هایی مانند فواصل اطمینان، توان آزمون و یا اندازه اثر و ... می‌تواند در کنار مقدار pvalue  گزارش شود."
  },
  {
    "objectID": "Pvalue.html#pvalue-problems",
    "href": "Pvalue.html#pvalue-problems",
    "title": "",
    "section": "pvalue Problems",
    "text": "pvalue Problems\n\n\n\nمشکلات pvalue  \n\n\nحقیقت این هست که بحث جدل زیادی پیرامون موقعیت و اهمیت pvalue  در محافل علمی وجود دارد. و این موضوع با ظهور کلان‌داده‌ها که عمدتا حول سوء تفاهم و همچنین استفاده نادرست از pvalue  می‌شود افزونی یافته هست. اولین ایرادی که وارد می‌کنند این هست که نقاط برش انتخاب شده یعنی  α = 0.1, 0.05, 0.001, ...  کاملا دلخواه هستند و صرفا بر‌اساس یک قرار‌داد شکل گرفته‌اند. و این واقعیت مولد آن هست که این مقدار لزوما برای هر زمینه‌ مطالعاتی مناسب نیست و به عنوان مثال برای بعضی از کارآزمایی‌های بالینی حتی مقدار α = 0.001  پیشنهاد می‌شود. علاوه بر‌این، دو تَوَرّش (سوگیری) رایج که به یک‌پارچگی یافته‌های تحقیق اثر می‌گذارد، یکی گزارش‌های انتخابی یا با عنوان انگلیسی Selective Reporting  و دیگری با اصطلاح P-Hacking  شناخته می‌شود، می‌باشد. به‌طور خلاصه گزارش‌ دهی انتخابی به گرایش به سمت گزارش کردن صرفا مقادیر معنادار یعنی زمانی که pvalue  از مقدار نقطه برش کمتر هست توجه دارد، که در یک بررسی مشخص شد این اریبی به سمت نتایج معنادار گزارش شده می‌باشد. که در متا‌آنالیز با عنوان اریبی انتشار از آن یاد می‌شود. در مقابل، اصطلاح P-Hacking   اشاره به نمونه‌‌گیری‌های غیر تصادفی و یا دستکاری عمدی داده‌ها دارد."
  },
  {
    "objectID": "Pvalue.html#the-problem-of-multiple-comparisons",
    "href": "Pvalue.html#the-problem-of-multiple-comparisons",
    "title": "",
    "section": "The problem of multiple comparisons",
    "text": "The problem of multiple comparisons\n\n\n\nمسئله مقایسه‌های چند‌گانه\n\n\nبا فرض این‌که تمام ایرادات مطرح شده برطرف شده یا نادیده گرفته شوند، آخرین و اما مهم‌ترین مسئله‌ای که در کمی سازی مقدار pvalue  باقی می‌ماند، زمانی هست که یک آزمون چند‌گانه روی می‌دهد، اما آزمون چند‌گانه چه مفهومی می‌تواند داشته باشد؟ وضعیتی را تصور کنید که می‌خواهیم تأثیر چند نوع کود را بر‌روی میزان محصولات با هم مقایسه کنیم، که البته تعداد انواع کود بیشتر از ۲ هست و همچنین با فرض یکسان بودن سایر شرایط، مانند نوع خاک، وسعت زمین، نوع آبیاری و …\nو بخواهیم این مقایسه‌ها را به صورت دو‌به‌دو انجام دهیم، یعنی ابتدا کود نوع ۱ را با نوع ۲ و سپس با نوع ۳والی آخر  یعنی به شکل زیر‌\n\n\\[\n\\begin{aligned}\n& \\text{Test}_1: ~ \\begin{cases}H_0: & \\mu_A = \\mu_B\\\\ H_1: & \\mu_A\\ne \\mu_B \\end{cases}\\\\\n& \\text{Test}_2: ~ \\begin{cases}H_0: & \\mu_A = \\mu_C\\\\ H_1: & \\mu_A\\ne \\mu_B \\end{cases}\\\\\n& \\text{Test}_3: ~ \\begin{cases}H_0: & \\mu_A = \\mu_D\\\\ H_1: & \\mu_A\\ne \\mu_B \\end{cases}\\\\\n& \\text{Test}_4: ~ \\begin{cases}H_0: & \\mu_B = \\mu_C\\\\ H_1: & \\mu_A\\ne \\mu_B \\end{cases}\\\\\n& \\text{Test}_5: ~ \\begin{cases}H_0: & \\mu_B = \\mu_D\\\\ H_1: & \\mu_A\\ne \\mu_B \\end{cases}\\\\\n& \\text{Test}_6: ~ \\begin{cases}H_0: & \\mu_C = \\mu_D\\\\ H_1: & \\mu_A\\ne \\mu_B \\end{cases}\\\\\n\\end{aligned}\n\\] \n\nواضح هست که حروف A, B, C, D  اشاره به نوع کودها دارد، همان‌طور که می بینیم وقتی انواع کود دارای ۴ سطح هست، ما ۶ مقایسه دو به دو خواهیم داشت که ترکیب ۲ از ۴ هست که جواب همان ۶ هست. \nحالا اگر خطای نوع اول یا همان  α = 0.05  در نظر بگیریم و برای هر ۶ مقایسه همزمان خطای نوع اول را پنج صدم در نظر بگیریم با وضعیت زیر مواجه خواهیم شد: \n\n\n\\[\n\\alpha_{Test_1} = \\alpha_{Test_2} = \\cdots = \\alpha_{Test_6} = 0.05\\implies\n\\]\n\n\nخطای نوع اول یعنی امکان مشاهده وضعیتی که فرض H0  را رد کنیم در صورتی که این فرض درست باشد،‌ پس احتمال این‌که فرض H0  را رد نکنیم در صورتی که این فرض درست باشد می‌شود  1 - α   ولی این مقادیر برای یک آزمون صدق می‌کند، ولی اگه بخواهیم احتمال این‌ را بسنجیم در صورتی برابری تمام میانگین سطوح‌ها ما فرض H0  را برای هیچ‌کدام از آزمون‌ها  رد نکنیم باید به این شکل آن را محاسبه کنیم\n\n\n\\[\n\\begin{aligned}\n& \\alpha_{Single} = 0.05 \\implies P_{single} = 1 - \\alpha_{single} = 1 - 0.05 = 0.95\\\\\n& \\implies P_{multiple} = P_{single} ^ 6 = 0.7350919 \\implies \\\\\n& \\alpha_{multiple} = 1 - P_{multiple} = 0.2649081\n\\end{aligned}\n\\]\n\n\nهمان‌طور که مشاهده می‌کنیم، خطا نوع اول برای مقایسه‌های همزمان به شدت تورم پیدا کرده هست و اگر تعداد مقایسه‌ها افزایش پیدا کند یعنی اگر ما فرضا ۵۰ تا مقایسه همزمان داشته باشیم و خطای نوع اول را را برای همه ۵۰ تا مقایسه پنج‌صدم در نظر بگیریم، آن‌گاه خطای نوع اول آزمون‌های چند‌گانه با توجه به روابطی که بالا آوردیم می‌شود:‌\n\n\n\\[\n\\alpha_{multiple} = 1 - P_{multiple} = 1 - (1 - 0.05)^{50} =  0.923055\n\\]\n\nواضح هست که در صورت افزایش مقایسه‌های چند‌گانه خطای نوع اول چند‌گانه به یک هم خواهد رسید. \nسؤالی که این‌جا شکل می‌گیرد این هست که چگونه باید جلوی رشد نرخ خطای نوع اول برای مقایسه‌های چند‌گانه گرفته شود؟\n \nاولین جوابی که به این سؤال میشه داد، کاهش خطای نوع اول هست. یا در واقع کاهش Threshold  یا آن آستانه‌ای که در صورتی که pvalue  از آن کمتر شود فرض اولیه رد می‌شود. یکی از روش‌هایی که برای پاسخ به این پرسش مد نظر قرار می‌گیرد، روش بونفرونی هست که در ادامه به بعضی از روش‌های نسبتا پر‌استفاده  تصحیح خطای نوع اول و یا مقدار pvalue  بیان خواهد شد. \n\n\nقبل از آن‌که به ادامه بحث بپردازیم، برای این‌که یک تصویر بهتر از توضیحاتی که قرار هست ارائه شود شکل گیرد، من روش‌هایی که می‌خواهم در این صفحه به آن‌ها بپردازم را در پایین فهرست می‌کنم: \n\n  Bonferroni\nHolm\nHochberg\nHommel\nBenjumaini and Hochberg (BH)\nBenjumaini and Yekutieli (BY)\nFalse discovery rate (fdr)"
  },
  {
    "objectID": "Pvalue.html#bonferronis-method-for-correcting-type-1-error-in-multiple-tests",
    "href": "Pvalue.html#bonferronis-method-for-correcting-type-1-error-in-multiple-tests",
    "title": "",
    "section": "Bonferroni’s method for correcting type 1 error in multiple tests",
    "text": "Bonferroni’s method for correcting type 1 error in multiple tests\n\n\n\nروش بونفرونی برای تصحیح خطای  نوع اول در آزمون‌های چند‌گانه\n\nما برای توضیح این ۷ نوع روش تصحیح pvalue  یا خطای نوع اول، یک بردار از مقادیر pvalue  محاسبه شده به روش‌های معمولی را مد نظر قرار می‌دهیم، یعنی فرض می‌کنیم که یک  آزمون چند‌گانه را پیاده‌سازی کرده‌ایم و مقادیر محاسبه شده برای pvalue  از قرار زیر بوده هست\n\n\n\n\n0.0001 0.001 0.01 0.1 0.08 0.09 0.15 0.21 0.35 0.55 0.3 0.64 0.77 0.9 0.03 0.02 0.09 0.19 0.21 0.41\n\n\n\nروش بونفرونی رویکرد خیلی ساده‌ای دارد، این روش به ما می گوید که اگر فرضا تعداد مقایسه‌ها (آزمون‌ها) فرضا mتا آزمون هست، آن‌گاه بر‌اساس خطای نوع اولی که در شروع تعیین می‌کنید، برای مقایسه‌های چند‌گانه این خطا را بر تعداد آزمون‌ها که در این‌جا فرض کردیم mتا می‌باشد تقسیم کنید و مقادیر pvalue محاسبه شده را با این خطا مقایسه کنید و آن‌گاه اگر مقدار pvalue  کمتر از مقدار خطا نوع اول برآورد شده بود فرض H0  را رد کنید. یعنی؛\n\n\\[\n\\begin{aligned}\n& \\text{Initial} ~\\alpha = \\alpha_0\\implies \\\\\n& \\text{if number of test}~ = m \\implies \\text{final}~ \\alpha = \\alpha_{multiple} = \\frac{\\alpha_0}{m}\n\\end{aligned}\n\\]\n\nحالا اگر بخواهیم برای مثالی که در بالا مقادیر pvalue  آن را آورده‌ایم، این روش را پیاده‌سازی کنیم، به جواب زیر خواهیم رسید. \n\nالبته قبل از آن‌که جواب را ببینیم، ذکر یک نکته در این‌جا می تواند اهمیت داشته باشد، و آن این هست که، در R و در بسته stats  که همراه R \nبر‌روی سیستم نصب می‌شود، یعنی جز بسته‌های پیش‌فرض هست، تابع  p.adjust   روش‌های گفته شده در بالا را پشتیبانی می‌کند و ما می‌توانیم با دادن بردار مقادیر pvalue  به این تابع و تعیین نوع تصحیح خروجی که مقادیر اصلاح شده pvalue  می‌باشد را داشته باشیم. ولی از نظر من در کتابخانه  statsmodels   در پایتون متد‌هایی هست که خروجی بهتری و همچنین روش‌های به نسبت بیشتری را برای تصحیح خطای نوع اول و یا pvalue  پشتیبانی می‌کنند. من خروجی در هر دو نرم‌افزار برای شما در پایین می‌آورم تا بهتر متوجه این مسئله بشوید. \n\nمثال:\n\n\nimport statsmodels.stats.multitest as stest \n\npVal = [0.0001, 0.001, .01, 0.1, 0.08, 0.09, 0.15, 0.21, 0.35, 0.55, 0.3, \n0.64, 0.77, 0.9, 0.03, 0.02, 0.09, 0.19, 0.21, 0.41]\n\nres = stest.multipletests(pVal, alpha = 0.05, method = \"bonferroni\")\n# python Result\nprint(res)\n\n(array([ True,  True, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False]), array([0.002, 0.02 , 0.2  , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n       1.   , 1.   , 1.   , 1.   , 1.   , 0.6  , 0.4  , 1.   , 1.   ,\n       1.   , 1.   ]), 0.0025613787765302876, 0.0025)\n\n\n\n\n# R Result\np.adjust(c(0.0001, 0.001, .01, 0.1, 0.08, 0.09, 0.15, 0.21, 0.35, 0.55, 0.3, \n0.64, 0.77, 0.9, 0.03, 0.02, 0.09, 0.19, 0.21, 0.41), method = \"bonferroni\")\n\n [1] 0.002 0.020 0.200 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n[13] 1.000 1.000 0.600 0.400 1.000 1.000 1.000 1.000\n\n\n\nهمان‌طور که مشاهده می‌کنیم خروجی پایتون دارای جزئیات بیشتری هست، خروجی این‌نرم‌افزار علاوه بر مقادیر اصلاح شده pvalue  که اگر بخواهیم به شکل مشخص‌تری نشان دهیم؛‌\n\n\n\n  (array([ True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]), array([0.002, 0.02 , 0.2 , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 0.6 , 0.4 , 1. , 1. , 1. , 1. ]), 0.0025613787765302876, 0.0025) \n\n\n\n\nخروجی پایتون یک تاپل می ‌باشد که شامل ۴ عضو هست، عضو اول و دوم array  می‌باشند و عضو‌های سوم و چهارم مقادیر عددی، آرایه اول در حقیقت نتایج آزمون‌ها را نشان می‌دهد که مقدار True  به معنای رد فرض اولیه هست و مقدار False  به معنای پذیرش فرض اولیه یا همان H0. که در این‌جا این آرایه با رنگ قرمز مشخص شده هست. آرایه دوم که با رنگ سبز مشخص شده هست اشاره دارد به مقادیر pvalue اصلاح شده توسط روش به‌کار برده شده که در این‌جا بونفرونی می‌باشد. و مقادیر عددی که عضو‌های سوم و چهارم این تاپل می‌باشند و با رنگ آبی پر‌رنگ مشخص شده‌اند، عضو سوم اشاره به خطای نوع اول اصلاح شده با روش Sidak  دارد. که برای این‌که بدانیم خطای نوع اول اصلاح شده Sidak  چگونه محاسبه می‌شود، با توجه به مثال آورده شده در بالا، به معادله زیر توجه کنید: \n\n\n\n\\[\n\\begin{aligned}\n& \\alpha_{Sidak} = 1 - (1 - \\alpha_{Intiial})^{\\frac{1}{\\text{\\# number of Tests}}} \\implies \\\\\n& \\text{In This Example:}\\quad  \\alpha_{Sidak} = 1 - (1 - 0.05)^{\\frac{1}{20}} = 0.0025614\n\\end{aligned}\n\\]\n\n\n\nکه البته در این‌جا کمی این مقدار گرد شده هست. و همچنین \nعضو چهارم همان خطای نوع اول اصلاح شده به روش بونفرونی می‌باشد. \n\nولی در خروجی R همان‌طور که ملاحظه می‌کنیم فقط مقادیر اصلاح شده pvalue  را ما در خروجی می‌بینیم. باز هم ذکر یک نکته حائز اهمیت هست، چرا وقتی ما در روش بونفرونی حرف از اصلاح خطای نوع اول زده‌ایم در این دو تابع مقادیر اصلاح شده برای pvalue  برای ما در خروجی ظاهر شده هست. دلیل این امر این هست که هر دو این توابع  یا متدها، به جای آن‌که در حقیقت مقایسه pvalue  را با مقدار تقسیم خطای نوع اول بر تعداد آزمون‌ها مقایسه کنند، به جای آن تعداد آزمون‌ها را در مقدار pvalue  ضرب می‌کنند و آن گاه مقدار pvalue  به‌دست آمده را با همان خطای نوع اول آغازین آزمون مقایسه می‌کنند. ولی در خروجی نهایی پایتون ما خطای نوع اول اصلاح شده نهایی هم در انتها می‌بینیم ولی در خروجی R این چنین نیست. البته باز هم شاید این ابهام شکل بگیرد که ضرب تعداد آزمون‌ها در بعضی از مقادیر pvalue  مقادیر گزارش شده در خروجی‌های بالا نیست، برای این مورد باید ذکر شود که مقدار pvalue  یک مقدار احتمال هست پس نمی‌تواند بزرگتر از ۱ گزارش شود و برای وقتی که ضرب تعداد آزمون‌ها در pvalue  برآورد شده اولیه بزرگتر از ۱ باشد، آن مقدار همان ۱ گزارش می‌شود."
  },
  {
    "objectID": "Pvalue.html#holms-method-for-correcting-type-1-error-in-multiple-tests",
    "href": "Pvalue.html#holms-method-for-correcting-type-1-error-in-multiple-tests",
    "title": "",
    "section": "Holm’s method for correcting type 1 error in multiple tests",
    "text": "Holm’s method for correcting type 1 error in multiple tests\n\n\n\nروش هولم برای تصحیح خطای  نوع اول در آزمون‌های چند‌گانه\n\nاین روش در حقیقت یک اصلاح هست بر‌روی روش بونفرونی که از مراحل زیر تشکیل شده هست. \n\n\n\n\n\nفرض کنید که m آزمون همزمان دارید و مقادیر برآورد شده برای pvalue  این آزمون‌ها را از کوچک به بزرگ به شکل زیر مرتب کرده‌اید: P1,   P2,  , ...,   Pm  و این مقادیر متناظر با فرض‌های اولیه H1,   H2,  , ...,   Hm می‌باشد برای به دست آوردن نتیجه هر آزمون البته با تصحیح خطای  نوع اول به شکل زیر عمل می‌کنیم\n\nاگر P1 &lt; α⁄m آن‌گاه فرض اولیه H1  را رد کن و برو گام بعدی، در غیر این صورت  فرض اولیه  H1  را قبول کن و از ادامه مراحل صرف‌نظر کن\n\nاگر P2 &lt; α⁄(m-1) آن‌گاه فرض اولیه H2  را رد کنید و بروید گام بعدی، در غیر این صورت  فرض اولیه  H2  را قبول کنید و از ادامه مراحل صرف‌نظر کنید\n\n\nاین روند ادامه پیدا‌ می‌کند به این‌ شکل که برای هر مقدار Pk, k = 1, 2, ..., m  اگر Pk &lt; α⁄(m - k + 1)  آن‌گاه فرض اولیه Hk  را رد کنید و بروید مرحله بعد در غیر این صورت از ادامه مراحل صرف‌نظر کنید. \n\n\nاین روش اطمینان حاصل می‌کند که مقدار خطای نوع اول چند‌گانه یا در اصطلاح بهتر آن FWER (family-wise error rate)  در سطح خطای نوع اول آزمون باقی بماند. \n\nمثال:\n\n\nimport statsmodels.stats.multitest as stest \n\npVal = [0.0001, 0.001, .01, 0.1, 0.08, 0.09, 0.15, 0.21, 0.35, 0.55, 0.3, \n0.64, 0.77, 0.9, 0.03, 0.02, 0.09, 0.19, 0.21, 0.41]\n\nres = stest.multipletests(pVal, alpha = 0.05, method = \"holm\")\n# python Result\nprint(res)\n\n(array([ True,  True, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False]), array([0.002, 0.019, 0.18 , 1.   , 1.   , 1.   , 1.   , 1.   , 1.   ,\n       1.   , 1.   , 1.   , 1.   , 1.   , 0.48 , 0.34 , 1.   , 1.   ,\n       1.   , 1.   ]), 0.0025613787765302876, 0.0025)\n\n\n\n\n# R Result\np.adjust(c(0.0001, 0.001, .01, 0.1, 0.08, 0.09, 0.15, 0.21, 0.35, 0.55, 0.3, \n0.64, 0.77, 0.9, 0.03, 0.02, 0.09, 0.19, 0.21, 0.41), method = \"holm\")\n\n [1] 0.002 0.019 0.180 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000\n[13] 1.000 1.000 0.480 0.340 1.000 1.000 1.000 1.000"
  },
  {
    "objectID": "Pvalue.html#hochbergs-method-for-correcting-type-1-error-in-multiple-tests",
    "href": "Pvalue.html#hochbergs-method-for-correcting-type-1-error-in-multiple-tests",
    "title": "",
    "section": "Hochberg’s method for correcting type 1 error in multiple tests",
    "text": "Hochberg’s method for correcting type 1 error in multiple tests\n\n\n\nروش هاچبرگ برای تصحیح خطای  نوع اول در آزمون‌های چند‌گانه\n\n\nروش هاچبرگ دقیقا مانند روش هولم هست، با این تفاوت که مقایسه‌ها از  بزرگترین مقدار pvalue  برآورد شده شروع می‌شود و تا کوچکترین مقدار امتداد پیدا می‌کند یا به عبارتی دیگر عکس مسیری که روش هولم در پیش می‌گرفت، روش هولم مقایسه‌ها را از کوچکترین مقدار pvalue  برآورد شده شروع می‌کرد ولی در روش هاچبرگ از بزرگترین مقدار شروع می‌شود و با اولین مقایسه معنادار (رد فرض صفر)، ادامه الگوریتم متوقف می‌شود و تمام مقایسه‌های (آزمون‌های) باقی‌مانده، معنادار گزارش می‌شود. \n\nالبته یک تفاوت دیگر هم بین این روش و روش هولم وجود دارد و آن تعیین مقدار pvalue  در هر مرحله هست، روش‌های ذکر شده همگی تصحیح‌ را را بر روی مقادیر خطای نوع اول انجام می‌دهند ولی همان‌طور که ذکر شده به‌جای مقایسه pvalue  هر مرحله با خطای نوع اول آن مرحله، ضریب اِعمال شده در خطای نوع اول هر مرحله را معکوس کرده و در مقدار pvalue  همان مرحله ضرب می‌کنند و اسم این مقدار pvalue  را مقدار اصلاح شده pvalue  می‌نامند ولی همان‌طور که در گفتار بالا گفته شد، pvalue  یک مقدار احتمال هست و نمی‌تواند بزرگتر از ۱ باشد لذا مقداری که انتخاب می‌‌شود مقدار کمینه بین ۱ و مقدار حاصل شده هست. \nتفاوت روش هاچبرگ با روش هولم در این‌جاست که روش‌های بونفرونی و هولم مقدار pvalue  حاصل شده را با یک مقایسه کرده و مقدار کمینه را در خروجی می‌آورند ولی روش هاچبرگ مقدار حاصل‌شده را با بیشینه مقدار pvalue  محاسبه شده با مقادیر pvalue  محاسبه شده در همه مقایسه‌های شکل گرفته مقابسه کرده و مقدار مینیم را انتخاب کرده و در خروجی می‌آورد. یعنی در مثال ما چون مقدار بیشینه 0.9  می‌باشد لذا آن‌جا که pvalue حاصل شده بیش‌تر از این مقدار باشد، همین مقدار 0.9  به عنوان مقدار نهایی برای pvalue  آن مرحله در خروجی خواهد آمد. \n\n\nمثال: \n\n\nimport statsmodels.stats.multitest as stest \n\npVal = [0.0001, 0.001, .01, 0.1, 0.08, 0.09, 0.15, 0.21, 0.35, 0.55, 0.3, \n0.64, 0.77, 0.9, 0.03, 0.02, 0.09, 0.19, 0.21, 0.41]\n\nres = stest.multipletests(pVal, alpha = 0.05, method = \"simes-hochberg\")\n# python Result\nprint(res)\n\n(array([ True,  True, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False]), array([0.002, 0.019, 0.18 , 0.9  , 0.9  , 0.9  , 0.9  , 0.9  , 0.9  ,\n       0.9  , 0.9  , 0.9  , 0.9  , 0.9  , 0.48 , 0.34 , 0.9  , 0.9  ,\n       0.9  , 0.9  ]), 0.0025613787765302876, 0.0025)\n\n\n\n\n# R Result\np.adjust(c(0.0001, 0.001, .01, 0.1, 0.08, 0.09, 0.15, 0.21, 0.35, 0.55, 0.3, \n0.64, 0.77, 0.9, 0.03, 0.02, 0.09, 0.19, 0.21, 0.41), method = \"hochberg\")\n\n [1] 0.002 0.019 0.180 0.900 0.900 0.900 0.900 0.900 0.900 0.900 0.900 0.900\n[13] 0.900 0.900 0.480 0.340 0.900 0.900 0.900 0.900"
  },
  {
    "objectID": "Pvalue.html#hommels-method-for-correcting-type-1-error-in-multiple-tests",
    "href": "Pvalue.html#hommels-method-for-correcting-type-1-error-in-multiple-tests",
    "title": "",
    "section": "Hommel’s method for correcting type 1 error in multiple tests",
    "text": "Hommel’s method for correcting type 1 error in multiple tests\n\n\n\nروش هومِل برای تصحیح خطای  نوع اول در آزمون‌های چند‌گانه\n\nاین روش، نسبتا روش پیچیده‌ای هست البته در مقایسه با روش‌های قبلی. \nفرض کنیم؛ \n\n\\[\n\\text{H} = \\left\\{H_{(1)}, H_{(2)}, ..., H_{(m)}\\right\\},\n\\]\n\nفرض‌های صفر متناظر با آزمون‌های چند‌گانه با مقادیر pvalue  برآورد شده به شرح زیر باشد؛ \n\n\n\n\nمقادیر مرتب شده هست.\n\n\n\n\\[\np_{(1)}, p_{(2)}, ..., p_{(m)}\n\\]\n\nکه در این‌جا m تعداد مقایسه‌های چند‌گانه هست. آن‌گاه برای بررسی معناداری آزمون Hi  به روش زیر عمل می‌کنیم. \n\nابتدا مقدار j که به فرم زیر هست را محاسبه می‌کنیم\n\n\\[\nj = \\max\\left\\{i \\in \\left\\{1, ..., m\\right\\}:\\quad p_{(m -i+k)} &gt; \\frac{k\\alpha}{i},\\quad\\text{for}~~k = 1, ..., i\\right\\}\n\\]\n\nواضح هست که اگر به ازای یک مقدار دلخواه i هیچ مقداری برای j حاصل نشود آن‌گاه تمام فرض‌های صفری که در بالا آورده شد رد می‌شود. حالا فرض کنیم که ما برای یک مقدار i یک مقدار j به‌دست آورده‌ایم آن‌گاه برای این‌که معناداری Hi  را بررسی کنیم باید این مقایسه را شکل دهیم؛ \n\n\\[\np_i \\geq \\frac{\\alpha}{j}\n\\]\n\nاگر گزاره شرطی بالا برقرار باشد، آن‌گاه فرض صفر Hi  را می‌پذیریم. \n\nمثال:\n\n\nimport statsmodels.stats.multitest as stest \n\npVal = [0.0001, 0.001, .01, 0.1, 0.08, 0.09, 0.15, 0.21, 0.35, 0.55, 0.3, \n0.64, 0.77, 0.9, 0.03, 0.02, 0.09, 0.19, 0.21, 0.41]\n\nres = stest.multipletests(pVal, alpha = 0.05, method = \"hommel\")\n# python Result\nprint(res)\n\n(array([ True,  True, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False]), array([0.002, 0.019, 0.18 , 0.8  , 0.72 , 0.738, 0.9  , 0.9  , 0.9  ,\n       0.9  , 0.9  , 0.9  , 0.9  , 0.9  , 0.42 , 0.32 , 0.738, 0.9  ,\n       0.9  , 0.9  ]), 0.0025613787765302876, 0.0025)\n\n\n\n\n# R Result\np.adjust(c(0.0001, 0.001, .01, 0.1, 0.08, 0.09, 0.15, 0.21, 0.35, 0.55, 0.3, \n0.64, 0.77, 0.9, 0.03, 0.02, 0.09, 0.19, 0.21, 0.41), method = \"hommel\")\n\n [1] 0.002 0.019 0.180 0.800 0.720 0.738 0.900 0.900 0.900 0.900 0.900 0.900\n[13] 0.900 0.900 0.420 0.320 0.738 0.900 0.900 0.900"
  },
  {
    "objectID": "Pvalue.html#benjamini-hochberg-method-bh-for-correcting-type-1-error-in-multiple-tests",
    "href": "Pvalue.html#benjamini-hochberg-method-bh-for-correcting-type-1-error-in-multiple-tests",
    "title": "",
    "section": "Benjamini-Hochberg Method (BH) for correcting type 1 error in multiple tests",
    "text": "Benjamini-Hochberg Method (BH) for correcting type 1 error in multiple tests\n\n\n\nروش بنجامینی-هاچبرگ برای تصحیح خطای  نوع اول در آزمون‌های چند‌گانه\n\n\nاین روش به نسبت روش قبل ساده‌‌تر هست، ولی تفاوتی که این روش و روش‌هایی که در ادامه می‌آید با روش‌هایی که ذکر شد در این هست که، روش‌های ذکر شده در جهت کنترل خطای نوع اول کل مقایسه یا همان (FWER)  کارکرد خودشان را پیاده‌سازی می‌کردند. ولی این روش و روش‌هایی که در ادامه می‌آید، فارغ از این‌که خطای نوع اول در ابتدا چه مقداری هست در جهت کنترل رد به اشتباه فرض صفر عمل می‌کنند. یا به عبارتی کنترل FDR (False Discovery Rate)   که نسبت FDR  اشاره دارد به تعداد فرض‌های صفر به اشتباه رد شده بر کل فرض‌های صفر رد شده. \nاز این بستر اولین روشی که معرفی می‌شود روش بنجامینی-هاچبرگ هست که مقدار pvalue  تصحیح شده با استفاده از این شیوه از طریق زیر حاصل می‌شود.\n\nدر ابتدا مقادیر pvalue  برآورد شده را از کوچک به بزرگ مرتب می‌کنیم و در مجموعه زیر قرار می‌دهیم\n\n\\[\n\\left\\{p_{(1)}, p_{(2)}, ..., p_{(m)}\\right\\}\n\\]\n\nکه مقدار m اشاره به تعداد کل آزمون‌های چند‌گانه دارد. آن‌گاه مقدار pvalue  حاصل شده برای عضو ith  این مجموعه با معادله زیر به دست می‌آید\n\n\\[\np_{(i)}^{(BH)} = \\min\\left\\{\\underset{j \\geq i}{\\min}\\left\\{\\frac{m \\times p_{(j)}}{j}\\right\\}, ~1\\right\\}\n\\]\n\n\nمثال:\n\n\nimport statsmodels.stats.multitest as stest \n\npVal = [0.0001, 0.001, .01, 0.1, 0.08, 0.09, 0.15, 0.21, 0.35, 0.55, 0.3, \n0.64, 0.77, 0.9, 0.03, 0.02, 0.09, 0.19, 0.21, 0.41]\n\nres = stest.multipletests(pVal, alpha = 0.05, method = \"fdr_bh\")\n# python Result\nprint(res)\n\n(array([ True,  True, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False]), array([0.002     , 0.01      , 0.06666667, 0.22222222, 0.22222222,\n       0.22222222, 0.3       , 0.32307692, 0.46666667, 0.64705882,\n       0.42857143, 0.71111111, 0.81052632, 0.9       , 0.12      ,\n       0.1       , 0.22222222, 0.32307692, 0.32307692, 0.5125    ]), 0.0025613787765302876, 0.0025)\n\n\n\n\n# R Result\np.adjust(c(0.0001, 0.001, .01, 0.1, 0.08, 0.09, 0.15, 0.21, 0.35, 0.55, 0.3, \n0.64, 0.77, 0.9, 0.03, 0.02, 0.09, 0.19, 0.21, 0.41), method = \"BH\")\n\n [1] 0.00200000 0.01000000 0.06666667 0.22222222 0.22222222 0.22222222\n [7] 0.30000000 0.32307692 0.46666667 0.64705882 0.42857143 0.71111111\n[13] 0.81052632 0.90000000 0.12000000 0.10000000 0.22222222 0.32307692\n[19] 0.32307692 0.51250000"
  },
  {
    "objectID": "Pvalue.html#benjumaini-and-yekutieli-method-by-for-correcting-type-1-error-in-multiple-tests",
    "href": "Pvalue.html#benjumaini-and-yekutieli-method-by-for-correcting-type-1-error-in-multiple-tests",
    "title": "",
    "section": "Benjumaini and Yekutieli Method (BY) for correcting type 1 error in multiple tests",
    "text": "Benjumaini and Yekutieli Method (BY) for correcting type 1 error in multiple tests\n\n\n\nروش بنجامینی-یِکوتیلی برای تصحیح خطای  نوع اول در آزمون‌های چند‌گانه\n\n\nاین روش در سال ۲۰۰۱ معرفی شد، مانند روش قبل ولی محافظه‌کارانه‌تر. همچنین به مانند روش قبل در جهت کنترل FDR  می‌باشد. روش محاسبه‌ی pvalue  اصلاح شده با این شیوه به فرم زیر هست، در ابتدا اگر فرض کنیم؛\n\n\\[\n\\text{H} = \\left\\{H_{(1)}, H_{(2)}, ..., H_{(m)}\\right\\},\n\\]\n\nفرض‌های صفر متناظر با آزمون‌های چند‌گانه با مقادیر pvalue  برآورد شده به شرح زیر باشد؛\n\n\n\n\nمقادیر مرتب شده هست.\n\n\n\n\\[\np_{(1)}, p_{(2)}, ..., p_{(m)}\n\\]\n\nآن‌گاه\n\n\\[\nk = \\max\\left\\{i:\\quad p_{(i)} \\leq \\frac{i}{m}\\tilde{\\alpha}\\right\\}, \\quad \\tilde{\\alpha} = \\frac{\\alpha_{(Initial)}}{\\sum_{i = 1}^m \\frac{1}{i}}\n\\]\n\n منظور از αInitial  همان خطای نوع اولی هست که در ابتدا آزمون به آن اشاره می‌شود. و در معادله بالا اگر مقداری برای k به دست نیاید تمام فرض‌های اولیه پذیرفته می‌شوند. و اگر مقدار برای k به دست بیاید، فرض های \n\n\\[\n\\left\\{H_1, \\dots, H_k\\right\\}\n\\]\n\n رد می شود، همان‌طور که مشاهده می کنیم این روش به نسبت دارای محاسبات کمتری و همچنین محافظه‌کارانه‌تر از روش قبلی می‌باشد. \n\n\nimport statsmodels.stats.multitest as stest \n\npVal = [0.0001, 0.001, .01, 0.1, 0.08, 0.09, 0.15, 0.21, 0.35, 0.55, 0.3, \n0.64, 0.77, 0.9, 0.03, 0.02, 0.09, 0.19, 0.21, 0.41]\n\nres = stest.multipletests(pVal, alpha = 0.05, method = \"fdr_by\")\n# python Result\nprint(res)\n\n(array([ True,  True, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False]), array([0.00719548, 0.0359774 , 0.23984931, 0.7994977 , 0.7994977 ,\n       0.7994977 , 1.        , 1.        , 1.        , 1.        ,\n       1.        , 1.        , 1.        , 1.        , 0.43172876,\n       0.35977397, 0.7994977 , 1.        , 1.        , 1.        ]), 0.0025613787765302876, 0.0025)\n\n\n\n\n# R Result\np.adjust(c(0.0001, 0.001, .01, 0.1, 0.08, 0.09, 0.15, 0.21, 0.35, 0.55, 0.3, \n0.64, 0.77, 0.9, 0.03, 0.02, 0.09, 0.19, 0.21, 0.41), method = \"BY\")\n\n [1] 0.007195479 0.035977397 0.239849310 0.799497702 0.799497702 0.799497702\n [7] 1.000000000 1.000000000 1.000000000 1.000000000 1.000000000 1.000000000\n[13] 1.000000000 1.000000000 0.431728759 0.359773966 0.799497702 1.000000000\n[19] 1.000000000 1.000000000"
  },
  {
    "objectID": "Pvalue.html#false-discovery-rate-fdr-method-for-correcting-type-1-error-in-multiple-tests",
    "href": "Pvalue.html#false-discovery-rate-fdr-method-for-correcting-type-1-error-in-multiple-tests",
    "title": "",
    "section": "False Discovery Rate (FDR) Method for correcting type 1 error in multiple tests",
    "text": "False Discovery Rate (FDR) Method for correcting type 1 error in multiple tests\n\n\n\nروش FDR  برای تصحیح خطای  نوع اول در آزمون‌های چند‌گانه\n\n\nدو روش آخری که در بالا ذکر شد، یک زیر‌مجموعه از مجموعه‌ روش‌های تصحیح خطا نوع اول با رویکرد اصطلاحا FDR  می‌باشد که در بالا یک اشاره کوتاه به آن شد، اگر بخواهیم به شکل خیلی ساده‌ترین مجموعه روش‌های FDR  را بیان کنیم که البته زیر‌مجموعه‌‌های آن قطعا دارای تفاوت‌هایی هستند، می‌توانیم به این شکل بیان کنیم؛ فرض کنیم مقادیر pvalue  به‌دست آمده از آزمون‌ها که از کوچک به بزرگ مرتب شده‌اند به صورت زیر هستند\n\n\\[\nP_{value}: ~~\\left\\{p_{(1)}, p_{(2)}, \\dots, p_{(m)}\\right\\}\n\\]\n\nاگر مانند قبل فرض‌‌های صفر متناظر با مقادیر pvalue  ذکر شده در بالا، عبارت باشد از\n\n\\[\n\\text{H} = \\left\\{H_{(1)}, H_{(2)}, ..., H_{(m)}\\right\\},\n\\]\n\nبرای برآورد pvalue  اصلاح شده به شکل زیر عمل می‌کنیم؛\n\n\n\\[\np_{(i)}^{(FDR)} = \\frac{m}{i} \\times p_{(i)} \\implies \\text{if}~~~ p_{(i)}^{(FDR)} \\leq \\alpha_{Initial} ~~ \\text{Reject}~H_i\n\\]\n\nکه در این‌جا مقدار m اشاره به تعداد مقایسه‌های چند‌گانه‌ای هست که می‌خواهیم انجام دهیم. \n\n\nمثال: \n\n\nimport statsmodels.stats.multitest as stest \n\npVal = [0.0001, 0.001, .01, 0.1, 0.08, 0.09, 0.15, 0.21, 0.35, 0.55, 0.3, \n0.64, 0.77, 0.9, 0.03, 0.02, 0.09, 0.19, 0.21, 0.41]\n\nres = stest.fdrcorrection(pVal, alpha = 0.05, method = \"indep\")\n# python Result\nprint(res)\n\n(array([ True,  True, False, False, False, False, False, False, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False]), array([0.002     , 0.01      , 0.06666667, 0.22222222, 0.22222222,\n       0.22222222, 0.3       , 0.32307692, 0.46666667, 0.64705882,\n       0.42857143, 0.71111111, 0.81052632, 0.9       , 0.12      ,\n       0.1       , 0.22222222, 0.32307692, 0.32307692, 0.5125    ]))\n\n\n\n\n# R Result\np.adjust(c(0.0001, 0.001, .01, 0.1, 0.08, 0.09, 0.15, 0.21, 0.35, 0.55, 0.3, \n0.64, 0.77, 0.9, 0.03, 0.02, 0.09, 0.19, 0.21, 0.41), method = \"fdr\")\n\n [1] 0.00200000 0.01000000 0.06666667 0.22222222 0.22222222 0.22222222\n [7] 0.30000000 0.32307692 0.46666667 0.64705882 0.42857143 0.71111111\n[13] 0.81052632 0.90000000 0.12000000 0.10000000 0.22222222 0.32307692\n[19] 0.32307692 0.51250000\n\n\n\n\nتابع statsmodels.stats.multitest.fdrcorrection   در حقیقت یک ابزار دیگر پایتون برای پیاده‌سازی همان  دو روش قبلی  (BH, BY)  هست؛ این تابع \nبرای آرگومان method پنج‌تا مقدار می تواند بگیرد که نتایج به دست آمده بر‌اساس هر کدام از مقادیر ذکر شده در راهنمای این تابع، یا نتایج روش BH  را دارد یا نتایج روش BY .\nهمان‌طور که می‌بینیم خروجی روش fdr  در R  نتیجه پیاده‌سازی روش BH  را دارد، در حقیقت وجود fdr  به عنوان یک آرگومان ضرورتی ندارد. البته برای روش‌های مستقر شده بر‌روی مفهوم FDR  تیب‌شیرانی نیز روش‌هایی مبتنی بر BH, BY  ارائه داده هست که از طریق بسته statsmodels  قابل دسترس هستند. برای جزئیات آرگومان‌های تابع ذکر شده در statsmodels  می‌توانید به این لینک مراجعه کنید."
  },
  {
    "objectID": "Pvalue.html#posthoc-tests-with-adjusted-pvalue",
    "href": "Pvalue.html#posthoc-tests-with-adjusted-pvalue",
    "title": "",
    "section": "PostHoc Tests With Adjusted Pvalue",
    "text": "PostHoc Tests With Adjusted Pvalue\n\n\n\nپیاده‌سازی آزمون‌های تعقیبی با مقادیر اصلاح شده pvalue \n\nدر این‌جا با استفاده از یک مجموعه داده ساده یعنی همان داده‌های Iris  پیاده‌سازی متدهای ذکر شده را نشان خواهیم داد \nبرای دسترسی به داده‌‌های iris  در پایتون من از بسته reticulate  استفاده می‌کنم، البته داده‌های iris  در پایتون موجود هست هم در بسته scikit-learn   و هم در کتابخانه statsmodels  ولی من برای این گزارش این روش را انتخاب کرده‌ام. \n\n\n## for use iris data in python \nlibrary(reticulate)\npathh &lt;- Sys.which(\"python\") |&gt;\n            gsub(\"\\\\\", \"//\", x = _,  fixed = TRUE)\nuse_python(pathh)\n\n\n\n## use python \nimport statsmodels.formula.api as sfa\nimport scikit_posthocs as sp\ndat = r.iris.copy()\ndat.columns = dat.columns.str.replace(\".\", \"\")\n\n&lt;string&gt;:1: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n\nprint(dat.head(10))\n\n   SepalLength  SepalWidth  PetalLength  PetalWidth Species\n0          5.1         3.5          1.4         0.2  setosa\n1          4.9         3.0          1.4         0.2  setosa\n2          4.7         3.2          1.3         0.2  setosa\n3          4.6         3.1          1.5         0.2  setosa\n4          5.0         3.6          1.4         0.2  setosa\n5          5.4         3.9          1.7         0.4  setosa\n6          4.6         3.4          1.4         0.3  setosa\n7          5.0         3.4          1.5         0.2  setosa\n8          4.4         2.9          1.4         0.2  setosa\n9          4.9         3.1          1.5         0.1  setosa\n\n\n\n## pairwise comparison use ttest \n\nsp.posthoc_ttest(dat, val_col = 'SepalWidth', group_col = 'Species', \np_adjust = \"bonferroni\").round(4)\n\n            setosa  versicolor  virginica\nsetosa         1.0      0.0000     0.0000\nversicolor     0.0      1.0000     0.0055\nvirginica      0.0      0.0055     1.0000\n\n\"\"\"p_adjust: \n    bonferroni : one-step correction\n\n    sidak : one-step correction\n\n    holm-sidak : step down method using Sidak adjustments\n\n    holm : step-down method using Bonferroni adjustments\n\n    simes-hochberg : step-up method (independent)\n\n    hommel : closed method based on Simes tests (non-negative)\n\n    fdr_bh : Benjamini/Hochberg (non-negative)\n\n    fdr_by : Benjamini/Yekutieli (negative)\n\n    fdr_tsbh : two stage fdr correction (non-negative)\n\n    fdr_tsbky : two stage fdr correction (non-negative)\n\"\"\"\n\n'p_adjust: \\n    bonferroni : one-step correction\\n\\n    sidak : one-step correction\\n\\n    holm-sidak : step down method using Sidak adjustments\\n\\n    holm : step-down method using Bonferroni adjustments\\n\\n    simes-hochberg : step-up method (independent)\\n\\n    hommel : closed method based on Simes tests (non-negative)\\n\\n    fdr_bh : Benjamini/Hochberg (non-negative)\\n\\n    fdr_by : Benjamini/Yekutieli (negative)\\n\\n    fdr_tsbh : two stage fdr correction (non-negative)\\n\\n    fdr_tsbky : two stage fdr correction (non-negative)\\n'\n\n## NonParametric pairwise test----\nsp.posthoc_mannwhitney(a = dat, val_col = 'SepalWidth', group_col = \"Species\", \np_adjust = \"fdr_by\").round(4)\n\n            setosa  versicolor  virginica\nsetosa         1.0      0.0000     0.0000\nversicolor     0.0      1.0000     0.0084\nvirginica      0.0      0.0084     1.0000\n\n\n\n\n## R: pairwise Ttest\npairwise.t.test(x = iris$Sepal.Width, g = iris$Species, \np.adjust.method = \"bonferroni\", pool.sd = F) |&gt; \n_$p.value |&gt; \nround(4)\n\n           setosa versicolor\nversicolor      0         NA\nvirginica       0     0.0055\n\n## R: pairwise wilcoxon test\npairwise.wilcox.test(x = iris$Sepal.Width, g = iris$Species, \np.adjust.method = \"BY\") |&gt;\n_$p.value |&gt;\nround(4)\n\n           setosa versicolor\nversicolor      0         NA\nvirginica       0     0.0084\n\n\n\nواضح هست که نتایج گزارش شده در هر دو پلتفرم (R, python)   یکسان هست."
  },
  {
    "objectID": "Pvalue.html#references",
    "href": "Pvalue.html#references",
    "title": "",
    "section": "References",
    "text": "References\n\n\n\nمنابع\n\n\nHsu JC. Multiple comparisons: theory and methods. London: Chapman & Hall: CRC Press, 1996. [Google Scholar]\nBender R, Lange S. Adjusting for multiple testing—when and how? J Clin Epidemiol 2001;54:343-9. 10.1016/S0895-4356(00)00314-0 [Google Scholar]\nThiese MS, Ronna B, Ott U. P value interpretations and considerations. J Thorac Dis 2016;8:E928-E931. 10.21037/jtd.2016.08.16 [Google Scholar]\nFarcomeni A. A review of modern multiple hypothesis testing, with particular attention to the false discovery proportion. Stat Methods Med Res 2008;17:347-88. 10.1177/0962280206079046 [Google Scholar]\nBland JM, Altman DG. Multiple significance tests: the Bonferroni method. BMJ 1995;310:170. 10.1136/bmj.310.6973.170 [Google Scholar]\nHolm M. A simple sequentially rejective multiple test procedure. Scand J Statist 1979;6:65-70. [Google Scholar]\nHochberg Y. A sharper Bonferroni procedure for multiple tests of significance. Biometrika 1988;75:800-2. 10.1093/biomet/75.4.800 [Google Scholar]\nSimes RJ. An improved Bonferroni procedure for multiple tests of significance. Biometrika 1986;73:751-4. 10.1093/biomet/73.3.751 [Google Scholar]\nHommel G. A stagewise rejective multiple test procedure based on a modified Bonferroni test. Biometrika 1988;75:383-6. 10.1093/biomet/75.2.383 [Google Scholar]\nBenjamini Y, Hochberg Y. Controlling the false discovery rate: a practical and powerful approach to multiple testing. J R Stat Soc Series B Stat Methodol 1995;57:289-300. [Google Scholar]\nBenjamini Y, Yekutieli D. The control of the false discovery rate in multiple testing under dependency. Ann Stat 2001;29:1165-88. [Google Scholar]"
  },
  {
    "objectID": "BlueSky.html#links-downloads",
    "href": "BlueSky.html#links-downloads",
    "title": "A project to expand the R user community",
    "section": "Links (Downloads)",
    "text": "Links (Downloads)\n\n\n\nلینک دانلود ویدئو‌ها\n\n\n\n\n\n\n\n\n\n لینک اول: نحوه نصب نرم‌افزار \n لینک دوم: یک مقدمه بر نرم‌افزار \nلینک سوم: نحوه ورود داده‌ها به نرم‌افزار. \nلینک چهارم: ترسیم نمودار StripPlot با نرم‌افزار. \nلینک پنجم: نمودار میله‌ای\n لینک ششم: نمودار جعبه‌ای \n لینک هفتم: نمودار کانتور پلات \n لینک هشتم: نمودار‌های بررسی توزیع (منحنی چگالی، نمودار چندک‌چندک و نمودار احتمال‌احتمال).\n لینک نهم:‌ نمودار HeatMap \nلینک دهم: نمودار LineChart\n لینک یازدهم: ترسیم Map و PieChart \nلینک دوازدهم: نمودار ScatterPlot و ViolinPlot\nلینک سیزدهم:‌ یک مقایسه با SPSS\n لینک چهاردهم: تولید داده تصادفی در نرم‌افزار BlueSky به‌همراه بررسی خوبی و برازندگی داده‌ها با یک توزیع خاص و آزمون نرمالیتی به همراه مقایسه با نرم‌افزار SPSS \nلینک پانزدهم: آزمون Ttest در BlueSky و SPSS به همراه Reshape کردن داده‌ها\nلینک شانزدهم: آنالیز واریانس، قسمت اول\nلینک هفدهم: آنالیز واریانس، قسمت دوم؛ به همراه مقایسه با نرم‌افزار SPSS\nلینک هجدهم: آنالیز کواریانس؛ به همراه مقایسه با نرم‌افزار SPSS\n لینک نوزدهم: آنالیز واریانس چند متغیره به همراه مقایسه با نرم‌افزار SPSS یا همان (MANOVA)\n لینک بیستم: تحلیل داده‌های با اندازه‌گیری مکرر (Repeated Measure Anova) به همراه مقایسه با نرم‌افزار SPSS قسمت اول\nلینک بیست و یکم: تحلیل داده‌‌های اندازه‌گیری مکرر (Repeated Measure Anova) و همچنین تغییر شکل داده‌ها از حالت Long به Wide  و برعکس به همراه مقایسه با نرم‌افزار SPSS، قسمت دوم\n لینک بیست و دوم: آزمون کای دو برای جداول توافقی و آزمون مک‌نمار قسمت اول \n لینک بیست و سوم: آزمون کای دو، مقایسه با نرم‌افزار SPSS  قسمت دوم\n لینک بیست و چهارم: آزمون کرسکال‌والیس و آزمون فریدمن به همراه مقایسه با نرم‌افزار SPSS\nلینک بیست و پنجم: آزمون ویلکاکسون به همراه مقایسه با نرم‌افزار SPSS\n لینک بیست و ششم: Compute Variables\n لینک بیست و هفتم: رگرسیون خطی با نرم‌‌افزار BlueSky Statistics\nلینک بیست و هشتم: رگرسیون لوجستیک و ترسیم نمودار ROC   برای رگرسیون لوجستیک به همراه  پیاده‌سازی آزمون Hosmer LemeShow و ماتریس آشتفتگی (Confusion Matrix) مدل\nلینک بیست و نهم: مقایسه مدل‌ها، پیاده‌سازی مدل های طبقه‌بندی و همچنین استفاده از شبکه‌های عصبی به همراه به دست آوردن مقادیر احتمال برآورد شده مدل‌ها و مقایسه نمودارهای ROC برای وقتی که متغیر پاسخ باینری هست. \n\nلینک سی‌ام: ماتریس همبستگی و آزمون همبستگی در BlueSky Statistics \nلینک سی‌ و یکم: فیلتر کردن داده‌ها در BlueSky Statistics \n\nلینک سی و دوم: تحلیل بقا در BlueSky Statistics، منحنی کاپلان-میر و رگرسیون کاکس"
  },
  {
    "objectID": "BlueSky.html#notes",
    "href": "BlueSky.html#notes",
    "title": "A project to expand the R user community",
    "section": "Notes",
    "text": "Notes\n\n\nچند نکته\n\n\n\n\nقطعا ویدئوهای ضبط شده حاوی اشکالاتی خواهند بود. \n\n\n\nرابط کاربری وبسایت BlueSky Statistics  در همین یک‌ماه اخیر دچار تغییرات جدی شده هست. و ویدئو مربوط به طریقه دانلود این نرم‌افزار از طریق وبسایت این کمپانی  منطبق بر‌رابط کاربری الان وبسایت نیست، البته قطعا دانلود کردن نرم‌افزار به صورت مستقیم از طریق وبسایت این‌ کمپانی کار سختی نیست. ولی گفتن این‌نکته از نظر من ضرورت داشت. در حال حاضر وبسایت از شما می‌خواهد که حتما یک اکانت ایجاد کنید و سپس وارد اکانت خودتون شوید و سپس نرم‌افزار را دانلود کنید. البته من لینک آخرین ورژن از این نرم‌افزار که در حال حاضر 10-3-2  می‌باشد نیز در همین صفحه قرار داده‌ام.  \n\nاز دوستانی که ویدئوها را تماشا می‌کنند و اشکالات تکنیکی یا تئوری را از طریق ایمیل برای من یاد‌آور می‌شوند، صمیمانه سپاسگذاری می‌کنم. \n\nهمان‌طور که در جلسات ضبط شده ذکر شد، من یک فایل برای تصحیح مقادیر pvalue  نیز آماده کرده‌ام که در این صفحه می‌توانید ببیند. \n\n\nهمان‌طور که در ویدئوهای مربوطه به آنالیز واریانس درباره‌ی آن صحبت شد، نحوه به دست آوردن مربعات تیماری بر چهار نوع می‌باشد. که من در این صفحه راجع به جزئیات این موضوع اشاره کرده‌ام."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "\nدرباره من\n",
    "section": "",
    "text": "درباره من\n\n\n\n\nسلام. من حبیب عزت‌آبادی هستم، دانشجوی کارشناسی ارشد دانشگاه علوم پزشکی شیراز. \nاین صفحه به منظور معرفی فعالیت‌های من درون گیت‌هاب طراحی شده هست. \n\nاین وبسایت با استفاده از  Quarto   کمی  CSS    و   HTML     و البته سخاوت گیت‌هاب برای ایجاد امکاناتی جهت پیاده‌سازی یک وبسایت شخصی بر‌روی این پلتفرم شکل گرفته هست. \n\n  \n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Anova-SS.html",
    "href": "Anova-SS.html",
    "title": "",
    "section": "",
    "text": "آنالیز واریانس از ابداعات رونالد فیشر هست"
  },
  {
    "objectID": "Anova-SS.html#about-anova",
    "href": "Anova-SS.html#about-anova",
    "title": "",
    "section": "About Anova",
    "text": "About Anova\n\n\nدرباره آنالیز واریانس\n\n\nآنالیز واریانس یا در اصطلاح آن Anova  یک فرآیند آماری برای تجزیه و تحلیل مقدار واریانس است که برای بررسی اثرات عامل‌های مختلف بر‌روی یک ویژگی خاص (متغیرپاسخ هدف ما) که باید یک کمیت پیوسته و دارای شرایط خاصی باشد به کار می رود. این روش \nدر ابتدا توسط رونالد فیشر در سال ۱۹۲۵ برای یک مدل   طرح آزمایش متعادل ابداع شد. \nAnova  از آن‌جهت می‌تواند در تحقیقات اهمیت داشته باشد که ابزار لازم برای مقایسه بیش از دو گروه را به طور همزمان برای تعیین این‌که اصولا تفاوت معناداری بین گروه‌ها وجود دارد یا خیر، فراهم می‌کند. برای جزئیات بیشتر در مورد این روش آماری می‌توانید از این لینک بازدید کنید."
  },
  {
    "objectID": "Anova-SS.html#types-of-ss-calculation-methods-in-anova",
    "href": "Anova-SS.html#types-of-ss-calculation-methods-in-anova",
    "title": "",
    "section": "Types of SS Calculation methods in Anova",
    "text": "Types of SS Calculation methods in Anova\n\n\n\nانواع روش‌های محاسبه مربعات تیماری\n\n\nهنگامی که داده‌ها نامعادل هستند یعنی توزیع مشاهدات در سطوح عوامل با هم یکسان نیست، ۴ رویکرد متفاوت برای به‌دست آوردن مجموع مربعات وجود دارد. که ۳ تای آن‌ها پر‌کابرد‌تر می‌باشند. که با نماد \n\n\nType I\n\n\nType II\n\n\nType III\n\n\nType IV\n\n\nمشخص می‌شوند. آن طور که مشخص هست، این نمادها از نرم‌افزار SAS  وارد ادبیات آماری شده‌اند، که البته در حال‌حاضر خیلی پر‌استفاده شده‌اند. نکته‌ای که وجود دارد، این‌هست که چه زمانی باید از هر کدام از این روش‌ها استفاده کرد که خود محل بحث‌های زیادی در ادبیات آماری بوده هست. ولی در حالت کلی بر‌میگردد به این‌که ما چه فرضیات ابتدایی در مورد داده‌ها داریم و هدف ما بررسی چه چیزهایی هست. \nمدلی را در نظر بگیرید که شامل دو عامل A و B باشد. بنابراین دو اثر اصلی و یک اثر توأم AB  در مدل تحلیل شما می‌تواند وجود داشته باشد.  مدل کامل را با این نماد نشان می‌دهیم SS(A, B, AB) .  \nمدل‌های دیگری که برای این مثال فرضی ما می‌توانند وجود داشته باشند عبارتند از؛ SS(A, B)  مدلی که اثر توأم را در خود قرار نداده هست و یا مدلی که اثر اصلی عامل A را در نظر نمی‌گیرد، که با نماد SS(B, AB)  نشان داده می‌شود و ...\n یک روش برای این‌که بتوان تأثیر و یا معنادار بودن تأثیر، اثرات اصلی یا توأم را بررسی کرد، مقایسه مدل‌های حامل این اثرات و مدل‌هایی که این اثرات را در بر ندارند می‌باشد. مثلا در مثال ما اگر بخواهیم اثر AB  را بررسی کنیم می‌توانیم مدل‌های SS(A, B), SS(A, B, AB)  را با هم مقایسه کنیم.\n \n اگر بخواهیم تأثیر عامل‌های در حضور بقیه عوامل بسنجیم و یا افزایش مربعات را با اضافه کردن یک اثر در حضور بقیه اثرات بسنجیم می‌توانیم به شکل زیر آن را بیان کنیم؛\n\nSS(AB| A, B) = SS(A, B, AB) - SS(A, B)\nSS(A | B, AB) = SS(A, B, AB) – SS(B, AB)\nSS(B | A, AB) = SS(A, B, AB) – SS(A, AB)\nSS(A | B) = SS(A, B) – SS(B)\nSS(B | A) = SS(A, B) – SS(A)\n\nدر نمادهای بالا، منظور از فرضا SS(AB|A, B)  اشاره دارد به افزایشی که در مجموع مربعات تیماری حادث می‌شود وقتی در حضور اثرات اصلی A و B اثر توأم این دو را نیز اضافه کنیم و یا مثلا منظور از SS(B|A)  اشاره دارد به‌این‌که میزان افزایش در مربعات تیماری وقتی اثر اصلی A حضور دارد و ما اثر B را اضافه کنیم. \nدر این‌جاست که اصولا انواع مختلف محاسبه مجموع مربعات شکل می‌گیرد. یا به شکل شفاف‌تر نحوه تعریف اثرات هست که که باعث شکل‌گیری این تفاوت‌ها می‌شود."
  },
  {
    "objectID": "Anova-SS.html#type-i",
    "href": "Anova-SS.html#type-i",
    "title": "",
    "section": "Type I",
    "text": "Type I\n\n\nمجموع مربعات نوع ۱\n\n\n\nدر این شیوه، تعریف اثرات برای مثال فرضی که گفتیم به این شکل هست؛ \n\n\nSS(A): برای عامل A\n\n\nSS(B | A): برای عامل B\n\n\nSS(AB | B, A): برای اثر توأم AB\n\n\nعبارات بالا، این مفهوم را دارد که ابتدا اثر اصلی عامل A سپس اثر اصلی عامل  B و در انتها اثر متقابل AB مورد بررسی قرار می‌گیرند. \nبه دلیل ماهیت سلسله مراتبی و این واقعیت که دو عامل اصلی به ترتیب خاصی مورد آزمایش قرار می‌گیرند. این نوع مجموع مربعات وابسته به این‌که کدام اثر اصلی ابتدا در نظر گرفته شود. نتایج متفاوتی برای داده‌های نامتعادل به همراه خواهد داشت. \n\nبرای داده‌ها نامتعادل  این رویکرد تفاوت در میانگین وزن‌‌های اثرات حاشیه‌ای  را مورد آزمایش قرار می‌دهد. از نظر عملی، این بدان‌معناست که نتایج به اندازه نمونه‌های محقق شده بستگی پیدا می کند، به‌عبارت دیگر اولین عامل را بدون کنترل عامل دیگر آزمایش می‌کند. برای جزئیات بیشتر می‌توانید به [1] مراجعه کنید. \n\nاین شیوه اصولا برای طرح‌های نامتعادل پیشنهاد نمی شود. \n\n\n\nمثال: \nمن برای مثال‌های که در این صفحه می‌خواهم بیاورم. از دو مجموعه داده استفاده کرده‌ام، یکی برای طرح متعادل هست و یکی برای به‌اصطلاح طرح نامتعادل. داده‌ها به صورت شبیه‌سازی شده هست. که کد وخروجی داده‌ها در ادامه خواهید دید. \n \nالبته با ذکر این‌نکته که خروجی به منظور نمایش داده‌ها و همچنین نشان دادن متعادل بودن یا نامتعادل بودن داده‌های طرح می‌باشد. \n\n\n\nshow the code\n## loading require package\nset.seed(1)\nlibrary(tidyverse)\nlibrary(AlgDesign)\nlibrary(splitstackshape)\nlibrary(kableExtra)\n\n## To create a design with 3 factors and a specified number of levels\nDesign_factorial &lt;- gen.factorial(levels = c(4, 3, 5), nVars = 3, \nvarNames = c(\"Fac1\", \"Fac2\", \"Fac3\"), center = FALSE)\nAnova_data &lt;- purrr :: map_dfr(seq_len(4), ~Design_factorial)\ny &lt;- Anova_data %&gt;%\n        apply(., MARGIN = 1, function(x) prod(x)) %&gt;%\n        unlist %&gt;%\n        rnorm(n = 240, mean = ., sd = 1) %&gt;% \n        round(2)\n\n\n## To simulate data for a balanced design\nanova_data_Balanced &lt;- Anova_data %&gt;%\n    mutate(across(starts_with(\"Fac\"), ~ as.factor(.x))) %&gt;%\n    mutate(Fac1 = fct_recode(Fac1, \n            A = \"1\", B = \"2\", C = \"3\", D = \"4\"), \n            Fac2 = fct_recode(Fac2, Level_1 = \"1\", \n            Level_2 = \"2\", Level_3 = \"3\"), \n            Fac3 = fct_recode(Fac3, Timar_1 = \"1\", Timar_2 = \"2\", \n            Timar_3 = \"3\", Timar_4 = \"4\", Timar_5 = \"5\")) %&gt;%\n            mutate(y = y) %&gt;%\n            relocate(y, .before = Fac1)\n\n\n\n\n## To simulate data for a Unbalanced design\nset.seed(1)\nCount &lt;- sample(c(2, 3, 4, 5, 6, 7), size = 60, replace = TRUE)\nlibrary(data.table)\ndat &lt;- as.data.table(Design_factorial)\nAnova_data_unbalanced &lt;- dat %&gt;% expandRows(count = get(\"Count\"), count.is.col = FALSE, drop = TRUE)\n\n\nset.seed(1)\ny_unbalanced &lt;- Anova_data_unbalanced %&gt;%\n        apply(., MARGIN = 1, function(x) prod(x)) %&gt;%\n        unlist %&gt;%\n        rnorm(n = 269, mean = ., sd = 1) %&gt;% \n        round(2)\n\nAnova_data_unbalanced &lt;- Anova_data_unbalanced %&gt;%\n    mutate(across(starts_with(\"Fac\"), ~ as.factor(.x))) %&gt;%\n    mutate(Fac1 = fct_recode(Fac1, \n            A = \"1\", B = \"2\", C = \"3\", D = \"4\"), \n            Fac2 = fct_recode(Fac2, Level_1 = \"1\", \n            Level_2 = \"2\", Level_3 = \"3\"), \n            Fac3 = fct_recode(Fac3, Timar_1 = \"1\", Timar_2 = \"2\", \n            Timar_3 = \"3\", Timar_4 = \"4\", Timar_5 = \"5\")) %&gt;%\n            mutate(y = y_unbalanced) %&gt;%\n            relocate(y, .before = Fac1)\n\n## To prove that the data is balanced\nanova_data_Balanced %&gt;%\nmutate(Interaction = interaction(Fac1, Fac2, Fac3)) %&gt;%\ncount(., Interaction) %&gt;%\nkbl(caption = \"To prove that the data is balanced\") %&gt;%\nkable_paper(\"hover\", full_width = F) %&gt;%\n  scroll_box(width = \"500px\", height = \"200px\")\n\n\n\n\nTo prove that the data is balanced\n\n\nInteraction\nn\n\n\n\n\nA.Level_1.Timar_1\n4\n\n\nB.Level_1.Timar_1\n4\n\n\nC.Level_1.Timar_1\n4\n\n\nD.Level_1.Timar_1\n4\n\n\nA.Level_2.Timar_1\n4\n\n\nB.Level_2.Timar_1\n4\n\n\nC.Level_2.Timar_1\n4\n\n\nD.Level_2.Timar_1\n4\n\n\nA.Level_3.Timar_1\n4\n\n\nB.Level_3.Timar_1\n4\n\n\nC.Level_3.Timar_1\n4\n\n\nD.Level_3.Timar_1\n4\n\n\nA.Level_1.Timar_2\n4\n\n\nB.Level_1.Timar_2\n4\n\n\nC.Level_1.Timar_2\n4\n\n\nD.Level_1.Timar_2\n4\n\n\nA.Level_2.Timar_2\n4\n\n\nB.Level_2.Timar_2\n4\n\n\nC.Level_2.Timar_2\n4\n\n\nD.Level_2.Timar_2\n4\n\n\nA.Level_3.Timar_2\n4\n\n\nB.Level_3.Timar_2\n4\n\n\nC.Level_3.Timar_2\n4\n\n\nD.Level_3.Timar_2\n4\n\n\nA.Level_1.Timar_3\n4\n\n\nB.Level_1.Timar_3\n4\n\n\nC.Level_1.Timar_3\n4\n\n\nD.Level_1.Timar_3\n4\n\n\nA.Level_2.Timar_3\n4\n\n\nB.Level_2.Timar_3\n4\n\n\nC.Level_2.Timar_3\n4\n\n\nD.Level_2.Timar_3\n4\n\n\nA.Level_3.Timar_3\n4\n\n\nB.Level_3.Timar_3\n4\n\n\nC.Level_3.Timar_3\n4\n\n\nD.Level_3.Timar_3\n4\n\n\nA.Level_1.Timar_4\n4\n\n\nB.Level_1.Timar_4\n4\n\n\nC.Level_1.Timar_4\n4\n\n\nD.Level_1.Timar_4\n4\n\n\nA.Level_2.Timar_4\n4\n\n\nB.Level_2.Timar_4\n4\n\n\nC.Level_2.Timar_4\n4\n\n\nD.Level_2.Timar_4\n4\n\n\nA.Level_3.Timar_4\n4\n\n\nB.Level_3.Timar_4\n4\n\n\nC.Level_3.Timar_4\n4\n\n\nD.Level_3.Timar_4\n4\n\n\nA.Level_1.Timar_5\n4\n\n\nB.Level_1.Timar_5\n4\n\n\nC.Level_1.Timar_5\n4\n\n\nD.Level_1.Timar_5\n4\n\n\nA.Level_2.Timar_5\n4\n\n\nB.Level_2.Timar_5\n4\n\n\nC.Level_2.Timar_5\n4\n\n\nD.Level_2.Timar_5\n4\n\n\nA.Level_3.Timar_5\n4\n\n\nB.Level_3.Timar_5\n4\n\n\nC.Level_3.Timar_5\n4\n\n\nD.Level_3.Timar_5\n4\n\n\n\n\n\n\n\nshow the code\n## to display balanced data\nkbl(anova_data_Balanced, caption = \"to display balanced data\") %&gt;%\nkable_paper(\"hover\", full_width = F) %&gt;%\n  scroll_box(width = \"500px\", height = \"200px\")\n\n\n\n\nto display balanced data\n\n\ny\nFac1\nFac2\nFac3\n\n\n\n\n0.37\nA\nLevel_1\nTimar_1\n\n\n2.18\nB\nLevel_1\nTimar_1\n\n\n2.16\nC\nLevel_1\nTimar_1\n\n\n5.60\nD\nLevel_1\nTimar_1\n\n\n2.33\nA\nLevel_2\nTimar_1\n\n\n3.18\nB\nLevel_2\nTimar_1\n\n\n6.49\nC\nLevel_2\nTimar_1\n\n\n8.74\nD\nLevel_2\nTimar_1\n\n\n3.58\nA\nLevel_3\nTimar_1\n\n\n5.69\nB\nLevel_3\nTimar_1\n\n\n10.51\nC\nLevel_3\nTimar_1\n\n\n12.39\nD\nLevel_3\nTimar_1\n\n\n1.38\nA\nLevel_1\nTimar_2\n\n\n1.79\nB\nLevel_1\nTimar_2\n\n\n7.12\nC\nLevel_1\nTimar_2\n\n\n7.96\nD\nLevel_1\nTimar_2\n\n\n3.98\nA\nLevel_2\nTimar_2\n\n\n8.94\nB\nLevel_2\nTimar_2\n\n\n12.82\nC\nLevel_2\nTimar_2\n\n\n16.59\nD\nLevel_2\nTimar_2\n\n\n6.92\nA\nLevel_3\nTimar_2\n\n\n12.78\nB\nLevel_3\nTimar_2\n\n\n18.07\nC\nLevel_3\nTimar_2\n\n\n22.01\nD\nLevel_3\nTimar_2\n\n\n3.62\nA\nLevel_1\nTimar_3\n\n\n5.94\nB\nLevel_1\nTimar_3\n\n\n8.84\nC\nLevel_1\nTimar_3\n\n\n10.53\nD\nLevel_1\nTimar_3\n\n\n5.52\nA\nLevel_2\nTimar_3\n\n\n12.42\nB\nLevel_2\nTimar_3\n\n\n19.36\nC\nLevel_2\nTimar_3\n\n\n23.90\nD\nLevel_2\nTimar_3\n\n\n9.39\nA\nLevel_3\nTimar_3\n\n\n17.95\nB\nLevel_3\nTimar_3\n\n\n25.62\nC\nLevel_3\nTimar_3\n\n\n35.59\nD\nLevel_3\nTimar_3\n\n\n3.61\nA\nLevel_1\nTimar_4\n\n\n7.94\nB\nLevel_1\nTimar_4\n\n\n13.10\nC\nLevel_1\nTimar_4\n\n\n16.76\nD\nLevel_1\nTimar_4\n\n\n7.84\nA\nLevel_2\nTimar_4\n\n\n15.75\nB\nLevel_2\nTimar_4\n\n\n24.70\nC\nLevel_2\nTimar_4\n\n\n32.56\nD\nLevel_2\nTimar_4\n\n\n11.31\nA\nLevel_3\nTimar_4\n\n\n23.29\nB\nLevel_3\nTimar_4\n\n\n36.36\nC\nLevel_3\nTimar_4\n\n\n48.77\nD\nLevel_3\nTimar_4\n\n\n4.89\nA\nLevel_1\nTimar_5\n\n\n10.88\nB\nLevel_1\nTimar_5\n\n\n15.40\nC\nLevel_1\nTimar_5\n\n\n19.39\nD\nLevel_1\nTimar_5\n\n\n10.34\nA\nLevel_2\nTimar_5\n\n\n18.87\nB\nLevel_2\nTimar_5\n\n\n31.43\nC\nLevel_2\nTimar_5\n\n\n41.98\nD\nLevel_2\nTimar_5\n\n\n14.63\nA\nLevel_3\nTimar_5\n\n\n28.96\nB\nLevel_3\nTimar_5\n\n\n45.57\nC\nLevel_3\nTimar_5\n\n\n59.86\nD\nLevel_3\nTimar_5\n\n\n3.40\nA\nLevel_1\nTimar_1\n\n\n1.96\nB\nLevel_1\nTimar_1\n\n\n3.69\nC\nLevel_1\nTimar_1\n\n\n4.03\nD\nLevel_1\nTimar_1\n\n\n1.26\nA\nLevel_2\nTimar_1\n\n\n4.19\nB\nLevel_2\nTimar_1\n\n\n4.20\nC\nLevel_2\nTimar_1\n\n\n9.47\nD\nLevel_2\nTimar_1\n\n\n3.15\nA\nLevel_3\nTimar_1\n\n\n8.17\nB\nLevel_3\nTimar_1\n\n\n9.48\nC\nLevel_3\nTimar_1\n\n\n11.29\nD\nLevel_3\nTimar_1\n\n\n2.61\nA\nLevel_1\nTimar_2\n\n\n3.07\nB\nLevel_1\nTimar_2\n\n\n4.75\nC\nLevel_1\nTimar_2\n\n\n8.29\nD\nLevel_1\nTimar_2\n\n\n3.56\nA\nLevel_2\nTimar_2\n\n\n8.00\nB\nLevel_2\nTimar_2\n\n\n12.07\nC\nLevel_2\nTimar_2\n\n\n15.41\nD\nLevel_2\nTimar_2\n\n\n5.43\nA\nLevel_3\nTimar_2\n\n\n11.86\nB\nLevel_3\nTimar_2\n\n\n19.18\nC\nLevel_3\nTimar_2\n\n\n22.48\nD\nLevel_3\nTimar_2\n\n\n3.59\nA\nLevel_1\nTimar_3\n\n\n6.33\nB\nLevel_1\nTimar_3\n\n\n10.06\nC\nLevel_1\nTimar_3\n\n\n11.70\nD\nLevel_1\nTimar_3\n\n\n6.37\nA\nLevel_2\nTimar_3\n\n\n12.27\nB\nLevel_2\nTimar_3\n\n\n17.46\nC\nLevel_2\nTimar_3\n\n\n25.21\nD\nLevel_2\nTimar_3\n\n\n10.16\nA\nLevel_3\nTimar_3\n\n\n18.70\nB\nLevel_3\nTimar_3\n\n\n28.59\nC\nLevel_3\nTimar_3\n\n\n36.56\nD\nLevel_3\nTimar_3\n\n\n2.72\nA\nLevel_1\nTimar_4\n\n\n7.43\nB\nLevel_1\nTimar_4\n\n\n10.78\nC\nLevel_1\nTimar_4\n\n\n15.53\nD\nLevel_1\nTimar_4\n\n\n7.38\nA\nLevel_2\nTimar_4\n\n\n16.04\nB\nLevel_2\nTimar_4\n\n\n23.09\nC\nLevel_2\nTimar_4\n\n\n32.16\nD\nLevel_2\nTimar_4\n\n\n11.35\nA\nLevel_3\nTimar_4\n\n\n25.77\nB\nLevel_3\nTimar_4\n\n\n36.72\nC\nLevel_3\nTimar_4\n\n\n48.91\nD\nLevel_3\nTimar_4\n\n\n5.38\nA\nLevel_1\nTimar_5\n\n\n11.68\nB\nLevel_1\nTimar_5\n\n\n14.36\nC\nLevel_1\nTimar_5\n\n\n19.54\nD\nLevel_1\nTimar_5\n\n\n11.43\nA\nLevel_2\nTimar_5\n\n\n19.35\nB\nLevel_2\nTimar_5\n\n\n29.79\nC\nLevel_2\nTimar_5\n\n\n39.61\nD\nLevel_2\nTimar_5\n\n\n14.68\nA\nLevel_3\nTimar_5\n\n\n29.72\nB\nLevel_3\nTimar_5\n\n\n45.49\nC\nLevel_3\nTimar_5\n\n\n59.82\nD\nLevel_3\nTimar_5\n\n\n0.49\nA\nLevel_1\nTimar_1\n\n\n3.34\nB\nLevel_1\nTimar_1\n\n\n2.79\nC\nLevel_1\nTimar_1\n\n\n3.82\nD\nLevel_1\nTimar_1\n\n\n1.90\nA\nLevel_2\nTimar_1\n\n\n4.71\nB\nLevel_2\nTimar_1\n\n\n5.93\nC\nLevel_2\nTimar_1\n\n\n7.96\nD\nLevel_2\nTimar_1\n\n\n2.32\nA\nLevel_3\nTimar_1\n\n\n5.68\nB\nLevel_3\nTimar_1\n\n\n9.06\nC\nLevel_3\nTimar_1\n\n\n11.41\nD\nLevel_3\nTimar_1\n\n\n2.53\nA\nLevel_1\nTimar_2\n\n\n2.48\nB\nLevel_1\nTimar_2\n\n\n6.31\nC\nLevel_1\nTimar_2\n\n\n6.46\nD\nLevel_1\nTimar_2\n\n\n3.70\nA\nLevel_2\nTimar_2\n\n\n7.47\nB\nLevel_2\nTimar_2\n\n\n11.35\nC\nLevel_2\nTimar_2\n\n\n15.94\nD\nLevel_2\nTimar_2\n\n\n4.09\nA\nLevel_3\nTimar_2\n\n\n13.18\nB\nLevel_3\nTimar_2\n\n\n16.34\nC\nLevel_3\nTimar_2\n\n\n23.54\nD\nLevel_3\nTimar_2\n\n\n1.88\nA\nLevel_1\nTimar_3\n\n\n5.25\nB\nLevel_1\nTimar_3\n\n\n11.09\nC\nLevel_1\nTimar_3\n\n\n12.02\nD\nLevel_1\nTimar_3\n\n\n4.71\nA\nLevel_2\nTimar_3\n\n\n10.36\nB\nLevel_2\nTimar_3\n\n\n18.45\nC\nLevel_2\nTimar_3\n\n\n23.98\nD\nLevel_2\nTimar_3\n\n\n8.68\nA\nLevel_3\nTimar_3\n\n\n17.07\nB\nLevel_3\nTimar_3\n\n\n25.51\nC\nLevel_3\nTimar_3\n\n\n34.92\nD\nLevel_3\nTimar_3\n\n\n5.00\nA\nLevel_1\nTimar_4\n\n\n7.38\nB\nLevel_1\nTimar_4\n\n\n10.62\nC\nLevel_1\nTimar_4\n\n\n17.87\nD\nLevel_1\nTimar_4\n\n\n8.43\nA\nLevel_2\nTimar_4\n\n\n15.76\nB\nLevel_2\nTimar_4\n\n\n25.06\nC\nLevel_2\nTimar_4\n\n\n32.89\nD\nLevel_2\nTimar_4\n\n\n11.38\nA\nLevel_3\nTimar_4\n\n\n26.21\nB\nLevel_3\nTimar_4\n\n\n35.74\nC\nLevel_3\nTimar_4\n\n\n46.58\nD\nLevel_3\nTimar_4\n\n\n4.86\nA\nLevel_1\nTimar_5\n\n\n10.21\nB\nLevel_1\nTimar_5\n\n\n17.31\nC\nLevel_1\nTimar_5\n\n\n20.11\nD\nLevel_1\nTimar_5\n\n\n10.46\nA\nLevel_2\nTimar_5\n\n\n19.92\nB\nLevel_2\nTimar_5\n\n\n29.67\nC\nLevel_2\nTimar_5\n\n\n39.97\nD\nLevel_2\nTimar_5\n\n\n15.79\nA\nLevel_3\nTimar_5\n\n\n32.08\nB\nLevel_3\nTimar_5\n\n\n46.03\nC\nLevel_3\nTimar_5\n\n\n61.21\nD\nLevel_3\nTimar_5\n\n\n-0.23\nA\nLevel_1\nTimar_1\n\n\n2.98\nB\nLevel_1\nTimar_1\n\n\n3.22\nC\nLevel_1\nTimar_1\n\n\n2.53\nD\nLevel_1\nTimar_1\n\n\n2.52\nA\nLevel_2\nTimar_1\n\n\n3.84\nB\nLevel_2\nTimar_1\n\n\n7.46\nC\nLevel_2\nTimar_1\n\n\n7.23\nD\nLevel_2\nTimar_1\n\n\n2.57\nA\nLevel_3\nTimar_1\n\n\n5.07\nB\nLevel_3\nTimar_1\n\n\n8.82\nC\nLevel_3\nTimar_1\n\n\n12.40\nD\nLevel_3\nTimar_1\n\n\n1.27\nA\nLevel_1\nTimar_2\n\n\n4.83\nB\nLevel_1\nTimar_2\n\n\n4.79\nC\nLevel_1\nTimar_2\n\n\n6.95\nD\nLevel_1\nTimar_2\n\n\n5.44\nA\nLevel_2\nTimar_2\n\n\n6.98\nB\nLevel_2\nTimar_2\n\n\n12.41\nC\nLevel_2\nTimar_2\n\n\n15.62\nD\nLevel_2\nTimar_2\n\n\n6.41\nA\nLevel_3\nTimar_2\n\n\n13.69\nB\nLevel_3\nTimar_2\n\n\n19.59\nC\nLevel_3\nTimar_2\n\n\n23.67\nD\nLevel_3\nTimar_2\n\n\n0.71\nA\nLevel_1\nTimar_3\n\n\n8.50\nB\nLevel_1\nTimar_3\n\n\n9.67\nC\nLevel_1\nTimar_3\n\n\n12.54\nD\nLevel_1\nTimar_3\n\n\n5.99\nA\nLevel_2\nTimar_3\n\n\n12.51\nB\nLevel_2\nTimar_3\n\n\n17.84\nC\nLevel_2\nTimar_3\n\n\n24.42\nD\nLevel_2\nTimar_3\n\n\n8.60\nA\nLevel_3\nTimar_3\n\n\n16.63\nB\nLevel_3\nTimar_3\n\n\n27.99\nC\nLevel_3\nTimar_3\n\n\n37.52\nD\nLevel_3\nTimar_3\n\n\n3.69\nA\nLevel_1\nTimar_4\n\n\n6.75\nB\nLevel_1\nTimar_4\n\n\n12.64\nC\nLevel_1\nTimar_4\n\n\n15.96\nD\nLevel_1\nTimar_4\n\n\n6.27\nA\nLevel_2\nTimar_4\n\n\n16.00\nB\nLevel_2\nTimar_4\n\n\n23.37\nC\nLevel_2\nTimar_4\n\n\n31.66\nD\nLevel_2\nTimar_4\n\n\n10.84\nA\nLevel_3\nTimar_4\n\n\n25.80\nB\nLevel_3\nTimar_4\n\n\n35.67\nC\nLevel_3\nTimar_4\n\n\n46.39\nD\nLevel_3\nTimar_4\n\n\n5.20\nA\nLevel_1\nTimar_5\n\n\n10.26\nB\nLevel_1\nTimar_5\n\n\n14.01\nC\nLevel_1\nTimar_5\n\n\n17.11\nD\nLevel_1\nTimar_5\n\n\n9.36\nA\nLevel_2\nTimar_5\n\n\n20.57\nB\nLevel_2\nTimar_5\n\n\n29.94\nC\nLevel_2\nTimar_5\n\n\n39.90\nD\nLevel_2\nTimar_5\n\n\n15.56\nA\nLevel_3\nTimar_5\n\n\n28.81\nB\nLevel_3\nTimar_5\n\n\n46.10\nC\nLevel_3\nTimar_5\n\n\n59.99\nD\nLevel_3\nTimar_5\n\n\n\n\n\n\n\nshow the code\n## To prove that the data is unbalanced\nAnova_data_unbalanced %&gt;%\nmutate(Interaction = interaction(Fac1, Fac2, Fac3)) %&gt;%\ncount(., Interaction) %&gt;%\nkbl(caption = \"To prove that the data is unbalanced\") %&gt;%\nkable_paper(\"hover\", full_width = F) %&gt;%\n  scroll_box(width = \"500px\", height = \"200px\")\n\n\n\n\nTo prove that the data is unbalanced\n\n\nInteraction\nn\n\n\n\n\nA.Level_1.Timar_1\n2\n\n\nB.Level_1.Timar_1\n5\n\n\nC.Level_1.Timar_1\n2\n\n\nD.Level_1.Timar_1\n3\n\n\nA.Level_2.Timar_1\n6\n\n\nB.Level_2.Timar_1\n4\n\n\nC.Level_2.Timar_1\n7\n\n\nD.Level_2.Timar_1\n3\n\n\nA.Level_3.Timar_1\n4\n\n\nB.Level_3.Timar_1\n4\n\n\nC.Level_3.Timar_1\n2\n\n\nD.Level_3.Timar_1\n6\n\n\nA.Level_1.Timar_2\n6\n\n\nB.Level_1.Timar_2\n3\n\n\nC.Level_1.Timar_2\n7\n\n\nD.Level_1.Timar_2\n7\n\n\nA.Level_2.Timar_2\n3\n\n\nB.Level_2.Timar_2\n2\n\n\nC.Level_2.Timar_2\n6\n\n\nD.Level_2.Timar_2\n6\n\n\nA.Level_3.Timar_2\n2\n\n\nB.Level_3.Timar_2\n2\n\n\nC.Level_3.Timar_2\n7\n\n\nD.Level_3.Timar_2\n6\n\n\nA.Level_1.Timar_3\n6\n\n\nB.Level_1.Timar_3\n3\n\n\nC.Level_1.Timar_3\n3\n\n\nD.Level_1.Timar_3\n7\n\n\nA.Level_2.Timar_3\n2\n\n\nB.Level_2.Timar_3\n5\n\n\nC.Level_2.Timar_3\n2\n\n\nD.Level_2.Timar_3\n5\n\n\nA.Level_3.Timar_3\n4\n\n\nB.Level_3.Timar_3\n7\n\n\nC.Level_3.Timar_3\n3\n\n\nD.Level_3.Timar_3\n3\n\n\nA.Level_1.Timar_4\n7\n\n\nB.Level_1.Timar_4\n5\n\n\nC.Level_1.Timar_4\n5\n\n\nD.Level_1.Timar_4\n5\n\n\nA.Level_2.Timar_4\n3\n\n\nB.Level_2.Timar_4\n5\n\n\nC.Level_2.Timar_4\n2\n\n\nD.Level_2.Timar_4\n7\n\n\nA.Level_3.Timar_4\n2\n\n\nB.Level_3.Timar_4\n5\n\n\nC.Level_3.Timar_4\n2\n\n\nD.Level_3.Timar_4\n7\n\n\nA.Level_1.Timar_5\n3\n\n\nB.Level_1.Timar_5\n4\n\n\nC.Level_1.Timar_5\n3\n\n\nD.Level_1.Timar_5\n7\n\n\nA.Level_2.Timar_5\n7\n\n\nB.Level_2.Timar_5\n3\n\n\nC.Level_2.Timar_5\n6\n\n\nD.Level_2.Timar_5\n3\n\n\nA.Level_3.Timar_5\n7\n\n\nB.Level_3.Timar_5\n7\n\n\nC.Level_3.Timar_5\n7\n\n\nD.Level_3.Timar_5\n2\n\n\n\n\n\n\n\nshow the code\n## To display unbalanced data\nkbl(Anova_data_unbalanced, caption = \"To display unbalanced data\") %&gt;%\nkable_paper(\"hover\", full_width = F) %&gt;%\n  scroll_box(width = \"500px\", height = \"200px\")\n\n\n\n\nTo display unbalanced data\n\n\ny\nFac1\nFac2\nFac3\n\n\n\n\n0.37\nA\nLevel_1\nTimar_1\n\n\n1.18\nA\nLevel_1\nTimar_1\n\n\n1.16\nB\nLevel_1\nTimar_1\n\n\n3.60\nB\nLevel_1\nTimar_1\n\n\n2.33\nB\nLevel_1\nTimar_1\n\n\n1.18\nB\nLevel_1\nTimar_1\n\n\n2.49\nB\nLevel_1\nTimar_1\n\n\n3.74\nC\nLevel_1\nTimar_1\n\n\n3.58\nC\nLevel_1\nTimar_1\n\n\n3.69\nD\nLevel_1\nTimar_1\n\n\n5.51\nD\nLevel_1\nTimar_1\n\n\n4.39\nD\nLevel_1\nTimar_1\n\n\n1.38\nA\nLevel_2\nTimar_1\n\n\n-0.21\nA\nLevel_2\nTimar_1\n\n\n3.12\nA\nLevel_2\nTimar_1\n\n\n1.96\nA\nLevel_2\nTimar_1\n\n\n1.98\nA\nLevel_2\nTimar_1\n\n\n2.94\nA\nLevel_2\nTimar_1\n\n\n4.82\nB\nLevel_2\nTimar_1\n\n\n4.59\nB\nLevel_2\nTimar_1\n\n\n4.92\nB\nLevel_2\nTimar_1\n\n\n4.78\nB\nLevel_2\nTimar_1\n\n\n6.07\nC\nLevel_2\nTimar_1\n\n\n4.01\nC\nLevel_2\nTimar_1\n\n\n6.62\nC\nLevel_2\nTimar_1\n\n\n5.94\nC\nLevel_2\nTimar_1\n\n\n5.84\nC\nLevel_2\nTimar_1\n\n\n4.53\nC\nLevel_2\nTimar_1\n\n\n5.52\nC\nLevel_2\nTimar_1\n\n\n8.42\nD\nLevel_2\nTimar_1\n\n\n9.36\nD\nLevel_2\nTimar_1\n\n\n7.90\nD\nLevel_2\nTimar_1\n\n\n3.39\nA\nLevel_3\nTimar_1\n\n\n2.95\nA\nLevel_3\nTimar_1\n\n\n1.62\nA\nLevel_3\nTimar_1\n\n\n2.59\nA\nLevel_3\nTimar_1\n\n\n5.61\nB\nLevel_3\nTimar_1\n\n\n5.94\nB\nLevel_3\nTimar_1\n\n\n7.10\nB\nLevel_3\nTimar_1\n\n\n6.76\nB\nLevel_3\nTimar_1\n\n\n8.84\nC\nLevel_3\nTimar_1\n\n\n8.75\nC\nLevel_3\nTimar_1\n\n\n12.70\nD\nLevel_3\nTimar_1\n\n\n12.56\nD\nLevel_3\nTimar_1\n\n\n11.31\nD\nLevel_3\nTimar_1\n\n\n11.29\nD\nLevel_3\nTimar_1\n\n\n12.36\nD\nLevel_3\nTimar_1\n\n\n12.77\nD\nLevel_3\nTimar_1\n\n\n1.89\nA\nLevel_1\nTimar_2\n\n\n2.88\nA\nLevel_1\nTimar_2\n\n\n2.40\nA\nLevel_1\nTimar_2\n\n\n1.39\nA\nLevel_1\nTimar_2\n\n\n2.34\nA\nLevel_1\nTimar_2\n\n\n0.87\nA\nLevel_1\nTimar_2\n\n\n5.43\nB\nLevel_1\nTimar_2\n\n\n5.98\nB\nLevel_1\nTimar_2\n\n\n3.63\nB\nLevel_1\nTimar_2\n\n\n4.96\nC\nLevel_1\nTimar_2\n\n\n6.57\nC\nLevel_1\nTimar_2\n\n\n5.86\nC\nLevel_1\nTimar_2\n\n\n8.40\nC\nLevel_1\nTimar_2\n\n\n5.96\nC\nLevel_1\nTimar_2\n\n\n6.69\nC\nLevel_1\nTimar_2\n\n\n6.03\nC\nLevel_1\nTimar_2\n\n\n7.26\nD\nLevel_1\nTimar_2\n\n\n8.19\nD\nLevel_1\nTimar_2\n\n\n6.20\nD\nLevel_1\nTimar_2\n\n\n9.47\nD\nLevel_1\nTimar_2\n\n\n8.15\nD\nLevel_1\nTimar_2\n\n\n10.17\nD\nLevel_1\nTimar_2\n\n\n8.48\nD\nLevel_1\nTimar_2\n\n\n3.29\nA\nLevel_2\nTimar_2\n\n\n4.61\nA\nLevel_2\nTimar_2\n\n\n3.07\nA\nLevel_2\nTimar_2\n\n\n6.75\nB\nLevel_2\nTimar_2\n\n\n8.29\nB\nLevel_2\nTimar_2\n\n\n11.56\nC\nLevel_2\nTimar_2\n\n\n12.00\nC\nLevel_2\nTimar_2\n\n\n12.07\nC\nLevel_2\nTimar_2\n\n\n11.41\nC\nLevel_2\nTimar_2\n\n\n11.43\nC\nLevel_2\nTimar_2\n\n\n11.86\nC\nLevel_2\nTimar_2\n\n\n17.18\nD\nLevel_2\nTimar_2\n\n\n14.48\nD\nLevel_2\nTimar_2\n\n\n16.59\nD\nLevel_2\nTimar_2\n\n\n16.33\nD\nLevel_2\nTimar_2\n\n\n17.06\nD\nLevel_2\nTimar_2\n\n\n15.70\nD\nLevel_2\nTimar_2\n\n\n6.37\nA\nLevel_3\nTimar_2\n\n\n6.27\nA\nLevel_3\nTimar_2\n\n\n11.46\nB\nLevel_3\nTimar_2\n\n\n13.21\nB\nLevel_3\nTimar_2\n\n\n19.16\nC\nLevel_3\nTimar_2\n\n\n18.70\nC\nLevel_3\nTimar_2\n\n\n19.59\nC\nLevel_3\nTimar_2\n\n\n18.56\nC\nLevel_3\nTimar_2\n\n\n16.72\nC\nLevel_3\nTimar_2\n\n\n17.43\nC\nLevel_3\nTimar_2\n\n\n16.78\nC\nLevel_3\nTimar_2\n\n\n23.53\nD\nLevel_3\nTimar_2\n\n\n23.38\nD\nLevel_3\nTimar_2\n\n\n24.04\nD\nLevel_3\nTimar_2\n\n\n23.09\nD\nLevel_3\nTimar_2\n\n\n24.16\nD\nLevel_3\nTimar_2\n\n\n23.35\nD\nLevel_3\nTimar_2\n\n\n4.77\nA\nLevel_1\nTimar_3\n\n\n3.72\nA\nLevel_1\nTimar_3\n\n\n3.91\nA\nLevel_1\nTimar_3\n\n\n3.38\nA\nLevel_1\nTimar_3\n\n\n4.68\nA\nLevel_1\nTimar_3\n\n\n2.36\nA\nLevel_1\nTimar_3\n\n\n5.54\nB\nLevel_1\nTimar_3\n\n\n7.43\nB\nLevel_1\nTimar_3\n\n\n5.35\nB\nLevel_1\nTimar_3\n\n\n8.79\nC\nLevel_1\nTimar_3\n\n\n8.61\nC\nLevel_1\nTimar_3\n\n\n8.68\nC\nLevel_1\nTimar_3\n\n\n11.72\nD\nLevel_1\nTimar_3\n\n\n12.49\nD\nLevel_1\nTimar_3\n\n\n11.82\nD\nLevel_1\nTimar_3\n\n\n11.49\nD\nLevel_1\nTimar_3\n\n\n13.34\nD\nLevel_1\nTimar_3\n\n\n11.79\nD\nLevel_1\nTimar_3\n\n\n11.82\nD\nLevel_1\nTimar_3\n\n\n5.90\nA\nLevel_2\nTimar_3\n\n\n6.71\nA\nLevel_2\nTimar_3\n\n\n11.93\nB\nLevel_2\nTimar_3\n\n\n11.96\nB\nLevel_2\nTimar_3\n\n\n11.32\nB\nLevel_2\nTimar_3\n\n\n11.68\nB\nLevel_2\nTimar_3\n\n\n12.06\nB\nLevel_2\nTimar_3\n\n\n17.41\nC\nLevel_2\nTimar_3\n\n\n18.53\nC\nLevel_2\nTimar_3\n\n\n22.48\nD\nLevel_2\nTimar_3\n\n\n24.31\nD\nLevel_2\nTimar_3\n\n\n22.46\nD\nLevel_2\nTimar_3\n\n\n23.70\nD\nLevel_2\nTimar_3\n\n\n23.47\nD\nLevel_2\nTimar_3\n\n\n8.35\nA\nLevel_3\nTimar_3\n\n\n8.94\nA\nLevel_3\nTimar_3\n\n\n7.09\nA\nLevel_3\nTimar_3\n\n\n10.18\nA\nLevel_3\nTimar_3\n\n\n16.34\nB\nLevel_3\nTimar_3\n\n\n17.54\nB\nLevel_3\nTimar_3\n\n\n16.88\nB\nLevel_3\nTimar_3\n\n\n17.25\nB\nLevel_3\nTimar_3\n\n\n20.09\nB\nLevel_3\nTimar_3\n\n\n18.02\nB\nLevel_3\nTimar_3\n\n\n16.71\nB\nLevel_3\nTimar_3\n\n\n25.36\nC\nLevel_3\nTimar_3\n\n\n27.45\nC\nLevel_3\nTimar_3\n\n\n26.98\nC\nLevel_3\nTimar_3\n\n\n35.68\nD\nLevel_3\nTimar_3\n\n\n35.07\nD\nLevel_3\nTimar_3\n\n\n34.51\nD\nLevel_3\nTimar_3\n\n\n2.92\nA\nLevel_1\nTimar_4\n\n\n5.00\nA\nLevel_1\nTimar_4\n\n\n3.38\nA\nLevel_1\nTimar_4\n\n\n2.62\nA\nLevel_1\nTimar_4\n\n\n5.87\nA\nLevel_1\nTimar_4\n\n\n4.43\nA\nLevel_1\nTimar_4\n\n\n3.76\nA\nLevel_1\nTimar_4\n\n\n9.06\nB\nLevel_1\nTimar_4\n\n\n8.89\nB\nLevel_1\nTimar_4\n\n\n7.38\nB\nLevel_1\nTimar_4\n\n\n10.21\nB\nLevel_1\nTimar_4\n\n\n7.74\nB\nLevel_1\nTimar_4\n\n\n10.58\nC\nLevel_1\nTimar_4\n\n\n11.86\nC\nLevel_1\nTimar_4\n\n\n12.21\nC\nLevel_1\nTimar_4\n\n\n14.31\nC\nLevel_1\nTimar_4\n\n\n12.11\nC\nLevel_1\nTimar_4\n\n\n16.46\nD\nLevel_1\nTimar_4\n\n\n15.92\nD\nLevel_1\nTimar_4\n\n\n15.67\nD\nLevel_1\nTimar_4\n\n\n15.97\nD\nLevel_1\nTimar_4\n\n\n16.79\nD\nLevel_1\nTimar_4\n\n\n10.08\nA\nLevel_2\nTimar_4\n\n\n9.03\nA\nLevel_2\nTimar_4\n\n\n9.21\nA\nLevel_2\nTimar_4\n\n\n14.77\nB\nLevel_2\nTimar_4\n\n\n16.98\nB\nLevel_2\nTimar_4\n\n\n16.22\nB\nLevel_2\nTimar_4\n\n\n14.53\nB\nLevel_2\nTimar_4\n\n\n16.52\nB\nLevel_2\nTimar_4\n\n\n23.84\nC\nLevel_2\nTimar_4\n\n\n25.46\nC\nLevel_2\nTimar_4\n\n\n31.23\nD\nLevel_2\nTimar_4\n\n\n31.57\nD\nLevel_2\nTimar_4\n\n\n31.07\nD\nLevel_2\nTimar_4\n\n\n31.82\nD\nLevel_2\nTimar_4\n\n\n32.40\nD\nLevel_2\nTimar_4\n\n\n31.27\nD\nLevel_2\nTimar_4\n\n\n32.83\nD\nLevel_2\nTimar_4\n\n\n10.79\nA\nLevel_3\nTimar_4\n\n\n10.95\nA\nLevel_3\nTimar_4\n\n\n25.44\nB\nLevel_3\nTimar_4\n\n\n22.98\nB\nLevel_3\nTimar_4\n\n\n24.41\nB\nLevel_3\nTimar_4\n\n\n23.62\nB\nLevel_3\nTimar_4\n\n\n24.41\nB\nLevel_3\nTimar_4\n\n\n37.69\nC\nLevel_3\nTimar_4\n\n\n37.59\nC\nLevel_3\nTimar_4\n\n\n47.67\nD\nLevel_3\nTimar_4\n\n\n45.71\nD\nLevel_3\nTimar_4\n\n\n50.50\nD\nLevel_3\nTimar_4\n\n\n48.67\nD\nLevel_3\nTimar_4\n\n\n48.54\nD\nLevel_3\nTimar_4\n\n\n47.99\nD\nLevel_3\nTimar_4\n\n\n48.51\nD\nLevel_3\nTimar_4\n\n\n4.84\nA\nLevel_1\nTimar_5\n\n\n5.42\nA\nLevel_1\nTimar_5\n\n\n4.60\nA\nLevel_1\nTimar_5\n\n\n8.63\nB\nLevel_1\nTimar_5\n\n\n10.99\nB\nLevel_1\nTimar_5\n\n\n11.52\nB\nLevel_1\nTimar_5\n\n\n9.69\nB\nLevel_1\nTimar_5\n\n\n13.75\nC\nLevel_1\nTimar_5\n\n\n15.64\nC\nLevel_1\nTimar_5\n\n\n14.96\nC\nLevel_1\nTimar_5\n\n\n18.27\nD\nLevel_1\nTimar_5\n\n\n20.00\nD\nLevel_1\nTimar_5\n\n\n19.37\nD\nLevel_1\nTimar_5\n\n\n19.66\nD\nLevel_1\nTimar_5\n\n\n18.84\nD\nLevel_1\nTimar_5\n\n\n21.80\nD\nLevel_1\nTimar_5\n\n\n19.67\nD\nLevel_1\nTimar_5\n\n\n8.39\nA\nLevel_2\nTimar_5\n\n\n10.20\nA\nLevel_2\nTimar_5\n\n\n10.26\nA\nLevel_2\nTimar_5\n\n\n9.01\nA\nLevel_2\nTimar_5\n\n\n7.11\nA\nLevel_2\nTimar_5\n\n\n9.36\nA\nLevel_2\nTimar_5\n\n\n10.57\nA\nLevel_2\nTimar_5\n\n\n19.94\nB\nLevel_2\nTimar_5\n\n\n19.90\nB\nLevel_2\nTimar_5\n\n\n20.56\nB\nLevel_2\nTimar_5\n\n\n28.81\nC\nLevel_2\nTimar_5\n\n\n31.10\nC\nLevel_2\nTimar_5\n\n\n29.99\nC\nLevel_2\nTimar_5\n\n\n30.71\nC\nLevel_2\nTimar_5\n\n\n31.03\nC\nLevel_2\nTimar_5\n\n\n30.22\nC\nLevel_2\nTimar_5\n\n\n39.12\nD\nLevel_2\nTimar_5\n\n\n41.16\nD\nLevel_2\nTimar_5\n\n\n38.00\nD\nLevel_2\nTimar_5\n\n\n14.46\nA\nLevel_3\nTimar_5\n\n\n14.74\nA\nLevel_3\nTimar_5\n\n\n14.83\nA\nLevel_3\nTimar_5\n\n\n16.02\nA\nLevel_3\nTimar_5\n\n\n15.14\nA\nLevel_3\nTimar_5\n\n\n15.41\nA\nLevel_3\nTimar_5\n\n\n14.93\nA\nLevel_3\nTimar_5\n\n\n29.75\nB\nLevel_3\nTimar_5\n\n\n30.70\nB\nLevel_3\nTimar_5\n\n\n31.15\nB\nLevel_3\nTimar_5\n\n\n27.60\nB\nLevel_3\nTimar_5\n\n\n30.57\nB\nLevel_3\nTimar_5\n\n\n30.37\nB\nLevel_3\nTimar_5\n\n\n29.57\nB\nLevel_3\nTimar_5\n\n\n45.95\nC\nLevel_3\nTimar_5\n\n\n44.61\nC\nLevel_3\nTimar_5\n\n\n44.72\nC\nLevel_3\nTimar_5\n\n\n45.86\nC\nLevel_3\nTimar_5\n\n\n46.72\nC\nLevel_3\nTimar_5\n\n\n45.27\nC\nLevel_3\nTimar_5\n\n\n44.58\nC\nLevel_3\nTimar_5\n\n\n58.81\nD\nLevel_3\nTimar_5\n\n\n59.67\nD\nLevel_3\nTimar_5\n\n\n\n\n\n\n\n\n\nبرای پیاده‌سازی یک مدل آنالیز واریانس از نوع اول و یا انواع دیگر آن می‌توانیم از اکثر نرم‌افزارهای آماری از قبیل SPSS, SAS, STATA, MINITAB, R, ...  استفاده کنیم البته تابع aov  به صورت پیش فرض از نوع ۱ برای مجموع مربعات استفاده می‌کند ولی با استفاده از تابع Anova  درون بسته car  می‌توانیم به انواع دیگر روش‌های مجموع مربعات دسترسی داشته باشیم. البته در پایتون این امر با سهولت بیشتری انجام می‌شود. به کدهای پایین توجه کنید؛\n\n\n\nshow the code: create connection between R and python\nlibrary(reticulate)\npathh &lt;- Sys.which(\"python\") |&gt;\n            gsub(\"\\\\\", \"//\", x = _,  fixed = TRUE)\nuse_python(pathh)\n\n\n\n\nshow the code: R Anova Type I\n## Type 1 Anova for Balanced Design \nModel_R_Balanced_data &lt;- aov(y ~ Fac1 * Fac2 * Fac3, data = anova_data_Balanced)\n\n## get Anova type 1 with R for Balanced data\ntab_R_b1 &lt;- anova(Model_R_Balanced_data)\n\n## Type 1 Anova for Unbalanced Design\nModel_R_Unbalanced_data &lt;- aov(y ~ Fac1 * Fac2 * Fac3, data = Anova_data_unbalanced)\n\n## get Anova type 1 with R for UnBalanced data\ntab_R_un1 &lt;- anova(Model_R_Unbalanced_data)\n\n## set R for type III\n\noptions(contrasts = c(\"contr.sum\"\n, \"contr.sum\"))\nModel_R_Balanced_data_type3 &lt;- aov(y ~ Fac1 * Fac2 * Fac3, data = anova_data_Balanced)\nModel_R_Unbalanced_data_type3 &lt;- aov(y ~ Fac1 * Fac2 * Fac3, data = Anova_data_unbalanced)\n\n\n\n\nshow the code: python Anova Type I\n\n\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nfrom statsmodels.formula.api import ols\n\n\npy_Balanced_data = r.anova_data_Balanced.copy()\npy_Unbalanced_data = r.Anova_data_unbalanced.copy()\n# py_Balanced_data.head()\n# py_Unbalanced_data.tail()\n\n## python type I and II anova for Balanced data\nModel_py_Balanced_data_type1 = ols('y ~ C(Fac1)*C(Fac2)*C(Fac3)', \n                                data = py_Balanced_data).fit()\ntab_py_b1 = sm.stats.anova_lm(Model_py_Balanced_data_type1, typ = \"I\")\n# print(tab_py_b1)\n\n## python type I and II anova for Unbalanced data\n\nModel_py_Unbalanced_data_type1 = ols('y ~ C(Fac1)*C(Fac2)*C(Fac3)', \n                                    data = py_Unbalanced_data).fit()\ntab_py_un1 = sm.stats.anova_lm(Model_py_Unbalanced_data_type1, typ = \"I\")\n# print(tab_py_un1)\n\n\n\nنتایج را در آخر این صفحه مورد بررسی قرار خواهیم داد."
  },
  {
    "objectID": "Anova-SS.html#type-ii",
    "href": "Anova-SS.html#type-ii",
    "title": "",
    "section": "Type II",
    "text": "Type II\n\n\nمجموع مربعات نوع ۲\n\n\nبرای محاسبه مجموع مربعات نوع ۲، ما  اثر‌ها را بر‌اساس فرم زیر برآورد می‌کنیم. \n\nSS(A|B): for factor A\nSS(B|A): for factor B\n\nمشخص هست که هیچ اثر معنادار در مجموع مربعات نوع ۲ در نظر گرفته نمی‌شود. به عبارت دیگر، ابتدا باید اثر توأم را بر‌اساس SS(AB|A, B)  معناداری آن بررسی شود. در صورتی که اثر توأمی معنادار گزارش نشد، به تحلیل اثرات اصلی بر‌اساس روش مربعات نوع ۲ بپردازیم. \nاگر در واقعیت هیچ اثر توأم معناداری وجود نداشته باشد، آن‌گاه نوع ۲ از نظر آماری قدرتمند‌تر از نوع ۳ می‌باشد. برای جزئیات بیشتر درباره روش نوع ۲ می‌توانید به [2] مراجعه کنید. \nاز نظر محاسباتی، این روش معادل روش نوع ۱ هست، البته بر‌اساس ترتیب‌های مختلف ورود عامل‌ها به مدل و انتخاب مناسبت‌ترین خروجی. \nبرای پیاده‌سازی این روش در R  باید علاوه بر‌پیاده‌سازی مدل چه با استفاده از تابع aov  و چه با استفاده از تابع lm  از تابع car :: Anova   استفاده کنیم. ولی در پایتون علاوه بر‌ابزاری که کتابخانه statsmodels  در اختیار ما قرار می‌دهد. یک بسته دیگر هم هست که روش نوع ۲ و همچنین نوع ۳ را پشتیبانی می‌کند. و می‌تواند خروجی‌های بهتری به ما نمایش دهد که با هم در ادامه خواهیم دید. \n\n\n\nمثال: \n\n\n\nshow the code: R Anova Type II\n## R version\n\n## Type II Anova for Balanced Design \ntab_R_b2 &lt;- car :: Anova(Model_R_Balanced_data, type = \"II\")\n\n## Type II Anova for Unbalanced Design\ntab_R_un2 &lt;- car :: Anova(Model_R_Unbalanced_data, type = \"II\")\n\n\n\n\nshow the code: python Anova Type II\n\n## python type II anova for Balanced data\n\ntab_py_b2 = sm.stats.anova_lm(Model_py_Balanced_data_type1, typ = \"II\")\n# print(tab_py_b2)\n\n## python type II anova for Unbalanced data\ntab_py_un2 = sm.stats.anova_lm(Model_py_Unbalanced_data_type1, typ = \"II\")\n# print(tab_py_un2)\n\n\n\nدر آخر این صفحه ما یک مقایسه اجمالی جداولی خروجی را با هم خواهیم کرد."
  },
  {
    "objectID": "Anova-SS.html#type-iii",
    "href": "Anova-SS.html#type-iii",
    "title": "",
    "section": "Type III",
    "text": "Type III\n\n\nمجموع مربعات نوع ۳\n\n\nبرای درک روش نوع ۳، باید روشی که برای برآورد مربعات اثرات اصلی به کار می‌برد را بفهمیم. این روش از قاعده زیر برای مربعات اثرات اصلی استفاده می‌کند. \n\nSS(A | B, AB) for factor A. \nSS(B | A, AB) for factor B. \n\nدر حقیقت این روش، یک اثر اصلی را بعد از اثرات اصلی دیگر و همچنین اثرات توأم مورد بررسی قرار می‌دهد. بنابراین این رویکرد در حضور وجود اثرات توأم می‌توان مناسب‌ترین رویکرد برای به دست آوردن مربعات تیماری باشد. \n\nبا‌این‌حال در صورت وجود اثرات توأم، تفسیر اثر اصلی اصولا امر راحتی نیست. و یا با بیان بهتر؛ وقتی اثر توأمی در مدل حضور دارد اصولا تفسیر اثرات اصلی به‌ تنهایی نمی‌تواند رویکرد خیلی قابل دفاعی باشد. برای جزئیات بیشتر می‌توانید به [3] مراجعه کنید. \n\nوقتی اثر توأم در مدل حضور ندارد، روی نوع ۲، روش قدرتمند‌تری می‌باشد. \n\n \nمثال: \n\n\n\nshow the code: R Anova Type III\n## R version\n\n## Type III Anova for Balanced Design \ntab_R_b3 &lt;- car :: Anova(Model_R_Balanced_data_type3, type = \"III\")\n\n## Type III Anova for Unbalanced Design\ntab_R_un3 &lt;- car :: Anova(Model_R_Unbalanced_data_type3, type = \"III\")\n\n\n\n\nshow the code: python Anova Type III\nfrom patsy.contrasts import Sum\n\n## python type III anova for Balanced data\nModel_py_Balanced_data_type3 = ols('y ~ C(Fac1, Sum)*C(Fac2, Sum)*C(Fac3, Sum)', \n                                data = py_Balanced_data).fit()\ntab_py_b3 = sm.stats.anova_lm(Model_py_Balanced_data_type3, typ = \"III\")\n# print(tab_py_b3)\n\n## python type III anova for Unbalanced data\n\nModel_py_Unbalanced_data_type3 = ols('y ~ C(Fac1, Sum)*C(Fac2, Sum)*C(Fac3, Sum)', \n                                    data = py_Unbalanced_data).fit()\ntab_py_un3 = sm.stats.anova_lm(Model_py_Unbalanced_data_type3, typ = \"III\")\n# print(tab_py_un3)"
  },
  {
    "objectID": "Anova-SS.html#type-iv",
    "href": "Anova-SS.html#type-iv",
    "title": "",
    "section": "Type IV",
    "text": "Type IV\n\n\nمجموع مربعات نوع ۴\n\nرویکرد مربعات نوع ۴، برای زمان‌هایی هست که در بعضی از سلول‌ها یا ترکیبات تیماری ما اصولا هیچ مشاهده‌ای نداریم. این روش به روش Radical   نیز معروف هست. و برآورد‌های به دست آمده در این روش اصولا منحصر به فرد نیستند. برای جزئیات بیشتر در مورد این روش می‌توانید به [4]  مراجعه کنید. \n\n\nدر صورت عدم وجود سلول خالی، نتایج این روش و رویکرد نوع ۳ تفاوتی ندارد."
  },
  {
    "objectID": "Anova-SS.html#compare-results",
    "href": "Anova-SS.html#compare-results",
    "title": "",
    "section": "Compare Results",
    "text": "Compare Results\n\nبررسی نتایج \n\nدر این قسمت می‌خواهیم نتایج روش‌های ۱ و ۲ و ۳ را با هم مقایسه کنیم. برای این منظور من جداول آنالیز واریانس خروجی در کدهایی که در بالا قرار دادم را در پایین می‌آوریم. \n\n\nجداول نتایج برای طرح متعادل\n\n\n\n\n\nR: Anova Type I\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n\nFac1\n3\n10890.7850\n3630.2616604\n3816.15115\n0\n\n\nFac2\n2\n9152.8378\n4576.4189129\n4810.75689\n0\n\n\nFac3\n4\n12103.3691\n3025.8422715\n3180.78215\n0\n\n\nFac1:Fac2\n6\n1805.8769\n300.9794779\n316.39129\n0\n\n\nFac1:Fac3\n12\n2443.4062\n203.6171823\n214.04351\n0\n\n\nFac2:Fac3\n8\n2030.2942\n253.7867780\n266.78207\n0\n\n\nFac1:Fac2:Fac3\n24\n454.9202\n18.9550097\n19.92561\n0\n\n\nResiduals\n180\n171.2320\n0.9512887\nNA\nNA\n\n\n\nNote: \n\n\n\n\n\n\n\n Banalced Desgin\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPython: Anova Type I\n\n\n\ndf\nsum_sq\nmean_sq\nF\nPR(&gt;F)\n\n\n\n\nC(Fac1)\n3\n10890.7850\n3630.2616604\n3816.15115\n0\n\n\nC(Fac2)\n2\n9152.8378\n4576.4189129\n4810.75689\n0\n\n\nC(Fac3)\n4\n12103.3691\n3025.8422715\n3180.78215\n0\n\n\nC(Fac1):C(Fac2)\n6\n1805.8769\n300.9794779\n316.39129\n0\n\n\nC(Fac1):C(Fac3)\n12\n2443.4062\n203.6171823\n214.04351\n0\n\n\nC(Fac2):C(Fac3)\n8\n2030.2942\n253.7867780\n266.78207\n0\n\n\nC(Fac1):C(Fac2):C(Fac3)\n24\n454.9202\n18.9550097\n19.92561\n0\n\n\nResidual\n180\n171.2320\n0.9512887\nNaN\nNaN\n\n\n\nNote: \n\n\n\n\n\n\n\n Banalced Desgin\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR: Anova Type II\n\n\n\nSum Sq\nDf\nF value\nPr(&gt;F)\n\n\n\n\nFac1\n10890.7850\n3\n3816.15115\n0\n\n\nFac2\n9152.8378\n2\n4810.75689\n0\n\n\nFac3\n12103.3691\n4\n3180.78215\n0\n\n\nFac1:Fac2\n1805.8769\n6\n316.39129\n0\n\n\nFac1:Fac3\n2443.4062\n12\n214.04351\n0\n\n\nFac2:Fac3\n2030.2942\n8\n266.78207\n0\n\n\nFac1:Fac2:Fac3\n454.9202\n24\n19.92561\n0\n\n\nResiduals\n171.2320\n180\nNA\nNA\n\n\n\nNote: \n\n\n\n\n\n\n Banalced Desgin\n\n\n\n\n\n\n\n\n\n\n\n\n\nPython: Anova Type II\n\n\n\nsum_sq\ndf\nF\nPR(&gt;F)\n\n\n\n\nC(Fac1)\n10890.7850\n3\n3816.15115\n0\n\n\nC(Fac2)\n9152.8378\n2\n4810.75689\n0\n\n\nC(Fac3)\n12103.3691\n4\n3180.78215\n0\n\n\nC(Fac1):C(Fac2)\n1805.8769\n6\n316.39129\n0\n\n\nC(Fac1):C(Fac3)\n2443.4062\n12\n214.04351\n0\n\n\nC(Fac2):C(Fac3)\n2030.2942\n8\n266.78207\n0\n\n\nC(Fac1):C(Fac2):C(Fac3)\n454.9202\n24\n19.92561\n0\n\n\nResidual\n171.2320\n180\nNaN\nNaN\n\n\n\nNote: \n\n\n\n\n\n\n Banalced Desgin\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR: Anova Type III\n\n\n\nSum Sq\nDf\nF value\nPr(&gt;F)\n\n\n\n\n(Intercept)\n54158.2157\n1\n56931.41617\n0\n\n\nFac1\n10890.7850\n3\n3816.15115\n0\n\n\nFac2\n9152.8378\n2\n4810.75689\n0\n\n\nFac3\n12103.3691\n4\n3180.78215\n0\n\n\nFac1:Fac2\n1805.8769\n6\n316.39129\n0\n\n\nFac1:Fac3\n2443.4062\n12\n214.04351\n0\n\n\nFac2:Fac3\n2030.2942\n8\n266.78207\n0\n\n\nFac1:Fac2:Fac3\n454.9202\n24\n19.92561\n0\n\n\nResiduals\n171.2320\n180\nNA\nNA\n\n\n\nNote: \n\n\n\n\n\n\n Banalced Desgin\n\n\n\n\n\n\n\n\n\n\n\n\n\nPython: Anova Type III\n\n\n\nsum_sq\ndf\nF\nPR(&gt;F)\n\n\n\n\nIntercept\n54158.2157\n1\n56931.41617\n0\n\n\nC(Fac1, Sum)\n10890.7850\n3\n3816.15115\n0\n\n\nC(Fac2, Sum)\n9152.8378\n2\n4810.75689\n0\n\n\nC(Fac3, Sum)\n12103.3691\n4\n3180.78215\n0\n\n\nC(Fac1, Sum):C(Fac2, Sum)\n1805.8769\n6\n316.39129\n0\n\n\nC(Fac1, Sum):C(Fac3, Sum)\n2443.4062\n12\n214.04351\n0\n\n\nC(Fac2, Sum):C(Fac3, Sum)\n2030.2942\n8\n266.78207\n0\n\n\nC(Fac1, Sum):C(Fac2, Sum):C(Fac3, Sum)\n454.9202\n24\n19.92561\n0\n\n\nResidual\n171.2320\n180\nNaN\nNaN\n\n\n\nNote: \n\n\n\n\n\n\n Banalced Desgin\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nجداول نتایج برای طرح نامتعادل\n\n\n\n\n\nR: Anova Type I\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n\nFac1\n3\n10153.2982\n3384.4327219\n3715.39978\n0\n\n\nFac2\n2\n10463.9292\n5231.9645771\n5743.60362\n0\n\n\nFac3\n4\n12940.0402\n3235.0100610\n3551.36493\n0\n\n\nFac1:Fac2\n6\n1811.1773\n301.8628809\n331.38235\n0\n\n\nFac1:Fac3\n12\n2570.3133\n214.1927737\n235.13890\n0\n\n\nFac2:Fac3\n8\n2142.1901\n267.7737678\n293.95963\n0\n\n\nFac1:Fac2:Fac3\n24\n422.8180\n17.6174177\n19.34024\n0\n\n\nResiduals\n209\n190.3823\n0.9109202\nNA\nNA\n\n\n\nNote: \n\n\n\n\n\n\n\n Unbanalced Desgin\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPython: Anova Type I\n\n\n\ndf\nsum_sq\nmean_sq\nF\nPR(&gt;F)\n\n\n\n\nC(Fac1)\n3\n10153.2982\n3384.4327219\n3715.39978\n0\n\n\nC(Fac2)\n2\n10463.9292\n5231.9645771\n5743.60362\n0\n\n\nC(Fac3)\n4\n12940.0402\n3235.0100610\n3551.36493\n0\n\n\nC(Fac1):C(Fac2)\n6\n1811.1773\n301.8628809\n331.38235\n0\n\n\nC(Fac1):C(Fac3)\n12\n2570.3133\n214.1927737\n235.13890\n0\n\n\nC(Fac2):C(Fac3)\n8\n2142.1901\n267.7737678\n293.95963\n0\n\n\nC(Fac1):C(Fac2):C(Fac3)\n24\n422.8180\n17.6174177\n19.34024\n0\n\n\nResidual\n209\n190.3823\n0.9109202\nNaN\nNaN\n\n\n\nNote: \n\n\n\n\n\n\n\n Unbanalced Desgin\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR: Anova Type II\n\n\n\nSum Sq\nDf\nF value\nPr(&gt;F)\n\n\n\n\nFac1\n11134.2492\n3\n4074.35952\n0\n\n\nFac2\n10046.3696\n2\n5514.40704\n0\n\n\nFac3\n13243.9531\n4\n3634.77313\n0\n\n\nFac1:Fac2\n1920.8077\n6\n351.44090\n0\n\n\nFac1:Fac3\n2531.5946\n12\n231.59682\n0\n\n\nFac2:Fac3\n2142.1901\n8\n293.95963\n0\n\n\nFac1:Fac2:Fac3\n422.8180\n24\n19.34024\n0\n\n\nResiduals\n190.3823\n209\nNA\nNA\n\n\n\nNote: \n\n\n\n\n\n\n Unbanalced Desgin\n\n\n\n\n\n\n\n\n\n\n\n\n\nPython: Anova Type II\n\n\n\nsum_sq\ndf\nF\nPR(&gt;F)\n\n\n\n\nC(Fac1)\n11134.2492\n3\n4074.35952\n0\n\n\nC(Fac2)\n10046.3696\n2\n5514.40704\n0\n\n\nC(Fac3)\n13243.9531\n4\n3634.77313\n0\n\n\nC(Fac1):C(Fac2)\n1920.8077\n6\n351.44090\n0\n\n\nC(Fac1):C(Fac3)\n2531.5946\n12\n231.59682\n0\n\n\nC(Fac2):C(Fac3)\n2142.1901\n8\n293.95963\n0\n\n\nC(Fac1):C(Fac2):C(Fac3)\n422.8180\n24\n19.34024\n0\n\n\nResidual\n190.3823\n209\nNaN\nNaN\n\n\n\nNote: \n\n\n\n\n\n\n Unbanalced Desgin\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR: Anova Type III\n\n\n\nSum Sq\nDf\nF value\nPr(&gt;F)\n\n\n\n\n(Intercept)\n49340.9237\n1\n54166.02192\n0\n\n\nFac1\n10163.4257\n3\n3719.10574\n0\n\n\nFac2\n7974.9291\n2\n4377.40269\n0\n\n\nFac3\n10883.2526\n4\n2986.88419\n0\n\n\nFac1:Fac2\n1742.2812\n6\n318.77678\n0\n\n\nFac1:Fac3\n2182.8683\n12\n199.69443\n0\n\n\nFac2:Fac3\n1867.4754\n8\n256.26221\n0\n\n\nFac1:Fac2:Fac3\n422.8180\n24\n19.34024\n0\n\n\nResiduals\n190.3823\n209\nNA\nNA\n\n\n\nNote: \n\n\n\n\n\n\n Unbanalced Desgin\n\n\n\n\n\n\n\n\n\n\n\n\n\nPython: Anova Type III\n\n\n\nsum_sq\ndf\nF\nPR(&gt;F)\n\n\n\n\nIntercept\n49340.9237\n1\n54166.02192\n0\n\n\nC(Fac1, Sum)\n10163.4257\n3\n3719.10574\n0\n\n\nC(Fac2, Sum)\n7974.9291\n2\n4377.40269\n0\n\n\nC(Fac3, Sum)\n10883.2526\n4\n2986.88419\n0\n\n\nC(Fac1, Sum):C(Fac2, Sum)\n1742.2812\n6\n318.77678\n0\n\n\nC(Fac1, Sum):C(Fac3, Sum)\n2182.8683\n12\n199.69443\n0\n\n\nC(Fac2, Sum):C(Fac3, Sum)\n1867.4754\n8\n256.26221\n0\n\n\nC(Fac1, Sum):C(Fac2, Sum):C(Fac3, Sum)\n422.8180\n24\n19.34024\n0\n\n\nResidual\n190.3823\n209\nNaN\nNaN\n\n\n\nNote: \n\n\n\n\n\n\n Unbanalced Desgin\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nواضح هست که وقتی طرح متعادل هست، نتایج برای هر سه روش \n\nAnova Type I, Anova Type II, Anova Type III\n\n\nکاملا یکسان هست. تفاوت‌ زمانی حاصل می‌شود که طرح نامتعادل هست. لازم به ذکر هست که برای پیاده‌سازی آنالیز واریانس نوع ۳ اگر بخواهیم شرط"
  },
  {
    "objectID": "Anova-SS.html#conclusion",
    "href": "Anova-SS.html#conclusion",
    "title": "",
    "section": "Conclusion",
    "text": "Conclusion\n\n حرف آخر \n\nحتمن این سؤال مطرح خواهد شد که با تمام این شرحی که در این صفحه ارائه شد، ما چه زمانی باید از هر کدام از انواع روش‌های مجموع مربعات استفاده کنیم؛‌\n\n\n\nType I:  این شیوه با لحاظ کردن ترتیب ورود عامل‌ها به مدل از بقیه مدل‌ها متمایز می‌شود، این روش برای طرح‌های نامتعادل توصیه نمی شود و همچنین برای طرح‌‌هایی که تعداد عامل‌های زیادی دارند هم توصیه نمی‌شود. ولی برای طرح‌های متعادل با تعداد عامل‌های پایین و همچنین مدل‌های Nested-Design  می‌تواند مناسب باشد. و همچنین برای مدل‌های رگرسیون چند‌جمله‌ای هم مفید هست. \n\n\nType II:  درک مجموع مربعات نوع ۲ کمی دشوار‌تر هست نسبت به ۱ و ۳؛ ولی به طور کلی، نوع ۲ برای یک اثر مانند اثر عامل A که ممکن هست یک اثر اصلی یا حتی یک اثر توأم در نظر گرفته شود وقتی این اثر را بخواهد مثلا با اثر B بیان کند اثر A را از B جدا می‌کند. یعنی اثراتی که با هم اشتراک دارند باید اشتراکات آن‌ها از هم تفکیک شود. برای همین منظور اصولا این نوع زمانی توصیه می شود که ما اعتقاد داشته باشیم اثرات توأم در مدل ما حضور ندارد یا اگر وجود دارد ناچیز هست. \n\n\nباید در این‌جا ذکر کنیم که مجموع نوع ۲ و همچنین نوع ۳ اصطلاحا به آن‌ها مجموع مربعات جزئی نیز می‌گویند. اتفاقی که در این‌جا می‌افتد و ادبیات این رشته از آن استفاده می‌شود، این روش نیز مانند روش ۳، به این‌شکل هست که هر اثر بر‌اساس اثرات دیگر تنظیم می‌شود. این روش در حقیقت با تجزیه تحلیل مجموع مربعات وزنی که با الگوریتم یتس پیاده‌سازی می‌شود، مطابقت دارد. یکی از کارکردهای این روش زمانی هست که محقق علی‌الرغم وجود اثر توأم در مدل، نیازمند بررسی اثرات اصلی باشد و بخواهد آن‌ها را با هم مقابسه کند. (هرچند این نوع تفسیر در میان آماردانان طرفدار چندانی ندارد) واضح هست که اگر مدل فقط شامل اثرات اصلی باشد رویکرد نوع ۳ و نوع ۲ نتایج کاملا یکسانی را تولید خواهد کرد. \n\n\nاین شیوه اساسا برای موقیعت‌هایی طراحی شده هست که ما سلول‌های خالی داریم یا اصطلاحا بعضی از ترکیبات تیماری فاقد نمونه محقق شده هستند. نتایج این روش با روش نوع ۳ زمانی که سلول خالی در طرح وجود نداشته باشد یکسان هست. و همچنین همان‌طور که قبال هم ذکر شد و در این‌جا باز بر‌روی آن تأکید می‌شود؛ \n\n\nوقتی طرح متعادل هست، نتایج هر ۴ روش یکسان خواهد بود."
  },
  {
    "objectID": "Anova-SS.html#references",
    "href": "Anova-SS.html#references",
    "title": "",
    "section": "References",
    "text": "References\n\n\n\nمنابع\n\n\n\n\n\n[1] Zahn. Ista. “Working with unbalanced cell sizes in multiple regression with categorical predictors”, 2009. [Google Scholar]\n\n\n[2] Oyvind Langsrud. “ANOVA for unbalanced data: Use Type II instead of Type III sums of squares”, Statistics and Computing, Volume 13, Number 2, pp. 163-167, 2003. [Google Scholar]\n\n\n[3] Shaw, R. G., & Mitchell-Olds, T. (1993). ANOVA for unbalanced data: an overview. Ecology, 74(6), 1638-1645. [Google Scholar]\n\n\n[4] URL"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "",
    "section": "",
    "text": "تلاش من در این‌جا صرفا برای معرفی کارهایی هست که درون  مخازن گیت‌هابم انجام می‌دهم، و همچنین ارائه آموزش‌هایی که شاید برای دیگران هم جالب باشد. ولی اصلی‌ترین چیزی که باعث شکل‌گیری انگیزه درونی جهت ایجاد این صفحه شد. معرفی یک ابزار مبتنی بر‌ برنامه نویسی R بود به نام BlueSky که در این  صفحه  به آن خواهیم پرداخت. با توجه به زمان محدودی که در اختیار دارم، تکمیل این صفحات زمان خواهد برد. ولی قسمت مربوط به  BlueSky را می‌توانید به صورت کامل مشاهده کنید. \n\n\n\n\n\n\n Back to top"
  }
]